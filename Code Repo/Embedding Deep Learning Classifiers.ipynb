{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Model\n",
    "In this notebook, I implemented the words embedding model with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.ranking module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from myfunctions import *\n",
    "import joblib\n",
    "\n",
    "from embedding_pytorch import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Find and sort list of common words in a sentence based on its occurence in the sentence\n",
    "def most_common_words(sent, numb_words=20):\n",
    "    words = sent.split()\n",
    "    wordCount = Counter(words)\n",
    "    wordCount = wordCount.most_common()\n",
    "    if numb_words > len(wordCount) or numb_words < 0:\n",
    "        numb_words = len(wordCount)\n",
    "    top_words = [x[0] for x in wordCount[:numb_words]]\n",
    "    count_words = [x[1] for x in wordCount[:numb_words]]\n",
    "    return top_words, count_words\n",
    "\n",
    "def add_unknown_token(sent, vocab):\n",
    "    sent_s = sent.split()\n",
    "    for idx, s in enumerate(sent_s):\n",
    "        if s not in vocab:\n",
    "            sent_s[idx] = '<unk>'\n",
    "    psent = ' '.join(sent_s)\n",
    "    return psent\n",
    "\n",
    "def remove_unknown_token(sent, vocab):\n",
    "    sent_s = sent.split()\n",
    "    psent = [x for x in sent_s if x in vocab]\n",
    "    psent = ' '.join(psent)\n",
    "    return psent\n",
    "\n",
    "# Get the embedded feature of a word from a pretrained model (Glove or Word2Vec)\n",
    "def get_word_features(w, model):\n",
    "    try:\n",
    "        feature = model[w]\n",
    "        flag = 1\n",
    "    except:\n",
    "        feature = np.random.uniform(-2.5, 2.5, 300)\n",
    "        file1 = open(\"KeyError_Glove.txt\",\"a\") \n",
    "        file1.write(f'{w}\\n')\n",
    "        file1.close() \n",
    "        flag = 0 # Error checker\n",
    "    return feature, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrain Glove model\n",
    "embeddings_dict = {}\n",
    "with open(\"../glove/glove.6B.300d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TRAINING SAMPLES =====\n",
      "Total Sample: 17171\n",
      "Sarcastic: 8180 (47.64%)\n",
      "Not Sarcastic: 8991 (52.36%)\n",
      "===== VALIDATING SAMPLES =====\n",
      "Total Sample: 4293\n",
      "Sarcastic: 2045 (47.64%)\n",
      "Not Sarcastic: 2248 (52.36%)\n",
      "===== TESTING SAMPLES =====\n",
      "Total Sample: 7155\n",
      "Sarcastic: 3409 (47.65%)\n",
      "Not Sarcastic: 3746 (52.35%)\n"
     ]
    }
   ],
   "source": [
    "# Read dataset\n",
    "data_full = pd.read_json('fake_news.json', lines=True)\n",
    "data_full = data_full.drop(columns=['article_link']) # remove link column\n",
    "df_train_f, df_test = split_dataframe(data_full, test_size=0.25, seed=1509)\n",
    "df_train, df_validate = split_dataframe(df_train_f, test_size=0.2, seed=1309)\n",
    "\n",
    "# Proportion of each subsets\n",
    "list_label = df_train['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TRAINING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_validate['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== VALIDATING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_test['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TESTING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "data_train = df_train.copy()\n",
    "data_train_f = df_train_f.copy()\n",
    "data_val = df_validate.copy()\n",
    "data_test = df_test.copy()\n",
    "\n",
    "# Preprocessing\n",
    "# S1 - discard symbol out of headlines\n",
    "# S2 - lemmatised headline_s1\n",
    "\n",
    "data_train = df_train\n",
    "data_train['headline'] = data_train.headline.apply(lambda row: row.lower())\n",
    "data_train['headline_s1'] = data_train.headline.apply(lambda row: remove_symbol(row))\n",
    "data_train['headline_s2'] = data_train.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_train['headline_s2'] = data_train.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "#data_train = data_train.drop(columns=['headline', 'headline_s1'])\n",
    "\n",
    "data_train_f = df_train_f\n",
    "data_train_f['headline'] = data_train_f.headline.apply(lambda row: row.lower())\n",
    "data_train_f['headline_s1'] = data_train_f.headline.apply(lambda row: remove_symbol(row))\n",
    "data_train_f['headline_s2'] = data_train_f.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_train_f['headline_s2'] = data_train_f.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "\n",
    "data_val = df_validate\n",
    "data_val['headline'] = data_val.headline.apply(lambda row: row.lower())\n",
    "data_val['headline_s1'] = data_val.headline.apply(lambda row: remove_symbol(row))\n",
    "data_val['headline_s2'] = data_val.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_val['headline_s2'] = data_val.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "#data_val = data_val.drop(columns=['headline', 'headline_s1'])\n",
    "\n",
    "data_test = df_test\n",
    "data_test['headline'] = data_test.headline.apply(lambda row: row.lower())\n",
    "data_test['headline_s1'] = data_test.headline.apply(lambda row: remove_symbol(row))\n",
    "data_test['headline_s2'] = data_test.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_test['headline_s2'] = data_test.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding with UNK\n",
    "Using entire vocabulary + Using UNK Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train = data_train.copy()\n",
    "dt_val = data_val.copy()\n",
    "# Count the frequency of words in the training corpus\n",
    "all_string = dt_train.headline_s1.tolist()\n",
    "all_string_in_one = ' '.join(all_string)\n",
    "list_common_words, count_words = most_common_words(all_string_in_one, numb_words=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words remaining: 21115 / 23115\n",
      "Total discard (Unknown Token): 2000\n"
     ]
    }
   ],
   "source": [
    "cwdf = pd.DataFrame(np.asarray(count_words),\n",
    "                    columns=['count_words'])\n",
    "cwdf['words'] = list_common_words\n",
    "\n",
    "# Find the index of words appeared only once in the corpus\n",
    "s = cwdf.index[cwdf.iloc[:,0] == 1].tolist()[0]\n",
    "s = s + 21115 - 11476 # Only take 2000 unknown words into UNK token\n",
    "common_vocab = cwdf.words[0:s].tolist()\n",
    "print(f\"Number of unique words remaining: {s} / {len(cwdf)}\")\n",
    "print(f\"Total discard (Unknown Token): {cwdf.iloc[s:,0].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert unknown words into UNK tokens in the dataset\n",
    "dt_train['preprocess'] = dt_train.headline_s1.apply(lambda row: add_unknown_token(row, common_vocab))\n",
    "dt_val['preprocess'] = dt_val.headline_s1.apply(lambda row: add_unknown_token(row, common_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary: 21116\n"
     ]
    }
   ],
   "source": [
    "# Add unknown token to the vocab\n",
    "list_vocab = ['<unk>'] + common_vocab\n",
    "print(f\"Total Vocabulary: {len(list_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21115/21115 [00:00<00:00, 177586.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialise weight by using pretrained Glove model\n",
    "embedding_weight = np.zeros((len(list_vocab), 300)) # index is use when words is not indictionary\n",
    "unknown_word = dict()\n",
    "embedding_weight[0] = np.random.uniform(-2.5, 2.5, 300)\n",
    "for idx in tqdm(range(1, len(list_vocab))):\n",
    "    word = list_vocab[idx]\n",
    "    word_split = word.split()\n",
    "    if len(word_split) == 1:\n",
    "        feature, flag = get_word_features(word_split[0], embeddings_dict)\n",
    "        if flag == 0: # not exist word\n",
    "            unknown_word[word_split[0]] = feature\n",
    "    else:\n",
    "        feature = np.zeros((len(word_split), 300))\n",
    "        count = 0\n",
    "        for idx_w, w in enumerate(word_split):\n",
    "            ft, flag = get_word_features(w, embeddings_dict)\n",
    "            if flag == 0:\n",
    "                if w in list(unknown_word.keys()):\n",
    "                    ft = unknown_word[w]\n",
    "                else:\n",
    "                    unknown_word[w] = ft\n",
    "            feature[idx_w] = ft\n",
    "            count = count + (1-flag)\n",
    "        feature[idx_w] = feature[idx_w] # + 1e-5 # avoid divided by 0    \n",
    "        feature = np.mean(feature, axis=0) # equal to divided by len(word_split) or count (not recommend)\n",
    "              \n",
    "    embedding_weight[idx] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset Pytorch datastructure\n",
    "datasetTrain = EmbeddingDataset(dt_train, col_name='preprocess', list_vocab=list_vocab)\n",
    "datasetVal = EmbeddingDataset(dt_val, col_name='preprocess', list_vocab=list_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/49\n",
      "Total iteration: 9\n",
      "Epoch 1/50 [16122020-010000] [SAVE]\n",
      "AccVal: 0.5490333100395993\n",
      "AUCVal: 0.6901888339757589\n",
      "Precision: 0.7853403091430664\n",
      "Recall: 0.07334963232278824\n",
      "F1Val: 0.13416815230449147\n",
      "LossVal: 0.6795703371365865\n",
      "LossTrain: 0.6858542097939385\n",
      "----------\n",
      "\n",
      "Training 1/49\n",
      "Total iteration: 9\n",
      "Epoch 2/50 [16122020-010006] [SAVE]\n",
      "AccVal: 0.6361518751455858\n",
      "AUCVal: 0.7355047464086523\n",
      "Precision: 0.7098175287246704\n",
      "Recall: 0.3995110094547272\n",
      "F1Val: 0.5112640940677248\n",
      "LossVal: 0.6651212175687155\n",
      "LossTrain: 0.6716833975580003\n",
      "----------\n",
      "\n",
      "Training 2/49\n",
      "Total iteration: 9\n",
      "Epoch 3/50 [16122020-010012] [SAVE]\n",
      "AccVal: 0.6727230375029117\n",
      "AUCVal: 0.7538511820341254\n",
      "Precision: 0.6939393877983093\n",
      "Recall: 0.5599021911621094\n",
      "F1Val: 0.6197563899801919\n",
      "LossVal: 0.6528047323226929\n",
      "LossTrain: 0.6584054430325826\n",
      "----------\n",
      "\n",
      "Training 3/49\n",
      "Total iteration: 9\n",
      "Epoch 4/50 [16122020-010018] [SAVE]\n",
      "AccVal: 0.7044025157232704\n",
      "AUCVal: 0.7834901330386588\n",
      "Precision: 0.7160356640815735\n",
      "Recall: 0.6288508772850037\n",
      "F1Val: 0.66961731220465\n",
      "LossVal: 0.6390542189280192\n",
      "LossTrain: 0.6433003743489584\n",
      "----------\n",
      "\n",
      "Training 4/49\n",
      "Total iteration: 9\n",
      "Epoch 5/50 [16122020-010024] [SAVE]\n",
      "AccVal: 0.7358490566037735\n",
      "AUCVal: 0.8158697978752099\n",
      "Precision: 0.7419012188911438\n",
      "Recall: 0.683129608631134\n",
      "F1Val: 0.7113034743048676\n",
      "LossVal: 0.6227052211761475\n",
      "LossTrain: 0.6252477698855929\n",
      "----------\n",
      "\n",
      "Training 5/49\n",
      "Total iteration: 9\n",
      "Epoch 6/50 [16122020-010030] [SAVE]\n",
      "AccVal: 0.7635686000465874\n",
      "AUCVal: 0.8432762836185819\n",
      "Precision: 0.7665631175041199\n",
      "Recall: 0.7242053747177124\n",
      "F1Val: 0.744782512978533\n",
      "LossVal: 0.6037424206733704\n",
      "LossTrain: 0.6036801404423184\n",
      "----------\n",
      "\n",
      "Training 6/49\n",
      "Total iteration: 9\n",
      "Epoch 7/50 [16122020-010036] [SAVE]\n",
      "AccVal: 0.785930584672723\n",
      "AUCVal: 0.8635930661538863\n",
      "Precision: 0.7823470234870911\n",
      "Recall: 0.7628361582756042\n",
      "F1Val: 0.7724684100618197\n",
      "LossVal: 0.582339366277059\n",
      "LossTrain: 0.5784198972913954\n",
      "----------\n",
      "\n",
      "Training 7/49\n",
      "Total iteration: 9\n",
      "Epoch 8/50 [16122020-010042] [SAVE]\n",
      "AccVal: 0.8017703237829024\n",
      "AUCVal: 0.8783718643684362\n",
      "Precision: 0.7935103178024292\n",
      "Recall: 0.7892420291900635\n",
      "F1Val: 0.7913704182409428\n",
      "LossVal: 0.5590019226074219\n",
      "LossTrain: 0.5497897267341614\n",
      "----------\n",
      "\n",
      "Training 8/49\n",
      "Total iteration: 9\n",
      "Epoch 9/50 [16122020-010048] [SAVE]\n",
      "AccVal: 0.812485441416259\n",
      "AUCVal: 0.8893876871807813\n",
      "Precision: 0.8006789684295654\n",
      "Recall: 0.8073349595069885\n",
      "F1Val: 0.8039932183243511\n",
      "LossVal: 0.5345930258433024\n",
      "LossTrain: 0.5186023910840353\n",
      "----------\n",
      "\n",
      "Training 9/49\n",
      "Total iteration: 9\n",
      "Epoch 10/50 [16122020-010054] [SAVE]\n",
      "AccVal: 0.8199394362916376\n",
      "AUCVal: 0.8975783962272359\n",
      "Precision: 0.8054755330085754\n",
      "Recall: 0.8200489282608032\n",
      "F1Val: 0.8126968730423377\n",
      "LossVal: 0.5101729234059652\n",
      "LossTrain: 0.4860130747159322\n",
      "----------\n",
      "\n",
      "Training 10/49\n",
      "Total iteration: 9\n",
      "Epoch 11/50 [16122020-010100] [SAVE]\n",
      "AccVal: 0.8259958071278826\n",
      "AUCVal: 0.9037398089255105\n",
      "Precision: 0.8120192289352417\n",
      "Recall: 0.8259168863296509\n",
      "F1Val: 0.8189090977990156\n",
      "LossVal: 0.486778865257899\n",
      "LossTrain: 0.453295714325375\n",
      "----------\n",
      "\n",
      "Training 11/49\n",
      "Total iteration: 9\n",
      "Epoch 12/50 [16122020-010106] [SAVE]\n",
      "AccVal: 0.831819240624272\n",
      "AUCVal: 0.9083573336581716\n",
      "Precision: 0.8184881806373596\n",
      "Recall: 0.8312958478927612\n",
      "F1Val: 0.8248422699753389\n",
      "LossVal: 0.465233971675237\n",
      "LossTrain: 0.4216062327226003\n",
      "----------\n",
      "\n",
      "Training 12/49\n",
      "Total iteration: 9\n",
      "Epoch 13/50 [16122020-010112] [SAVE]\n",
      "AccVal: 0.8367109247612392\n",
      "AUCVal: 0.9119627117611743\n",
      "Precision: 0.8243243098258972\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.8297304066751611\n",
      "LossVal: 0.4460473656654358\n",
      "LossTrain: 0.39180657929844326\n",
      "----------\n",
      "\n",
      "Training 13/49\n",
      "Total iteration: 9\n",
      "Epoch 14/50 [16122020-010119] [SAVE]\n",
      "AccVal: 0.8381085488003727\n",
      "AUCVal: 0.9147893482062839\n",
      "Precision: 0.8286270499229431\n",
      "Recall: 0.8322738409042358\n",
      "F1Val: 0.8304464716401994\n",
      "LossVal: 0.4294138451417287\n",
      "LossTrain: 0.36439694960912067\n",
      "----------\n",
      "\n",
      "Training 14/49\n",
      "Total iteration: 9\n",
      "Epoch 15/50 [16122020-010125] [SAVE]\n",
      "AccVal: 0.8406708595387841\n",
      "AUCVal: 0.9171088237085505\n",
      "Precision: 0.8324376940727234\n",
      "Recall: 0.8332518339157104\n",
      "F1Val: 0.832844594832779\n",
      "LossVal: 0.4152819712956746\n",
      "LossTrain: 0.33955061435699463\n",
      "----------\n",
      "\n",
      "Training 15/49\n",
      "Total iteration: 9\n",
      "Epoch 16/50 [16122020-010131] [SAVE]\n",
      "AccVal: 0.8404379221989284\n",
      "AUCVal: 0.9189632294721091\n",
      "Precision: 0.831384003162384\n",
      "Recall: 0.8342298269271851\n",
      "F1Val: 0.8328044540929181\n",
      "LossVal: 0.40344783663749695\n",
      "LossTrain: 0.3172058098846012\n",
      "----------\n",
      "\n",
      "Training 16/49\n",
      "Total iteration: 9\n",
      "Epoch 17/50 [16122020-010137] [SAVE]\n",
      "AccVal: 0.8416026088982064\n",
      "AUCVal: 0.9204997215672283\n",
      "Precision: 0.8324403166770935\n",
      "Recall: 0.835696816444397\n",
      "F1Val: 0.8340654177301785\n",
      "LossVal: 0.39363821347554523\n",
      "LossTrain: 0.2971649004353417\n",
      "----------\n",
      "\n",
      "Training 17/49\n",
      "Total iteration: 9\n",
      "Epoch 18/50 [16122020-010144] [SAVE]\n",
      "AccVal: 0.8430002329373398\n",
      "AUCVal: 0.9217901922056226\n",
      "Precision: 0.833901584148407\n",
      "Recall: 0.8371638059616089\n",
      "F1Val: 0.8355295406337813\n",
      "LossVal: 0.3855678935845693\n",
      "LossTrain: 0.2791722185081906\n",
      "----------\n",
      "\n",
      "Training 18/49\n",
      "Total iteration: 9\n",
      "Epoch 19/50 [16122020-010150] [SAVE]\n",
      "AccVal: 0.843466107617051\n",
      "AUCVal: 0.9228829320711048\n",
      "Precision: 0.8347147703170776\n",
      "Recall: 0.8371638059616089\n",
      "F1Val: 0.8359374944159015\n",
      "LossVal: 0.378971000512441\n",
      "LossTrain: 0.26296399864885545\n",
      "----------\n",
      "\n",
      "Training 19/49\n",
      "Total iteration: 9\n",
      "Epoch 20/50 [16122020-010156] [SAVE]\n",
      "AccVal: 0.8420684835779175\n",
      "AUCVal: 0.9237459649000688\n",
      "Precision: 0.832927405834198\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.8345534586980461\n",
      "LossVal: 0.37361430128415424\n",
      "LossTrain: 0.24829511013295916\n",
      "----------\n",
      "\n",
      "Training 20/49\n",
      "Total iteration: 9\n",
      "Epoch 21/50 [16122020-010203] [SAVE]\n",
      "AccVal: 0.8446307943163289\n",
      "AUCVal: 0.9244640169147906\n",
      "Precision: 0.8360975384712219\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8371183908901271\n",
      "LossVal: 0.3693002164363861\n",
      "LossTrain: 0.23495028913021088\n",
      "----------\n",
      "\n",
      "Training 21/49\n",
      "Total iteration: 9\n",
      "Epoch 22/50 [16122020-010209] [SAVE]\n",
      "AccVal: 0.8455625436757512\n",
      "AUCVal: 0.9250380669804836\n",
      "Precision: 0.83740234375\n",
      "Recall: 0.8386307954788208\n",
      "F1Val: 0.8380161194163759\n",
      "LossVal: 0.36586447556813556\n",
      "LossTrain: 0.22274651295608944\n",
      "----------\n",
      "\n",
      "Training 22/49\n",
      "Total iteration: 9\n",
      "Epoch 23/50 [16122020-010215] [SAVE]\n",
      "AccVal: 0.8469601677148847\n",
      "AUCVal: 0.9254929130158619\n",
      "Precision: 0.8378773331642151\n",
      "Recall: 0.8415647745132446\n",
      "F1Val: 0.8397169758994832\n",
      "LossVal: 0.36317214369773865\n",
      "LossTrain: 0.2115308576160007\n",
      "----------\n",
      "\n",
      "Training 23/49\n",
      "Total iteration: 9\n",
      "Epoch 24/50 [16122020-010222] [SAVE]\n",
      "AccVal: 0.8488236664337293\n",
      "AUCVal: 0.9258374735706393\n",
      "Precision: 0.8391642570495605\n",
      "Recall: 0.8444987535476685\n",
      "F1Val: 0.8418230544231396\n",
      "LossVal: 0.36111273368199664\n",
      "LossTrain: 0.20117654899756113\n",
      "----------\n",
      "\n",
      "Training 24/49\n",
      "Total iteration: 9\n",
      "Epoch 25/50 [16122020-010228] [SAVE]\n",
      "AccVal: 0.8499883531330072\n",
      "AUCVal: 0.9260960027495238\n",
      "Precision: 0.8405444622039795\n",
      "Recall: 0.8454767465591431\n",
      "F1Val: 0.8430033899322905\n",
      "LossVal: 0.35959606369336444\n",
      "LossTrain: 0.19157871769534218\n",
      "----------\n",
      "\n",
      "Training 25/49\n",
      "Total iteration: 9\n",
      "Epoch 26/50 [16122020-010234] [SAVE]\n",
      "AccVal: 0.8499883531330072\n",
      "AUCVal: 0.9262666515848916\n",
      "Precision: 0.83988356590271\n",
      "Recall: 0.8464547395706177\n",
      "F1Val: 0.8431563497530532\n",
      "LossVal: 0.3585481643676758\n",
      "LossTrain: 0.18265037569734785\n",
      "----------\n",
      "\n",
      "Training 26/49\n",
      "Total iteration: 9\n",
      "Epoch 27/50 [16122020-010241] [SAVE]\n",
      "AccVal: 0.8490566037735849\n",
      "AUCVal: 0.9263778071679036\n",
      "Precision: 0.8402338027954102\n",
      "Recall: 0.8435207605361938\n",
      "F1Val: 0.8418740733326444\n",
      "LossVal: 0.35790832837422687\n",
      "LossTrain: 0.1743190735578537\n",
      "----------\n",
      "\n",
      "Training 27/49\n",
      "Total iteration: 9\n",
      "Epoch 28/50 [16122020-010247] [SAVE]\n",
      "AccVal: 0.8495224784532961\n",
      "AUCVal: 0.9264115236363322\n",
      "Precision: 0.8417195677757263\n",
      "Recall: 0.8425427675247192\n",
      "F1Val: 0.8421309962790602\n",
      "LossVal: 0.35762638847033185\n",
      "LossTrain: 0.166523992187447\n",
      "----------\n",
      "\n",
      "Training 28/49\n",
      "Total iteration: 9\n",
      "Epoch 29/50 [16122020-010253]\n",
      "AccVal: 0.8485907290938738\n",
      "AUCVal: 0.9263812875775479\n",
      "Precision: 0.8404099345207214\n",
      "Recall: 0.8420537710189819\n",
      "F1Val: 0.8412310795240856\n",
      "LossVal: 0.3576606810092926\n",
      "LossTrain: 0.1592136820157369\n",
      "----------\n",
      "\n",
      "Training 29/49\n",
      "Total iteration: 9\n",
      "Epoch 30/50 [16122020-010300]\n",
      "AccVal: 0.847891917074307\n",
      "AUCVal: 0.9262907969267982\n",
      "Precision: 0.8395121693611145\n",
      "Recall: 0.8415647745132446\n",
      "F1Val: 0.8405371890132279\n",
      "LossVal: 0.3579762776692708\n",
      "LossTrain: 0.15234417137172487\n",
      "----------\n",
      "\n",
      "Training 30/49\n",
      "Total iteration: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [16122020-010306]\n",
      "AccVal: 0.8490566037735849\n",
      "AUCVal: 0.9261759434085393\n",
      "Precision: 0.8408979773521423\n",
      "Recall: 0.8425427675247192\n",
      "F1Val: 0.8417195987272311\n",
      "LossVal: 0.35854379336039227\n",
      "LossTrain: 0.1458775583240721\n",
      "----------\n",
      "\n",
      "Training 31/49\n",
      "Total iteration: 9\n",
      "Epoch 32/50 [16122020-010312] [SAVE]\n",
      "AccVal: 0.8502212904728628\n",
      "AUCVal: 0.9260062734383837\n",
      "Precision: 0.8426197171211243\n",
      "Recall: 0.8430317640304565\n",
      "F1Val: 0.8428256604123323\n",
      "LossVal: 0.3593381444613139\n",
      "LossTrain: 0.13978082769446903\n",
      "----------\n",
      "\n",
      "Training 32/49\n",
      "Total iteration: 9\n",
      "Epoch 33/50 [16122020-010318]\n",
      "AccVal: 0.8483577917540182\n",
      "AUCVal: 0.9257852674259761\n",
      "Precision: 0.84033203125\n",
      "Recall: 0.8415647745132446\n",
      "F1Val: 0.8409479511131346\n",
      "LossVal: 0.36033787329991657\n",
      "LossTrain: 0.13402495864364836\n",
      "----------\n",
      "\n",
      "Training 33/49\n",
      "Total iteration: 9\n",
      "Epoch 34/50 [16122020-010325]\n",
      "AccVal: 0.8483577917540182\n",
      "AUCVal: 0.9255475119421557\n",
      "Precision: 0.8399999737739563\n",
      "Recall: 0.8420537710189819\n",
      "F1Val: 0.8410255887450995\n",
      "LossVal: 0.3615242838859558\n",
      "LossTrain: 0.12858425743050045\n",
      "----------\n",
      "\n",
      "Training 34/49\n",
      "Total iteration: 9\n",
      "Epoch 35/50 [16122020-010331]\n",
      "AccVal: 0.8467272303750292\n",
      "AUCVal: 0.9253125842911711\n",
      "Precision: 0.8381277322769165\n",
      "Recall: 0.84058678150177\n",
      "F1Val: 0.8393554558317362\n",
      "LossVal: 0.36288108428319293\n",
      "LossTrain: 0.12343577129973306\n",
      "----------\n",
      "\n",
      "Training 35/49\n",
      "Total iteration: 9\n",
      "Epoch 36/50 [16122020-010337]\n",
      "AccVal: 0.8464942930351735\n",
      "AUCVal: 0.9250435051205526\n",
      "Precision: 0.8377193212509155\n",
      "Recall: 0.84058678150177\n",
      "F1Val: 0.839150601784973\n",
      "LossVal: 0.36439387996991474\n",
      "LossTrain: 0.11855891760852602\n",
      "----------\n",
      "\n",
      "Training 36/49\n",
      "Total iteration: 9\n",
      "Epoch 37/50 [16122020-010343]\n",
      "AccVal: 0.8464942930351735\n",
      "AUCVal: 0.9247572414273161\n",
      "Precision: 0.8377193212509155\n",
      "Recall: 0.84058678150177\n",
      "F1Val: 0.839150601784973\n",
      "LossVal: 0.3660498758157094\n",
      "LossTrain: 0.11393508149517907\n",
      "----------\n",
      "\n",
      "Training 37/49\n",
      "Total iteration: 9\n",
      "Epoch 38/50 [16122020-010350]\n",
      "AccVal: 0.8455625436757512\n",
      "AUCVal: 0.9244618416587632\n",
      "Precision: 0.8370731472969055\n",
      "Recall: 0.8391197919845581\n",
      "F1Val: 0.8380951903538701\n",
      "LossVal: 0.3678375581900279\n",
      "LossTrain: 0.10954741305775112\n",
      "----------\n",
      "\n",
      "Training 38/49\n",
      "Total iteration: 9\n",
      "Epoch 39/50 [16122020-010356]\n",
      "AccVal: 0.8462613556953179\n",
      "AUCVal: 0.9241138006943417\n",
      "Precision: 0.8379697203636169\n",
      "Recall: 0.8396087884902954\n",
      "F1Val: 0.838788483508358\n",
      "LossVal: 0.36974653601646423\n",
      "LossTrain: 0.10538054009278615\n",
      "----------\n",
      "\n",
      "Training 39/49\n",
      "Total iteration: 9\n",
      "Epoch 40/50 [16122020-010402]\n",
      "AccVal: 0.8457954810156068\n",
      "AUCVal: 0.9237805514709082\n",
      "Precision: 0.837481677532196\n",
      "Recall: 0.8391197919845581\n",
      "F1Val: 0.8382999643052125\n",
      "LossVal: 0.37176740169525146\n",
      "LossTrain: 0.10142042322291268\n",
      "----------\n",
      "\n",
      "Training 40/49\n",
      "Total iteration: 9\n",
      "Epoch 41/50 [16122020-010409]\n",
      "AccVal: 0.8448637316561844\n",
      "AUCVal: 0.9234134770162448\n",
      "Precision: 0.8361774682998657\n",
      "Recall: 0.8386307954788208\n",
      "F1Val: 0.8374023350226878\n",
      "LossVal: 0.37389157215754193\n",
      "LossTrain: 0.09765419239799182\n",
      "----------\n",
      "\n",
      "Training 41/49\n",
      "Total iteration: 9\n",
      "Epoch 42/50 [16122020-010415]\n",
      "AccVal: 0.8448637316561844\n",
      "AUCVal: 0.9230511881248423\n",
      "Precision: 0.8365055918693542\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8373229258989214\n",
      "LossVal: 0.37611109018325806\n",
      "LossTrain: 0.09407001071506077\n",
      "----------\n",
      "\n",
      "Training 42/49\n",
      "Total iteration: 9\n",
      "Epoch 43/50 [16122020-010421]\n",
      "AccVal: 0.8443978569764733\n",
      "AUCVal: 0.9227077151980789\n",
      "Precision: 0.8370044231414795\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.8365949177928318\n",
      "LossVal: 0.37841880321502686\n",
      "LossTrain: 0.09065694610277812\n",
      "----------\n",
      "\n",
      "Training 43/49\n",
      "Total iteration: 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ff9b2425ddca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            dropout=0.8, batchnorm=True, checkpoint=None, model_name='EMB_UNK_Raw')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/embedding_pytorch.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, numb_epoch)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mtimestampSTART\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampDate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestampTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mlossTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderVal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mmetricsVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/embedding_pytorch.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mnumb_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total iteration: {numb_iter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatchID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mbatch_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mbatch_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_offset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/embedding_pytorch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Declare the model and Train\n",
    "model_emb = ModelEmbedding(vocab_size=len(list_vocab), datasetTrain=datasetTrain, datasetVal=datasetVal,\n",
    "                           init_weight=embedding_weight, \n",
    "                           batch_size=2048, optimizer_choice='adam', init_lr=0.001, layers=[300,1], weight_decay=1e-4, \n",
    "                           dropout=0.8, batchnorm=True, checkpoint=None, model_name='EMB_UNK_Raw')\n",
    "\n",
    "model_emb.train(numb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL AT Checkpoint/EMB_UNK_Raw-16122020-005954.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9622619532933434,\n",
       " 'precision': 0.9640217,\n",
       " 'recall': 0.9564792,\n",
       " 'f1': 0.960235626235471,\n",
       " 'tp': 7824,\n",
       " 'tn': 8699,\n",
       " 'fp': 292,\n",
       " 'fn': 356,\n",
       " 'auc': 0.9928722528559528}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model and evaluate on train / validate set\n",
    "dataloader = make_EmbeddingDataLoader(datasetTrain, batch_size=2048)\n",
    "model_emb = ModelEmbedding(vocab_size=len(list_vocab), datasetTrain=datasetTrain, datasetVal=datasetVal,\n",
    "                           init_weight=embedding_weight, \n",
    "                           batch_size=2048, optimizer_choice='adam', init_lr=0.001, layers=[300,1], weight_decay=1e-4, \n",
    "                           dropout=0.8, batchnorm=True, checkpoint='Checkpoint/EMB_UNK_Raw-16122020-005954.pth.tar',\n",
    "                           model_name='EMB_UNK_Raw')\n",
    "model_emb.load_trained_model()\n",
    "model_emb.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discard UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train = data_train.copy()\n",
    "dt_val = data_val.copy()\n",
    "# Count the frequency of words in the training corpus\n",
    "all_string = dt_train.headline_s1.tolist()\n",
    "all_string_in_one = ' '.join(all_string)\n",
    "list_common_words, count_words = most_common_words(all_string_in_one, numb_words=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words remaining: 11476 / 23115\n",
      "Total discard (Unknown Token): 11639\n"
     ]
    }
   ],
   "source": [
    "cwdf = pd.DataFrame(np.asarray(count_words),\n",
    "                    columns=['count_words'])\n",
    "cwdf['words'] = list_common_words\n",
    "\n",
    "# Find the index of words appeared only once in the corpus\n",
    "# Only use words appearing more than once in the training corpus\n",
    "s = cwdf.index[cwdf.iloc[:,0] == 1].tolist()[0]\n",
    "common_vocab = cwdf.words[0:s].tolist()\n",
    "print(f\"Number of unique words remaining: {s} / {len(cwdf)}\")\n",
    "print(f\"Total discard (Unknown Token): {cwdf.iloc[s:,0].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unknown words in the dataset\n",
    "dt_train['preprocess'] = dt_train.headline_s1.apply(lambda row: remove_unknown_token(row, common_vocab))\n",
    "dt_val['preprocess'] = dt_val.headline_s1.apply(lambda row: remove_unknown_token(row, common_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary: 11476\n"
     ]
    }
   ],
   "source": [
    "list_vocab = common_vocab\n",
    "print(f\"Total Vocabulary: {len(list_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11476/11476 [00:00<00:00, 436366.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# initialise weight by Glove model\n",
    "embedding_weight = np.zeros((len(list_vocab), 300)) # index is use when words is not indictionary\n",
    "unknown_word = dict()\n",
    "for idx in tqdm(range(len(list_vocab))):\n",
    "    word = list_vocab[idx]\n",
    "    word_split = word.split()\n",
    "    if len(word_split) == 1:\n",
    "        feature, flag = get_word_features(word_split[0], embeddings_dict)\n",
    "        if flag == 0: # not exist word\n",
    "            unknown_word[word_split[0]] = feature\n",
    "    else:\n",
    "        feature = np.zeros((len(word_split), 300))\n",
    "        count = 0\n",
    "        for idx_w, w in enumerate(word_split):\n",
    "            ft, flag = get_word_features(w, embeddings_dict)\n",
    "            if flag == 0:\n",
    "                if w in list(unknown_word.keys()):\n",
    "                    ft = unknown_word[w]\n",
    "                else:\n",
    "                    unknown_word[w] = ft\n",
    "            feature[idx_w] = ft\n",
    "            count = count + (1-flag)\n",
    "        feature[idx_w] = feature[idx_w] # + 1e-5 # avoid divided by 0    \n",
    "        feature = np.mean(feature, axis=0) # equal to divided by len(word_split) or count (not recommend)\n",
    "              \n",
    "    embedding_weight[idx] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset Pytorch datastructure\n",
    "datasetTrain = EmbeddingDataset(dt_train, col_name='preprocess', list_vocab=list_vocab)\n",
    "datasetVal = EmbeddingDataset(dt_val, col_name='preprocess', list_vocab=list_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/49\n",
      "Total iteration: 9\n",
      "Epoch 1/50 [16122020-015801] [SAVE]\n",
      "AccVal: 0.5709294199860238\n",
      "AUCVal: 0.6686292189090657\n",
      "Precision: 0.6661211252212524\n",
      "Recall: 0.19902200996875763\n",
      "F1Val: 0.3064759162158546\n",
      "LossVal: 0.6795707941055298\n",
      "LossTrain: 0.6873425311512418\n",
      "----------\n",
      "\n",
      "Training 1/49\n",
      "Total iteration: 9\n",
      "Epoch 2/50 [16122020-015805] [SAVE]\n",
      "AccVal: 0.5942231539715817\n",
      "AUCVal: 0.7610997876950116\n",
      "Precision: 0.8110883235931396\n",
      "Recall: 0.19315403699874878\n",
      "F1Val: 0.31200630627394255\n",
      "LossVal: 0.6661047538121542\n",
      "LossTrain: 0.6713760428958468\n",
      "----------\n",
      "\n",
      "Training 2/49\n",
      "Total iteration: 9\n",
      "Epoch 3/50 [16122020-015809] [SAVE]\n",
      "AccVal: 0.6561844863731656\n",
      "AUCVal: 0.8084440176108728\n",
      "Precision: 0.836686372756958\n",
      "Recall: 0.3457212746143341\n",
      "F1Val: 0.4892733689194232\n",
      "LossVal: 0.6512021025021871\n",
      "LossTrain: 0.6556229525142245\n",
      "----------\n",
      "\n",
      "Training 3/49\n",
      "Total iteration: 9\n",
      "Epoch 4/50 [16122020-015813] [SAVE]\n",
      "AccVal: 0.7216398788725833\n",
      "AUCVal: 0.8365469115714919\n",
      "Precision: 0.8269230723381042\n",
      "Recall: 0.5256723761558533\n",
      "F1Val: 0.6427503756841331\n",
      "LossVal: 0.6338359514872233\n",
      "LossTrain: 0.6372295684284635\n",
      "----------\n",
      "\n",
      "Training 4/49\n",
      "Total iteration: 9\n",
      "Epoch 5/50 [16122020-015818] [SAVE]\n",
      "AccVal: 0.7596086652690426\n",
      "AUCVal: 0.8558094562730034\n",
      "Precision: 0.8282566666603088\n",
      "Recall: 0.6249388456344604\n",
      "F1Val: 0.7123745422306681\n",
      "LossVal: 0.6134687066078186\n",
      "LossTrain: 0.6151516834894816\n",
      "----------\n",
      "\n",
      "Training 5/49\n",
      "Total iteration: 9\n",
      "Epoch 6/50 [16122020-015822] [SAVE]\n",
      "AccVal: 0.7843000232937339\n",
      "AUCVal: 0.8700757641674425\n",
      "Precision: 0.8296994566917419\n",
      "Recall: 0.6885085701942444\n",
      "F1Val: 0.7525387516090013\n",
      "LossVal: 0.590120275815328\n",
      "LossTrain: 0.5888508624500699\n",
      "----------\n",
      "\n",
      "Training 6/49\n",
      "Total iteration: 9\n",
      "Epoch 7/50 [16122020-015826] [SAVE]\n",
      "AccVal: 0.7987421383647799\n",
      "AUCVal: 0.8808094562730033\n",
      "Precision: 0.8293362855911255\n",
      "Recall: 0.7271393537521362\n",
      "F1Val: 0.7748827357200087\n",
      "LossVal: 0.5645252267519633\n",
      "LossTrain: 0.5586079955101013\n",
      "----------\n",
      "\n",
      "Training 7/49\n",
      "Total iteration: 9\n",
      "Epoch 8/50 [16122020-015830] [SAVE]\n",
      "AccVal: 0.8054973212205917\n",
      "AUCVal: 0.8890340993134893\n",
      "Precision: 0.8284473419189453\n",
      "Recall: 0.7462102770805359\n",
      "F1Val: 0.7851813495209661\n",
      "LossVal: 0.5378862222035726\n",
      "LossTrain: 0.5254276427957747\n",
      "----------\n",
      "\n",
      "Training 8/49\n",
      "Total iteration: 9\n",
      "Epoch 9/50 [16122020-015834] [SAVE]\n",
      "AccVal: 0.8131842534358258\n",
      "AUCVal: 0.8955443143157951\n",
      "Precision: 0.8272775411605835\n",
      "Recall: 0.7682151794433594\n",
      "F1Val: 0.7966531674197451\n",
      "LossVal: 0.5116014877955118\n",
      "LossTrain: 0.49076026015811497\n",
      "----------\n",
      "\n",
      "Training 9/49\n",
      "Total iteration: 9\n",
      "Epoch 10/50 [16122020-015839] [SAVE]\n",
      "AccVal: 0.8187747495923596\n",
      "AUCVal: 0.9008687972574373\n",
      "Precision: 0.8284084796905518\n",
      "Recall: 0.7814180850982666\n",
      "F1Val: 0.8042274640484346\n",
      "LossVal: 0.486936092376709\n",
      "LossTrain: 0.45617274443308514\n",
      "----------\n",
      "\n",
      "Training 10/49\n",
      "Total iteration: 9\n",
      "Epoch 11/50 [16122020-015843] [SAVE]\n",
      "AccVal: 0.8245981830887491\n",
      "AUCVal: 0.9051538341062743\n",
      "Precision: 0.8326467275619507\n",
      "Recall: 0.7907090187072754\n",
      "F1Val: 0.8111361645694937\n",
      "LossVal: 0.46479960282643634\n",
      "LossTrain: 0.4230274458726247\n",
      "----------\n",
      "\n",
      "Training 11/49\n",
      "Total iteration: 9\n",
      "Epoch 12/50 [16122020-015847] [SAVE]\n",
      "AccVal: 0.8292569298858607\n",
      "AUCVal: 0.9087514900503789\n",
      "Precision: 0.8374485373497009\n",
      "Recall: 0.7960880398750305\n",
      "F1Val: 0.8162446729262516\n",
      "LossVal: 0.44567522406578064\n",
      "LossTrain: 0.3922855920261807\n",
      "----------\n",
      "\n",
      "Training 12/49\n",
      "Total iteration: 9\n",
      "Epoch 13/50 [16122020-015851] [SAVE]\n",
      "AccVal: 0.8332168646634055\n",
      "AUCVal: 0.9116236981092674\n",
      "Precision: 0.8427024483680725\n",
      "Recall: 0.7990220189094543\n",
      "F1Val: 0.8202811434632441\n",
      "LossVal: 0.42966175079345703\n",
      "LossTrain: 0.3644501070181529\n",
      "----------\n",
      "\n",
      "Training 13/49\n",
      "Total iteration: 9\n",
      "Epoch 14/50 [16122020-015856] [SAVE]\n",
      "AccVal: 0.8343815513626834\n",
      "AUCVal: 0.913907281887078\n",
      "Precision: 0.8420512676239014\n",
      "Recall: 0.8029339909553528\n",
      "F1Val: 0.8220275602768008\n",
      "LossVal: 0.416580597559611\n",
      "LossTrain: 0.33962684207492405\n",
      "----------\n",
      "\n",
      "Training 14/49\n",
      "Total iteration: 9\n",
      "Epoch 15/50 [16122020-015900] [SAVE]\n",
      "AccVal: 0.8376426741206615\n",
      "AUCVal: 0.9157706062003497\n",
      "Precision: 0.8442288041114807\n",
      "Recall: 0.8083129525184631\n",
      "F1Val: 0.8258805860907432\n",
      "LossVal: 0.4060986638069153\n",
      "LossTrain: 0.31765082478523254\n",
      "----------\n",
      "\n",
      "Training 15/49\n",
      "Total iteration: 9\n",
      "Epoch 16/50 [16122020-015904] [SAVE]\n",
      "AccVal: 0.8397391101793618\n",
      "AUCVal: 0.9173248266320946\n",
      "Precision: 0.8428499102592468\n",
      "Recall: 0.8156479001045227\n",
      "F1Val: 0.8290258269987741\n",
      "LossVal: 0.3978324731190999\n",
      "LossTrain: 0.29821791913774276\n",
      "----------\n",
      "\n",
      "Training 16/49\n",
      "Total iteration: 9\n",
      "Epoch 17/50 [16122020-015908] [SAVE]\n",
      "AccVal: 0.8416026088982064\n",
      "AUCVal: 0.9185721184383402\n",
      "Precision: 0.8441755175590515\n",
      "Recall: 0.8185818791389465\n",
      "F1Val: 0.8311817260399659\n",
      "LossVal: 0.39141486088434857\n",
      "LossTrain: 0.2809840208954281\n",
      "----------\n",
      "\n",
      "Training 17/49\n",
      "Total iteration: 9\n",
      "Epoch 18/50 [16122020-015912] [SAVE]\n",
      "AccVal: 0.8441649196366178\n",
      "AUCVal: 0.9195324939745408\n",
      "Precision: 0.8450350761413574\n",
      "Recall: 0.8239609003067017\n",
      "F1Val: 0.8343649379071393\n",
      "LossVal: 0.38652535279591876\n",
      "LossTrain: 0.265621585978402\n",
      "----------\n",
      "\n",
      "Training 18/49\n",
      "Total iteration: 9\n",
      "Epoch 19/50 [16122020-015917] [SAVE]\n",
      "AccVal: 0.8443978569764733\n",
      "AUCVal: 0.9203399490119987\n",
      "Precision: 0.8444222211837769\n",
      "Recall: 0.8254278898239136\n",
      "F1Val: 0.834817026459373\n",
      "LossVal: 0.38289675116539\n",
      "LossTrain: 0.25184302363130784\n",
      "----------\n",
      "\n",
      "Training 19/49\n",
      "Total iteration: 9\n",
      "Epoch 20/50 [16122020-015921] [SAVE]\n",
      "AccVal: 0.8453296063358956\n",
      "AUCVal: 0.9209344464843512\n",
      "Precision: 0.8454226851463318\n",
      "Recall: 0.8264058828353882\n",
      "F1Val: 0.8358061571346741\n",
      "LossVal: 0.380311518907547\n",
      "LossTrain: 0.23940568334526485\n",
      "----------\n",
      "\n",
      "Training 20/49\n",
      "Total iteration: 9\n",
      "Epoch 21/50 [16122020-015925] [SAVE]\n",
      "AccVal: 0.8467272303750292\n",
      "AUCVal: 0.9213799389188106\n",
      "Precision: 0.8465766906738281\n",
      "Recall: 0.8283618688583374\n",
      "F1Val: 0.8373702374066236\n",
      "LossVal: 0.37859464685122174\n",
      "LossTrain: 0.22810862958431244\n",
      "----------\n",
      "\n",
      "Training 21/49\n",
      "Total iteration: 9\n",
      "Epoch 22/50 [16122020-015939] [SAVE]\n",
      "AccVal: 0.8462613556953179\n",
      "AUCVal: 0.9217494061551045\n",
      "Precision: 0.84504234790802\n",
      "Recall: 0.829339861869812\n",
      "F1Val: 0.8371174753238322\n",
      "LossVal: 0.37760621309280396\n",
      "LossTrain: 0.2177868452337053\n",
      "----------\n",
      "\n",
      "Training 22/49\n",
      "Total iteration: 9\n",
      "Epoch 23/50 [16122020-015955] [SAVE]\n",
      "AccVal: 0.8483577917540182\n",
      "AUCVal: 0.9220057600779612\n",
      "Precision: 0.8485000133514404\n",
      "Recall: 0.8298288583755493\n",
      "F1Val: 0.8390605789752513\n",
      "LossVal: 0.37723444898923236\n",
      "LossTrain: 0.20830514861477745\n",
      "----------\n",
      "\n",
      "Training 23/49\n",
      "Total iteration: 9\n",
      "Epoch 24/50 [16122020-020011]\n",
      "AccVal: 0.8481248544141626\n",
      "AUCVal: 0.9221773877785413\n",
      "Precision: 0.8480759859085083\n",
      "Recall: 0.8298288583755493\n",
      "F1Val: 0.8388532038626555\n",
      "LossVal: 0.3773898283640544\n",
      "LossTrain: 0.19955268253882727\n",
      "----------\n",
      "\n",
      "Training 24/49\n",
      "Total iteration: 9\n",
      "Epoch 25/50 [16122020-020021]\n",
      "AccVal: 0.8476589797344515\n",
      "AUCVal: 0.9222359021656849\n",
      "Precision: 0.8468828201293945\n",
      "Recall: 0.8303178548812866\n",
      "F1Val: 0.8385185351075239\n",
      "LossVal: 0.378000150124232\n",
      "LossTrain: 0.19143818070491156\n",
      "----------\n",
      "\n",
      "Training 25/49\n",
      "Total iteration: 9\n",
      "Epoch 26/50 [16122020-020031]\n",
      "AccVal: 0.8471931050547403\n",
      "AUCVal: 0.922253304213906\n",
      "Precision: 0.8463840484619141\n",
      "Recall: 0.8298288583755493\n",
      "F1Val: 0.8380246993892532\n",
      "LossVal: 0.37900697191556293\n",
      "LossTrain: 0.18388606193992826\n",
      "----------\n",
      "\n",
      "Training 26/49\n",
      "Total iteration: 9\n",
      "Epoch 27/50 [16122020-020042]\n",
      "AccVal: 0.8474260423945958\n",
      "AUCVal: 0.9221453027521338\n",
      "Precision: 0.8464606404304504\n",
      "Recall: 0.8303178548812866\n",
      "F1Val: 0.8383115124450059\n",
      "LossVal: 0.380362610022227\n",
      "LossTrain: 0.17683330840534633\n",
      "----------\n",
      "\n",
      "Training 27/49\n",
      "Total iteration: 9\n",
      "Epoch 28/50 [16122020-020058]\n",
      "AccVal: 0.8457954810156068\n",
      "AUCVal: 0.9220198992421408\n",
      "Precision: 0.8442010879516602\n",
      "Recall: 0.829339861869812\n",
      "F1Val: 0.8367044902568561\n",
      "LossVal: 0.38202788432439166\n",
      "LossTrain: 0.1702269423339102\n",
      "----------\n",
      "\n",
      "Training 28/49\n",
      "Total iteration: 9\n",
      "Epoch 29/50 [16122020-020114]\n",
      "AccVal: 0.8439319822967621\n",
      "AUCVal: 0.9218500117463826\n",
      "Precision: 0.8428927659988403\n",
      "Recall: 0.8264058828353882\n",
      "F1Val: 0.8345679077944401\n",
      "LossVal: 0.3839704593022664\n",
      "LossTrain: 0.1640220491422547\n",
      "----------\n",
      "\n",
      "Training 29/49\n",
      "Total iteration: 9\n",
      "Epoch 30/50 [16122020-020130]\n",
      "AccVal: 0.8430002329373398\n",
      "AUCVal: 0.9216353139764549\n",
      "Precision: 0.8422366380691528\n",
      "Recall: 0.8249388933181763\n",
      "F1Val: 0.8334980294997735\n",
      "LossVal: 0.3861633638540904\n",
      "LossTrain: 0.15818022771014106\n",
      "----------\n",
      "\n",
      "Training 30/49\n",
      "Total iteration: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [16122020-020145]\n",
      "AccVal: 0.8427672955974843\n",
      "AUCVal: 0.9213899450965379\n",
      "Precision: 0.8411354422569275\n",
      "Recall: 0.8259168863296509\n",
      "F1Val: 0.8334567288338386\n",
      "LossVal: 0.3885838786760966\n",
      "LossTrain: 0.15266832792096668\n",
      "----------\n",
      "\n",
      "Training 31/49\n",
      "Total iteration: 9\n",
      "Epoch 32/50 [16122020-020201]\n",
      "AccVal: 0.8420684835779175\n",
      "AUCVal: 0.9210983520260334\n",
      "Precision: 0.8408977389335632\n",
      "Recall: 0.824449896812439\n",
      "F1Val: 0.8325926239373141\n",
      "LossVal: 0.39121275146802265\n",
      "LossTrain: 0.14745755907562044\n",
      "----------\n",
      "\n",
      "Training 32/49\n",
      "Total iteration: 9\n",
      "Epoch 33/50 [16122020-020216]\n",
      "AccVal: 0.8416026088982064\n",
      "AUCVal: 0.9207887043304998\n",
      "Precision: 0.8403990268707275\n",
      "Recall: 0.8239609003067017\n",
      "F1Val: 0.832098787636169\n",
      "LossVal: 0.3940335313479106\n",
      "LossTrain: 0.14252269433604348\n",
      "----------\n",
      "\n",
      "Training 33/49\n",
      "Total iteration: 9\n",
      "Epoch 34/50 [16122020-020232]\n",
      "AccVal: 0.8427672955974843\n",
      "AUCVal: 0.920480470551384\n",
      "Precision: 0.8421578407287598\n",
      "Recall: 0.824449896812439\n",
      "F1Val: 0.8332097940610321\n",
      "LossVal: 0.3970317741235097\n",
      "LossTrain: 0.137841511103842\n",
      "----------\n",
      "\n",
      "Training 34/49\n",
      "Total iteration: 9\n",
      "Epoch 35/50 [16122020-020248]\n",
      "AccVal: 0.8427672955974843\n",
      "AUCVal: 0.9200939275552733\n",
      "Precision: 0.8428428173065186\n",
      "Recall: 0.8234719038009644\n",
      "F1Val: 0.833044767090668\n",
      "LossVal: 0.4001949727535248\n",
      "LossTrain: 0.13339432494507897\n",
      "----------\n",
      "\n",
      "Training 35/49\n",
      "Total iteration: 9\n",
      "Epoch 36/50 [16122020-020304]\n",
      "AccVal: 0.8427672955974843\n",
      "AUCVal: 0.9197306597986584\n",
      "Precision: 0.8424999713897705\n",
      "Recall: 0.8239609003067017\n",
      "F1Val: 0.8331273139680706\n",
      "LossVal: 0.4035119414329529\n",
      "LossTrain: 0.12916360878282124\n",
      "----------\n",
      "\n",
      "Training 36/49\n",
      "Total iteration: 9\n",
      "Epoch 37/50 [16122020-020319]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.9193425941233283\n",
      "Precision: 0.8420789837837219\n",
      "Recall: 0.8239609003067017\n",
      "F1Val: 0.8329213957126829\n",
      "LossVal: 0.40697261691093445\n",
      "LossTrain: 0.12513367707530657\n",
      "----------\n",
      "\n",
      "Training 37/49\n",
      "Total iteration: 9\n",
      "Epoch 38/50 [16122020-020335]\n",
      "AccVal: 0.8413696715583509\n",
      "AUCVal: 0.9189316882597082\n",
      "Precision: 0.8396414518356323\n",
      "Recall: 0.824449896812439\n",
      "F1Val: 0.8319763321739757\n",
      "LossVal: 0.4105679392814636\n",
      "LossTrain: 0.12129043953286277\n",
      "----------\n",
      "\n",
      "Training 38/49\n",
      "Total iteration: 9\n",
      "Epoch 39/50 [16122020-020350]\n",
      "AccVal: 0.8411367342184952\n",
      "AUCVal: 0.918548408147639\n",
      "Precision: 0.8395615220069885\n",
      "Recall: 0.8239609003067017\n",
      "F1Val: 0.8316880295335893\n",
      "LossVal: 0.41428957382837933\n",
      "LossTrain: 0.117621172633436\n",
      "----------\n",
      "\n",
      "Training 39/49\n",
      "Total iteration: 9\n",
      "Epoch 40/50 [16122020-020406]\n",
      "AccVal: 0.8397391101793618\n",
      "AUCVal: 0.9181272785806889\n",
      "Precision: 0.8373943567276001\n",
      "Recall: 0.8234719038009644\n",
      "F1Val: 0.8303747767712585\n",
      "LossVal: 0.41812973221143085\n",
      "LossTrain: 0.11411438220077091\n",
      "----------\n",
      "\n",
      "Training 40/49\n",
      "Total iteration: 9\n",
      "Epoch 41/50 [16122020-020421]\n",
      "AccVal: 0.839040298159795\n",
      "AUCVal: 0.9177057139625333\n",
      "Precision: 0.8358134627342224\n",
      "Recall: 0.8239609003067017\n",
      "F1Val: 0.8298448913411448\n",
      "LossVal: 0.4220811426639557\n",
      "LossTrain: 0.11075960761970943\n",
      "----------\n",
      "\n",
      "Training 41/49\n",
      "Total iteration: 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-3a329fbc4e1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            dropout=0.8, batchnorm=True, checkpoint=None, model_name='EMB_Raw')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/embedding_pytorch.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, numb_epoch)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mtimestampSTART\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampDate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestampTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mlossTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderVal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mmetricsVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/embedding_pytorch.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mnumb_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total iteration: {numb_iter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatchID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mbatch_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mbatch_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_offset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/embedding_pytorch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Declare and Train model\n",
    "model_emb = ModelEmbedding(vocab_size=len(list_vocab), datasetTrain=datasetTrain, datasetVal=datasetVal,\n",
    "                           init_weight=embedding_weight, \n",
    "                           batch_size=2048, optimizer_choice='adam', init_lr=0.001, layers=[300,1], weight_decay=1e-4, \n",
    "                           dropout=0.8, batchnorm=True, checkpoint=None, model_name='EMB_Raw')\n",
    "\n",
    "model_emb.train(numb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL AT Checkpoint/EMB_Raw-16122020-015756.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.933958418263351,\n",
       " 'precision': 0.9351532,\n",
       " 'recall': 0.9255501,\n",
       " 'f1': 0.9303268938167982,\n",
       " 'tp': 7571,\n",
       " 'tn': 8466,\n",
       " 'fp': 525,\n",
       " 'fn': 609,\n",
       " 'auc': 0.9819344405530224}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model and evaluate\n",
    "dataloader = make_EmbeddingDataLoader(datasetTrain, batch_size=2048)\n",
    "model_emb = ModelEmbedding(vocab_size=len(list_vocab), datasetTrain=datasetTrain, datasetVal=datasetVal,\n",
    "                           init_weight=embedding_weight, \n",
    "                           batch_size=2048, optimizer_choice='adam', init_lr=0.001, layers=[300,1], weight_decay=1e-4, \n",
    "                           dropout=0.8, batchnorm=True, checkpoint='Checkpoint/EMB_Raw-16122020-015756.pth.tar', \n",
    "                           model_name='EMB_Raw')\n",
    "model_emb.load_trained_model()\n",
    "model_emb.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding with UNK and Selected Vocab\n",
    "Using UNK token but only use 2457 selected words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train = data_train.copy()\n",
    "dt_val = data_val.copy()\n",
    "\n",
    "# Load list of selected words\n",
    "common_vocab = joblib.load('selected_vocab_s1.joblib')\n",
    "\n",
    "# Replace unknown words with UNK token\n",
    "dt_train['preprocess'] = dt_train.headline_s1.apply(lambda row: add_unknown_token(row, common_vocab))\n",
    "dt_val['preprocess'] = dt_val.headline_s1.apply(lambda row: add_unknown_token(row, common_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary: 2458\n"
     ]
    }
   ],
   "source": [
    "# Add unk token\n",
    "list_vocab = ['<unk>'] + common_vocab\n",
    "print(f\"Total Vocabulary: {len(list_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2457/2457 [00:00<00:00, 386447.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialise weight by Glove model\n",
    "embedding_weight = np.zeros((len(list_vocab), 300)) # index is use when words is not indictionary\n",
    "unknown_word = dict()\n",
    "embedding_weight[0] = np.random.uniform(-2.5, 2.5, 300)\n",
    "for idx in tqdm(range(1, len(list_vocab))):\n",
    "    word = list_vocab[idx]\n",
    "    word_split = word.split()\n",
    "    if len(word_split) == 1:\n",
    "        feature, flag = get_word_features(word_split[0], embeddings_dict)\n",
    "        if flag == 0: # not exist word\n",
    "            unknown_word[word_split[0]] = feature\n",
    "    else:\n",
    "        feature = np.zeros((len(word_split), 300))\n",
    "        count = 0\n",
    "        for idx_w, w in enumerate(word_split):\n",
    "            ft, flag = get_word_features(w, embeddings_dict)\n",
    "            if flag == 0:\n",
    "                if w in list(unknown_word.keys()):\n",
    "                    ft = unknown_word[w]\n",
    "                else:\n",
    "                    unknown_word[w] = ft\n",
    "            feature[idx_w] = ft\n",
    "            count = count + (1-flag)\n",
    "        feature[idx_w] = feature[idx_w] # + 1e-5 # avoid divided by 0    \n",
    "        feature = np.mean(feature, axis=0) # equal to divided by len(word_split) or count (not recommend)\n",
    "              \n",
    "    embedding_weight[idx] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset data structure of Pytorch\n",
    "datasetTrain = EmbeddingDataset(dt_train, col_name='preprocess', list_vocab=list_vocab)\n",
    "datasetVal = EmbeddingDataset(dt_val, col_name='preprocess', list_vocab=list_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/49\n",
      "Total iteration: 9\n",
      "Epoch 1/50 [16122020-020950] [SAVE]\n",
      "AccVal: 0.59958071278826\n",
      "AUCVal: 0.6392825135518451\n",
      "Precision: 0.5726381540298462\n",
      "Recall: 0.6283618807792664\n",
      "F1Val: 0.5992073187360426\n",
      "LossVal: 0.6808372537295023\n",
      "LossTrain: 0.6865804261631436\n",
      "----------\n",
      "\n",
      "Training 1/49\n",
      "Total iteration: 9\n",
      "Epoch 2/50 [16122020-020953] [SAVE]\n",
      "AccVal: 0.6245050081528069\n",
      "AUCVal: 0.6931211878638116\n",
      "Precision: 0.6638910174369812\n",
      "Recall: 0.42885085940361023\n",
      "F1Val: 0.5210933106476258\n",
      "LossVal: 0.6709955135981241\n",
      "LossTrain: 0.6756826506720649\n",
      "----------\n",
      "\n",
      "Training 2/49\n",
      "Total iteration: 9\n",
      "Epoch 3/50 [16122020-020955] [SAVE]\n",
      "AccVal: 0.6429070580013976\n",
      "AUCVal: 0.7224701772398612\n",
      "Precision: 0.6916167736053467\n",
      "Recall: 0.4518337547779083\n",
      "F1Val: 0.5465838776113282\n",
      "LossVal: 0.6614372134208679\n",
      "LossTrain: 0.6651503841082255\n",
      "----------\n",
      "\n",
      "Training 3/49\n",
      "Total iteration: 9\n",
      "Epoch 4/50 [16122020-020958] [SAVE]\n",
      "AccVal: 0.6655019799673888\n",
      "AUCVal: 0.737598321572449\n",
      "Precision: 0.6809269189834595\n",
      "Recall: 0.5603911876678467\n",
      "F1Val: 0.6148068618342295\n",
      "LossVal: 0.6511942545572916\n",
      "LossTrain: 0.6541846526993645\n",
      "----------\n",
      "\n",
      "Training 4/49\n",
      "Total iteration: 9\n",
      "Epoch 5/50 [16122020-021000] [SAVE]\n",
      "AccVal: 0.6820405310971349\n",
      "AUCVal: 0.760828642031167\n",
      "Precision: 0.6907968521118164\n",
      "Recall: 0.6019560098648071\n",
      "F1Val: 0.6433237611844754\n",
      "LossVal: 0.6399714748064677\n",
      "LossTrain: 0.6419888734817505\n",
      "----------\n",
      "\n",
      "Training 5/49\n",
      "Total iteration: 9\n",
      "Epoch 6/50 [16122020-021002] [SAVE]\n",
      "AccVal: 0.7039366410435592\n",
      "AUCVal: 0.7891393817052266\n",
      "Precision: 0.718397319316864\n",
      "Recall: 0.6224938631057739\n",
      "F1Val: 0.6670160088860364\n",
      "LossVal: 0.6271225810050964\n",
      "LossTrain: 0.6281983719931709\n",
      "----------\n",
      "\n",
      "Training 6/49\n",
      "Total iteration: 9\n",
      "Epoch 7/50 [16122020-021004] [SAVE]\n",
      "AccVal: 0.7228045655718611\n",
      "AUCVal: 0.8141386203656171\n",
      "Precision: 0.737368106842041\n",
      "Recall: 0.6493887305259705\n",
      "F1Val: 0.6905875714450228\n",
      "LossVal: 0.612634023030599\n",
      "LossTrain: 0.6124034325281779\n",
      "----------\n",
      "\n",
      "Training 7/49\n",
      "Total iteration: 9\n",
      "Epoch 8/50 [16122020-021007] [SAVE]\n",
      "AccVal: 0.7481947356161193\n",
      "AUCVal: 0.8349018742005934\n",
      "Precision: 0.7561105489730835\n",
      "Recall: 0.695843517780304\n",
      "F1Val: 0.7247262357357557\n",
      "LossVal: 0.5964938203493754\n",
      "LossTrain: 0.5944146116574606\n",
      "----------\n",
      "\n",
      "Training 8/49\n",
      "Total iteration: 9\n",
      "Epoch 9/50 [16122020-021009] [SAVE]\n",
      "AccVal: 0.7721872816212438\n",
      "AUCVal: 0.8525624516005534\n",
      "Precision: 0.774575412273407\n",
      "Recall: 0.7359412908554077\n",
      "F1Val: 0.7547643135442611\n",
      "LossVal: 0.5789039134979248\n",
      "LossTrain: 0.5743112564086914\n",
      "----------\n",
      "\n",
      "Training 9/49\n",
      "Total iteration: 9\n",
      "Epoch 10/50 [16122020-021012] [SAVE]\n",
      "AccVal: 0.7849988353133007\n",
      "AUCVal: 0.8672263962968441\n",
      "Precision: 0.7821931838989258\n",
      "Recall: 0.7603911757469177\n",
      "F1Val: 0.771138081447909\n",
      "LossVal: 0.5602647066116333\n",
      "LossTrain: 0.5524145563443502\n",
      "----------\n",
      "\n",
      "Training 10/49\n",
      "Total iteration: 9\n",
      "Epoch 11/50 [16122020-021015] [SAVE]\n",
      "AccVal: 0.7978103890053576\n",
      "AUCVal: 0.8785002044740666\n",
      "Precision: 0.790044367313385\n",
      "Recall: 0.7838630676269531\n",
      "F1Val: 0.7869416091802477\n",
      "LossVal: 0.5411427219708761\n",
      "LossTrain: 0.5292291111416287\n",
      "----------\n",
      "\n",
      "Training 11/49\n",
      "Total iteration: 9\n",
      "Epoch 12/50 [16122020-021017] [SAVE]\n",
      "AccVal: 0.8068949452597252\n",
      "AUCVal: 0.8866571970520931\n",
      "Precision: 0.795432448387146\n",
      "Recall: 0.8004890084266663\n",
      "F1Val: 0.7979526879351471\n",
      "LossVal: 0.5221633712450663\n",
      "LossTrain: 0.5053870909743838\n",
      "----------\n",
      "\n",
      "Training 12/49\n",
      "Total iteration: 9\n",
      "Epoch 13/50 [16122020-021020] [SAVE]\n",
      "AccVal: 0.8155136268343816\n",
      "AUCVal: 0.892746064961846\n",
      "Precision: 0.8013467788696289\n",
      "Recall: 0.8146699070930481\n",
      "F1Val: 0.807953452016523\n",
      "LossVal: 0.5039185484250387\n",
      "LossTrain: 0.481566846370697\n",
      "----------\n",
      "\n",
      "Training 13/49\n",
      "Total iteration: 9\n",
      "Epoch 14/50 [16122020-021023] [SAVE]\n",
      "AccVal: 0.8211041229909154\n",
      "AUCVal: 0.8971873939562687\n",
      "Precision: 0.8059415221214294\n",
      "Recall: 0.8224939107894897\n",
      "F1Val: 0.8141336220809475\n",
      "LossVal: 0.48689066370328266\n",
      "LossTrain: 0.45839567316903007\n",
      "----------\n",
      "\n",
      "Training 14/49\n",
      "Total iteration: 9\n",
      "Epoch 15/50 [16122020-021025] [SAVE]\n",
      "AccVal: 0.8222688096901933\n",
      "AUCVal: 0.9005281521635096\n",
      "Precision: 0.8066985607147217\n",
      "Recall: 0.824449896812439\n",
      "F1Val: 0.8154776373307773\n",
      "LossVal: 0.4714036782582601\n",
      "LossTrain: 0.43637104829152423\n",
      "----------\n",
      "\n",
      "Training 15/49\n",
      "Total iteration: 9\n",
      "Epoch 16/50 [16122020-021028] [SAVE]\n",
      "AccVal: 0.8255299324481714\n",
      "AUCVal: 0.9031151841571752\n",
      "Precision: 0.8094555735588074\n",
      "Recall: 0.8288508653640747\n",
      "F1Val: 0.8190384424886215\n",
      "LossVal: 0.4576156934102376\n",
      "LossTrain: 0.41582246290312874\n",
      "----------\n",
      "\n",
      "Training 16/49\n",
      "Total iteration: 9\n",
      "Epoch 17/50 [16122020-021030] [SAVE]\n",
      "AccVal: 0.827393431167016\n",
      "AUCVal: 0.9050530109893935\n",
      "Precision: 0.8110687136650085\n",
      "Recall: 0.8312958478927612\n",
      "F1Val: 0.8210577532863506\n",
      "LossVal: 0.44554610053698224\n",
      "LossTrain: 0.39691465430789524\n",
      "----------\n",
      "\n",
      "Training 17/49\n",
      "Total iteration: 9\n",
      "Epoch 18/50 [16122020-021032] [SAVE]\n",
      "AccVal: 0.8292569298858607\n",
      "AUCVal: 0.9067642849063334\n",
      "Precision: 0.8132760524749756\n",
      "Recall: 0.8327628374099731\n",
      "F1Val: 0.8229040968819162\n",
      "LossVal: 0.4351186255613963\n",
      "LossTrain: 0.37967918316523236\n",
      "----------\n",
      "\n",
      "Training 18/49\n",
      "Total iteration: 9\n",
      "Epoch 19/50 [16122020-021034] [SAVE]\n",
      "AccVal: 0.8306545539249942\n",
      "AUCVal: 0.9081967997633321\n",
      "Precision: 0.8147087097167969\n",
      "Recall: 0.8342298269271851\n",
      "F1Val: 0.8243537170116562\n",
      "LossVal: 0.4262022078037262\n",
      "LossTrain: 0.36405589514308506\n",
      "----------\n",
      "\n",
      "Training 19/49\n",
      "Total iteration: 9\n",
      "Epoch 20/50 [16122020-021036] [SAVE]\n",
      "AccVal: 0.8325180526438388\n",
      "AUCVal: 0.9094195111764655\n",
      "Precision: 0.816921591758728\n",
      "Recall: 0.835696816444397\n",
      "F1Val: 0.8262025524207366\n",
      "LossVal: 0.4186419149239858\n",
      "LossTrain: 0.34993118709988064\n",
      "----------\n",
      "\n",
      "Training 20/49\n",
      "Total iteration: 9\n",
      "Epoch 21/50 [16122020-021038] [SAVE]\n",
      "AccVal: 0.8343815513626834\n",
      "AUCVal: 0.9105047464086524\n",
      "Precision: 0.8188336491584778\n",
      "Recall: 0.8376528024673462\n",
      "F1Val: 0.8281362948891926\n",
      "LossVal: 0.4122792383035024\n",
      "LossTrain: 0.3371664385000865\n",
      "----------\n",
      "\n",
      "Training 21/49\n",
      "Total iteration: 9\n",
      "Epoch 22/50 [16122020-021040] [SAVE]\n",
      "AccVal: 0.8348474260423946\n",
      "AUCVal: 0.9114444570125904\n",
      "Precision: 0.8193116784095764\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8286197455767578\n",
      "LossVal: 0.4069634974002838\n",
      "LossTrain: 0.3256169623798794\n",
      "----------\n",
      "\n",
      "Training 22/49\n",
      "Total iteration: 9\n",
      "Epoch 23/50 [16122020-021042] [SAVE]\n",
      "AccVal: 0.8353133007221057\n",
      "AUCVal: 0.9122040564174403\n",
      "Precision: 0.8200957179069519\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8290205933063817\n",
      "LossVal: 0.40255768100420636\n",
      "LossTrain: 0.3151431481043498\n",
      "----------\n",
      "\n",
      "Training 23/49\n",
      "Total iteration: 9\n",
      "Epoch 24/50 [16122020-021044] [SAVE]\n",
      "AccVal: 0.8367109247612392\n",
      "AUCVal: 0.9128221554176927\n",
      "Precision: 0.8227665424346924\n",
      "Recall: 0.8376528024673462\n",
      "F1Val: 0.8301429420980997\n",
      "LossVal: 0.39894043405850727\n",
      "LossTrain: 0.3056165377298991\n",
      "----------\n",
      "\n",
      "Training 24/49\n",
      "Total iteration: 9\n",
      "Epoch 25/50 [16122020-021047] [SAVE]\n",
      "AccVal: 0.837409736780806\n",
      "AUCVal: 0.9133428029479069\n",
      "Precision: 0.8236424922943115\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.830828891366802\n",
      "LossVal: 0.39600614706675213\n",
      "LossTrain: 0.2969223095311059\n",
      "----------\n",
      "\n",
      "Training 25/49\n",
      "Total iteration: 9\n",
      "Epoch 26/50 [16122020-021049] [SAVE]\n",
      "AccVal: 0.8381085488003727\n",
      "AUCVal: 0.9138246221580281\n",
      "Precision: 0.8248315453529358\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8314333754680808\n",
      "LossVal: 0.3936639428138733\n",
      "LossTrain: 0.2889597664276759\n",
      "----------\n",
      "\n",
      "Training 26/49\n",
      "Total iteration: 9\n",
      "Epoch 27/50 [16122020-021052] [SAVE]\n",
      "AccVal: 0.839040298159795\n",
      "AUCVal: 0.9142476006926014\n",
      "Precision: 0.826107919216156\n",
      "Recall: 0.8386307954788208\n",
      "F1Val: 0.8323222859338311\n",
      "LossVal: 0.3918360471725464\n",
      "LossTrain: 0.28164149986373055\n",
      "----------\n",
      "\n",
      "Training 27/49\n",
      "Total iteration: 9\n",
      "Epoch 28/50 [16122020-021054] [SAVE]\n",
      "AccVal: 0.8383414861402283\n",
      "AUCVal: 0.9145627952910057\n",
      "Precision: 0.8252286911010742\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8316351214007907\n",
      "LossVal: 0.39045607050259906\n",
      "LossTrain: 0.2748920867840449\n",
      "----------\n",
      "\n",
      "Training 28/49\n",
      "Total iteration: 9\n",
      "Epoch 29/50 [16122020-021057] [SAVE]\n",
      "AccVal: 0.8388073608199395\n",
      "AUCVal: 0.9147881518154686\n",
      "Precision: 0.826969563961029\n",
      "Recall: 0.8366748094558716\n",
      "F1Val: 0.8317939076380979\n",
      "LossVal: 0.3894674479961395\n",
      "LossTrain: 0.26864669223626453\n",
      "----------\n",
      "\n",
      "Training 29/49\n",
      "Total iteration: 9\n",
      "Epoch 30/50 [16122020-021100] [SAVE]\n",
      "AccVal: 0.8399720475192173\n",
      "AUCVal: 0.915008178962664\n",
      "Precision: 0.8277027010917664\n",
      "Recall: 0.8386307954788208\n",
      "F1Val: 0.8331309439489377\n",
      "LossVal: 0.388821800549825\n",
      "LossTrain: 0.2628495544195175\n",
      "----------\n",
      "\n",
      "Training 30/49\n",
      "Total iteration: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [16122020-021102] [SAVE]\n",
      "AccVal: 0.8413696715583509\n",
      "AUCVal: 0.9151934020134169\n",
      "Precision: 0.8285163640975952\n",
      "Recall: 0.8410757780075073\n",
      "F1Val: 0.8347488323066976\n",
      "LossVal: 0.38847771286964417\n",
      "LossTrain: 0.25745272305276656\n",
      "----------\n",
      "\n",
      "Training 31/49\n",
      "Total iteration: 9\n",
      "Epoch 32/50 [16122020-021105] [SAVE]\n",
      "AccVal: 0.8413696715583509\n",
      "AUCVal: 0.9152609437130751\n",
      "Precision: 0.8282002210617065\n",
      "Recall: 0.8415647745132446\n",
      "F1Val: 0.8348290138273278\n",
      "LossVal: 0.3883997102578481\n",
      "LossTrain: 0.2524148225784302\n",
      "----------\n",
      "\n",
      "Training 32/49\n",
      "Total iteration: 9\n",
      "Epoch 33/50 [16122020-021108]\n",
      "AccVal: 0.8409037968786397\n",
      "AUCVal: 0.9153600266251338\n",
      "Precision: 0.8270893096923828\n",
      "Recall: 0.8420537710189819\n",
      "F1Val: 0.8345044594968324\n",
      "LossVal: 0.38855721553166706\n",
      "LossTrain: 0.24770012166765001\n",
      "----------\n",
      "\n",
      "Training 33/49\n",
      "Total iteration: 9\n",
      "Epoch 34/50 [16122020-021110]\n",
      "AccVal: 0.8406708595387841\n",
      "AUCVal: 0.9154124502953997\n",
      "Precision: 0.8270062208175659\n",
      "Recall: 0.8415647745132446\n",
      "F1Val: 0.8342219847893265\n",
      "LossVal: 0.3889238238334656\n",
      "LossTrain: 0.24327752656406826\n",
      "----------\n",
      "\n",
      "Training 34/49\n",
      "Total iteration: 9\n",
      "Epoch 35/50 [16122020-021113]\n",
      "AccVal: 0.8402049848590729\n",
      "AUCVal: 0.9153976585544118\n",
      "Precision: 0.8262121677398682\n",
      "Recall: 0.8415647745132446\n",
      "F1Val: 0.8338178074398348\n",
      "LossVal: 0.38947658737500507\n",
      "LossTrain: 0.23912000324991015\n",
      "----------\n",
      "\n",
      "Training 35/49\n",
      "Total iteration: 9\n",
      "Epoch 36/50 [16122020-021116]\n",
      "AccVal: 0.8397391101793618\n",
      "AUCVal: 0.915392546702747\n",
      "Precision: 0.8257321119308472\n",
      "Recall: 0.8410757780075073\n",
      "F1Val: 0.833333322526695\n",
      "LossVal: 0.39019564787546795\n",
      "LossTrain: 0.23520384066634709\n",
      "----------\n",
      "\n",
      "Training 36/49\n",
      "Total iteration: 9\n",
      "Epoch 37/50 [16122020-021118]\n",
      "AccVal: 0.8395061728395061\n",
      "AUCVal: 0.915343277153721\n",
      "Precision: 0.8250239491462708\n",
      "Recall: 0.8415647745132446\n",
      "F1Val: 0.8332122485205244\n",
      "LossVal: 0.39106356104214984\n",
      "LossTrain: 0.23150822354687584\n",
      "----------\n",
      "\n",
      "Training 37/49\n",
      "Total iteration: 9\n",
      "Epoch 38/50 [16122020-021121]\n",
      "AccVal: 0.8388073608199395\n",
      "AUCVal: 0.9152893308042356\n",
      "Precision: 0.824149489402771\n",
      "Recall: 0.8410757780075073\n",
      "F1Val: 0.8325266095342544\n",
      "LossVal: 0.3920650879542033\n",
      "LossTrain: 0.22801472577783796\n",
      "----------\n",
      "\n",
      "Training 38/49\n",
      "Total iteration: 9\n",
      "Epoch 39/50 [16122020-021123]\n",
      "AccVal: 0.8383414861402283\n",
      "AUCVal: 0.915225595802626\n",
      "Precision: 0.8239808082580566\n",
      "Recall: 0.8400977849960327\n",
      "F1Val: 0.8319612483484882\n",
      "LossVal: 0.3931868076324463\n",
      "LossTrain: 0.2247070074081421\n",
      "----------\n",
      "\n",
      "Training 39/49\n",
      "Total iteration: 9\n",
      "Epoch 40/50 [16122020-021125]\n",
      "AccVal: 0.8378756114605171\n",
      "AUCVal: 0.9151498968928643\n",
      "Precision: 0.8231911659240723\n",
      "Recall: 0.8400977849960327\n",
      "F1Val: 0.831558551192869\n",
      "LossVal: 0.3944168786207835\n",
      "LossTrain: 0.22157053649425507\n",
      "----------\n",
      "\n",
      "Training 40/49\n",
      "Total iteration: 9\n",
      "Epoch 41/50 [16122020-021128]\n",
      "AccVal: 0.8383414861402283\n",
      "AUCVal: 0.915025037196878\n",
      "Precision: 0.8242918848991394\n",
      "Recall: 0.8396087884902954\n",
      "F1Val: 0.83187986723354\n",
      "LossVal: 0.3957447111606598\n",
      "LossTrain: 0.21859226293034023\n",
      "----------\n",
      "\n",
      "Training 41/49\n",
      "Total iteration: 9\n",
      "Epoch 42/50 [16122020-021130]\n",
      "AccVal: 0.8378756114605171\n",
      "AUCVal: 0.9149436826214445\n",
      "Precision: 0.8235011696815491\n",
      "Recall: 0.8396087884902954\n",
      "F1Val: 0.8314769462107691\n",
      "LossVal: 0.39716100692749023\n",
      "LossTrain: 0.21576051082875994\n",
      "----------\n",
      "\n",
      "Training 42/49\n",
      "Total iteration: 9\n",
      "Epoch 43/50 [16122020-021133]\n",
      "AccVal: 0.8378756114605171\n",
      "AUCVal: 0.914856346091935\n",
      "Precision: 0.8241230249404907\n",
      "Recall: 0.8386307954788208\n",
      "F1Val: 0.8313136189985912\n",
      "LossVal: 0.39865731199582416\n",
      "LossTrain: 0.2130647467242347\n",
      "----------\n",
      "\n",
      "Training 43/49\n",
      "Total iteration: 9\n",
      "Epoch 44/50 [16122020-021135]\n",
      "AccVal: 0.8376426741206615\n",
      "AUCVal: 0.9147516075142045\n",
      "Precision: 0.8243503570556641\n",
      "Recall: 0.8376528024673462\n",
      "F1Val: 0.8309483442869162\n",
      "LossVal: 0.40022608637809753\n",
      "LossTrain: 0.21049544546339247\n",
      "----------\n",
      "\n",
      "Training 44/49\n",
      "Total iteration: 9\n",
      "Epoch 45/50 [16122020-021138]\n",
      "AccVal: 0.8376426741206615\n",
      "AUCVal: 0.9146230498829713\n",
      "Precision: 0.8240384459495544\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8310303198314358\n",
      "LossVal: 0.4018605450789134\n",
      "LossTrain: 0.20804398755232492\n",
      "----------\n",
      "\n",
      "Training 45/49\n",
      "Total iteration: 9\n",
      "Epoch 46/50 [16122020-021140]\n",
      "AccVal: 0.8371767994409504\n",
      "AUCVal: 0.9144982989497864\n",
      "Precision: 0.8238691091537476\n",
      "Recall: 0.8371638059616089\n",
      "F1Val: 0.83046325302404\n",
      "LossVal: 0.40355450908343\n",
      "LossTrain: 0.20570252339045206\n",
      "----------\n",
      "\n",
      "Training 46/49\n",
      "Total iteration: 9\n",
      "Epoch 47/50 [16122020-021142]\n",
      "AccVal: 0.8385744234800838\n",
      "AUCVal: 0.9143521217447294\n",
      "Precision: 0.8256261944770813\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8318368929464298\n",
      "LossVal: 0.4053023358186086\n",
      "LossTrain: 0.20346391532156202\n",
      "----------\n",
      "\n",
      "Training 47/49\n",
      "Total iteration: 9\n",
      "Epoch 48/50 [16122020-021144]\n",
      "AccVal: 0.8383414861402283\n",
      "AUCVal: 0.9141522157157896\n",
      "Precision: 0.8252286911010742\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8316351214007907\n",
      "LossVal: 0.4070989688237508\n",
      "LossTrain: 0.20132163166999817\n",
      "----------\n",
      "\n",
      "Training 48/49\n",
      "Total iteration: 9\n",
      "Epoch 49/50 [16122020-021146]\n",
      "AccVal: 0.8381085488003727\n",
      "AUCVal: 0.9139925519233614\n",
      "Precision: 0.8254580497741699\n",
      "Recall: 0.8371638059616089\n",
      "F1Val: 0.8312697204437698\n",
      "LossVal: 0.4089397192001343\n",
      "LossTrain: 0.19926969375875261\n",
      "----------\n",
      "\n",
      "Training 49/49\n",
      "Total iteration: 9\n",
      "Epoch 50/50 [16122020-021148]\n",
      "AccVal: 0.8369438621010948\n",
      "AUCVal: 0.9138248396836307\n",
      "Precision: 0.8240963816642761\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.8300971121961191\n",
      "LossVal: 0.4108203053474426\n",
      "LossTrain: 0.19730260802639854\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare and Train model\n",
    "model_emb = ModelEmbedding(vocab_size=len(list_vocab), datasetTrain=datasetTrain, datasetVal=datasetVal,\n",
    "                           init_weight=embedding_weight, \n",
    "                           batch_size=2048, optimizer_choice='adam', init_lr=0.001, layers=[300,1], weight_decay=1e-4, \n",
    "                           dropout=0.8, batchnorm=True, checkpoint=None, model_name='EMB_UNK_Raw_Light')\n",
    "\n",
    "model_emb.train(numb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL AT Checkpoint/EMB_UNK_Raw_Light-16122020-020947.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9093820977229049,\n",
       " 'precision': 0.9015519,\n",
       " 'recall': 0.9090465,\n",
       " 'f1': 0.9052836756570761,\n",
       " 'tp': 7436,\n",
       " 'tn': 8179,\n",
       " 'fp': 812,\n",
       " 'fn': 744,\n",
       " 'auc': 0.9695333951174756}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrain and evaluate model\n",
    "dataloader = make_EmbeddingDataLoader(datasetTrain, batch_size=2048)\n",
    "model_emb = ModelEmbedding(vocab_size=len(list_vocab), datasetTrain=datasetTrain, datasetVal=datasetVal,\n",
    "                           init_weight=embedding_weight, \n",
    "                           batch_size=2048, optimizer_choice='adam', init_lr=0.001, layers=[300,1], weight_decay=1e-4, \n",
    "                           dropout=0.8, batchnorm=True, checkpoint='Checkpoint/EMB_UNK_Raw_Light-16122020-020947.pth.tar', \n",
    "                           model_name='EMB_UNK_Raw_Light')\n",
    "model_emb.load_trained_model()\n",
    "model_emb.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discard UNK and Selected Vocab\n",
    "Not use UNK token and use 2457 selected words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary: 2457\n"
     ]
    }
   ],
   "source": [
    "dt_train = data_train.copy()\n",
    "dt_val = data_val.copy()\n",
    "\n",
    "# Load list of selected words\n",
    "common_vocab = joblib.load('selected_vocab_s1.joblib')\n",
    "\n",
    "# remove unknown words\n",
    "dt_train['preprocess'] = dt_train.headline_s1.apply(lambda row: remove_unknown_token(row, common_vocab))\n",
    "dt_val['preprocess'] = dt_val.headline_s1.apply(lambda row: remove_unknown_token(row, common_vocab))\n",
    "\n",
    "list_vocab = common_vocab\n",
    "print(f\"Total Vocabulary: {len(list_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2457/2457 [00:00<00:00, 497389.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# initialise weight by Glove model\n",
    "embedding_weight = np.zeros((len(list_vocab), 300)) # index is use when words is not indictionary\n",
    "unknown_word = dict()\n",
    "for idx in tqdm(range(len(list_vocab))):\n",
    "    word = list_vocab[idx]\n",
    "    word_split = word.split()\n",
    "    if len(word_split) == 1:\n",
    "        feature, flag = get_word_features(word_split[0], embeddings_dict)\n",
    "        if flag == 0: # not exist word\n",
    "            unknown_word[word_split[0]] = feature\n",
    "    else:\n",
    "        feature = np.zeros((len(word_split), 300))\n",
    "        count = 0\n",
    "        for idx_w, w in enumerate(word_split):\n",
    "            ft, flag = get_word_features(w, embeddings_dict)\n",
    "            if flag == 0:\n",
    "                if w in list(unknown_word.keys()):\n",
    "                    ft = unknown_word[w]\n",
    "                else:\n",
    "                    unknown_word[w] = ft\n",
    "            feature[idx_w] = ft\n",
    "            count = count + (1-flag)\n",
    "        feature[idx_w] = feature[idx_w] # + 1e-5 # avoid divided by 0    \n",
    "        feature = np.mean(feature, axis=0) # equal to divided by len(word_split) or count (not recommend)\n",
    "              \n",
    "    embedding_weight[idx] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset data structure in Pytorch\n",
    "datasetTrain = EmbeddingDataset(dt_train, col_name='preprocess', list_vocab=list_vocab)\n",
    "datasetVal = EmbeddingDataset(dt_val, col_name='preprocess', list_vocab=list_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/49\n",
      "Total iteration: 9\n",
      "Epoch 1/50 [16122020-021736] [SAVE]\n",
      "AccVal: 0.5718611693454461\n",
      "AUCVal: 0.7141987661947811\n",
      "Precision: 0.777479887008667\n",
      "Recall: 0.14180928468704224\n",
      "F1Val: 0.2398676499841472\n",
      "LossVal: 0.6756773789723715\n",
      "LossTrain: 0.6842303077379862\n",
      "----------\n",
      "\n",
      "Training 1/49\n",
      "Total iteration: 9\n",
      "Epoch 2/50 [16122020-021738] [SAVE]\n",
      "AccVal: 0.663172606568833\n",
      "AUCVal: 0.799472065362093\n",
      "Precision: 0.8462427854537964\n",
      "Recall: 0.3579462170600891\n",
      "F1Val: 0.5030927672348566\n",
      "LossVal: 0.6589230497678121\n",
      "LossTrain: 0.6655566427442763\n",
      "----------\n",
      "\n",
      "Training 2/49\n",
      "Total iteration: 9\n",
      "Epoch 3/50 [16122020-021740] [SAVE]\n",
      "AccVal: 0.7290938737479618\n",
      "AUCVal: 0.8351411523636332\n",
      "Precision: 0.830584704875946\n",
      "Recall: 0.5418093204498291\n",
      "F1Val: 0.6558153222405851\n",
      "LossVal: 0.6399380366007487\n",
      "LossTrain: 0.645358039273156\n",
      "----------\n",
      "\n",
      "Training 3/49\n",
      "Total iteration: 9\n",
      "Epoch 4/50 [16122020-021742] [SAVE]\n",
      "AccVal: 0.7584439785697648\n",
      "AUCVal: 0.8543557326697351\n",
      "Precision: 0.828125\n",
      "Recall: 0.6220048666000366\n",
      "F1Val: 0.7104160696460237\n",
      "LossVal: 0.6177572011947632\n",
      "LossTrain: 0.6217018100950453\n",
      "----------\n",
      "\n",
      "Training 4/49\n",
      "Total iteration: 9\n",
      "Epoch 5/50 [16122020-021744] [SAVE]\n",
      "AccVal: 0.7749825296995109\n",
      "AUCVal: 0.8669155522104953\n",
      "Precision: 0.8201780319213867\n",
      "Recall: 0.6757946014404297\n",
      "F1Val: 0.7410187510541888\n",
      "LossVal: 0.5923154552777609\n",
      "LossTrain: 0.5936860707071092\n",
      "----------\n",
      "\n",
      "Training 5/49\n",
      "Total iteration: 9\n",
      "Epoch 6/50 [16122020-021746] [SAVE]\n",
      "AccVal: 0.7889587700908456\n",
      "AUCVal: 0.8757540525019795\n",
      "Precision: 0.8162131905555725\n",
      "Recall: 0.718826413154602\n",
      "F1Val: 0.7644305409927472\n",
      "LossVal: 0.5645263393719991\n",
      "LossTrain: 0.5614951848983765\n",
      "----------\n",
      "\n",
      "Training 6/49\n",
      "Total iteration: 9\n",
      "Epoch 7/50 [16122020-021748] [SAVE]\n",
      "AccVal: 0.80083857442348\n",
      "AUCVal: 0.8822019464190937\n",
      "Precision: 0.8171641826629639\n",
      "Recall: 0.749633252620697\n",
      "F1Val: 0.7819433541007038\n",
      "LossVal: 0.5360911885897318\n",
      "LossTrain: 0.5263396302858988\n",
      "----------\n",
      "\n",
      "Training 7/49\n",
      "Total iteration: 9\n",
      "Epoch 8/50 [16122020-021750] [SAVE]\n",
      "AccVal: 0.8045655718611694\n",
      "AUCVal: 0.8872324435086012\n",
      "Precision: 0.8157067894935608\n",
      "Recall: 0.7618581652641296\n",
      "F1Val: 0.7878634425325597\n",
      "LossVal: 0.5089607636133829\n",
      "LossTrain: 0.49013442794481915\n",
      "----------\n",
      "\n",
      "Training 8/49\n",
      "Total iteration: 9\n",
      "Epoch 9/50 [16122020-021752] [SAVE]\n",
      "AccVal: 0.8101560680177032\n",
      "AUCVal: 0.89115791053607\n",
      "Precision: 0.8170102834701538\n",
      "Recall: 0.7750611305236816\n",
      "F1Val: 0.7954830523177812\n",
      "LossVal: 0.48474117120107013\n",
      "LossTrain: 0.45492684841156006\n",
      "----------\n",
      "\n",
      "Training 9/49\n",
      "Total iteration: 9\n",
      "Epoch 10/50 [16122020-021754] [SAVE]\n",
      "AccVal: 0.8143489401351036\n",
      "AUCVal: 0.8945165058427376\n",
      "Precision: 0.8173957467079163\n",
      "Recall: 0.7858190536499023\n",
      "F1Val: 0.80129646491862\n",
      "LossVal: 0.4643392562866211\n",
      "LossTrain: 0.42234227392408585\n",
      "----------\n",
      "\n",
      "Training 10/49\n",
      "Total iteration: 9\n",
      "Epoch 11/50 [16122020-021756] [SAVE]\n",
      "AccVal: 0.816911250873515\n",
      "AUCVal: 0.897241666594158\n",
      "Precision: 0.819057285785675\n",
      "Recall: 0.7902200222015381\n",
      "F1Val: 0.8043803107368885\n",
      "LossVal: 0.44795576731363934\n",
      "LossTrain: 0.39329832130008274\n",
      "----------\n",
      "\n",
      "Training 11/49\n",
      "Total iteration: 9\n",
      "Epoch 12/50 [16122020-021758] [SAVE]\n",
      "AccVal: 0.8192406242720708\n",
      "AUCVal: 0.8995197034690984\n",
      "Precision: 0.8209407925605774\n",
      "Recall: 0.793643057346344\n",
      "F1Val: 0.807061163835706\n",
      "LossVal: 0.4352983633677165\n",
      "LossTrain: 0.36804016100035775\n",
      "----------\n",
      "\n",
      "Training 12/49\n",
      "Total iteration: 9\n",
      "Epoch 13/50 [16122020-021800] [SAVE]\n",
      "AccVal: 0.8243652457488936\n",
      "AUCVal: 0.9014201158976411\n",
      "Precision: 0.8265048265457153\n",
      "Recall: 0.7990220189094543\n",
      "F1Val: 0.8125310668058925\n",
      "LossVal: 0.42583449681599933\n",
      "LossTrain: 0.34635262025727165\n",
      "----------\n",
      "\n",
      "Training 13/49\n",
      "Total iteration: 9\n",
      "Epoch 14/50 [16122020-021802] [SAVE]\n",
      "AccVal: 0.8264616818075937\n",
      "AUCVal: 0.9029721610733584\n",
      "Precision: 0.8282828330993652\n",
      "Recall: 0.8019559979438782\n",
      "F1Val: 0.8149068684114563\n",
      "LossVal: 0.4189838071664174\n",
      "LossTrain: 0.32779282993740505\n",
      "----------\n",
      "\n",
      "Training 14/49\n",
      "Total iteration: 9\n",
      "Epoch 15/50 [16122020-021804] [SAVE]\n",
      "AccVal: 0.827393431167016\n",
      "AUCVal: 0.9042316343133587\n",
      "Precision: 0.8292929530143738\n",
      "Recall: 0.8029339909553528\n",
      "F1Val: 0.8159006355029648\n",
      "LossVal: 0.41422245899836224\n",
      "LossTrain: 0.3118612501356337\n",
      "----------\n",
      "\n",
      "Training 15/49\n",
      "Total iteration: 9\n",
      "Epoch 16/50 [16122020-021806] [SAVE]\n",
      "AccVal: 0.8280922431865828\n",
      "AUCVal: 0.9051778706853796\n",
      "Precision: 0.8302173018455505\n",
      "Recall: 0.8034229874610901\n",
      "F1Val: 0.8166004098414303\n",
      "LossVal: 0.41111887494723004\n",
      "LossTrain: 0.298094328906801\n",
      "----------\n",
      "\n",
      "Training 16/49\n",
      "Total iteration: 9\n",
      "Epoch 17/50 [16122020-021808] [SAVE]\n",
      "AccVal: 0.8278593058467272\n",
      "AUCVal: 0.9059548721384507\n",
      "Precision: 0.830131471157074\n",
      "Recall: 0.8029339909553528\n",
      "F1Val: 0.8163062542411424\n",
      "LossVal: 0.4093327522277832\n",
      "LossTrain: 0.28609878818194073\n",
      "----------\n",
      "\n",
      "Training 17/49\n",
      "Total iteration: 9\n",
      "Epoch 18/50 [16122020-021810] [SAVE]\n",
      "AccVal: 0.8283251805264384\n",
      "AUCVal: 0.9065032541830174\n",
      "Precision: 0.8306369781494141\n",
      "Recall: 0.8034229874610901\n",
      "F1Val: 0.8168033987342218\n",
      "LossVal: 0.4086000621318817\n",
      "LossTrain: 0.27555471824275124\n",
      "----------\n",
      "\n",
      "Training 18/49\n",
      "Total iteration: 9\n",
      "Epoch 19/50 [16122020-021812]\n",
      "AccVal: 0.8271604938271605\n",
      "AUCVal: 0.9068497724682195\n",
      "Precision: 0.8298734426498413\n",
      "Recall: 0.8014670014381409\n",
      "F1Val: 0.8154228723533671\n",
      "LossVal: 0.4087173640727997\n",
      "LossTrain: 0.26620683901839787\n",
      "----------\n",
      "\n",
      "Training 19/49\n",
      "Total iteration: 9\n",
      "Epoch 20/50 [16122020-021814]\n",
      "AccVal: 0.8271604938271605\n",
      "AUCVal: 0.9071290753421677\n",
      "Precision: 0.8282116055488586\n",
      "Recall: 0.8039119839668274\n",
      "F1Val: 0.815880904164501\n",
      "LossVal: 0.40952720244725543\n",
      "LossTrain: 0.2578531288438373\n",
      "----------\n",
      "\n",
      "Training 20/49\n",
      "Total iteration: 9\n",
      "Epoch 21/50 [16122020-021816]\n",
      "AccVal: 0.8283251805264384\n",
      "AUCVal: 0.9073553019690419\n",
      "Precision: 0.829305112361908\n",
      "Recall: 0.8053789734840393\n",
      "F1Val: 0.8171669448332082\n",
      "LossVal: 0.4109070102373759\n",
      "LossTrain: 0.25033394826783073\n",
      "----------\n",
      "\n",
      "Training 21/49\n",
      "Total iteration: 9\n",
      "Epoch 22/50 [16122020-021819] [SAVE]\n",
      "AccVal: 0.8292569298858607\n",
      "AUCVal: 0.9074803791906307\n",
      "Precision: 0.8309788107872009\n",
      "Recall: 0.8053789734840393\n",
      "F1Val: 0.8179786450758855\n",
      "LossVal: 0.4127601583798726\n",
      "LossTrain: 0.2435226539770762\n",
      "----------\n",
      "\n",
      "Training 22/49\n",
      "Total iteration: 9\n",
      "Epoch 23/50 [16122020-021821] [SAVE]\n",
      "AccVal: 0.8294898672257163\n",
      "AUCVal: 0.9075016966997018\n",
      "Precision: 0.8313983082771301\n",
      "Recall: 0.8053789734840393\n",
      "F1Val: 0.8181818302806886\n",
      "LossVal: 0.41500959793726605\n",
      "LossTrain: 0.23731805384159088\n",
      "----------\n",
      "\n",
      "Training 23/49\n",
      "Total iteration: 9\n",
      "Epoch 24/50 [16122020-021823] [SAVE]\n",
      "AccVal: 0.8306545539249942\n",
      "AUCVal: 0.9074805967162336\n",
      "Precision: 0.8314889073371887\n",
      "Recall: 0.8083129525184631\n",
      "F1Val: 0.8197371525548063\n",
      "LossVal: 0.41759298245112103\n",
      "LossTrain: 0.23163849943213993\n",
      "----------\n",
      "\n",
      "Training 24/49\n",
      "Total iteration: 9\n",
      "Epoch 25/50 [16122020-021825] [SAVE]\n",
      "AccVal: 0.8311204286047054\n",
      "AUCVal: 0.9073920637959089\n",
      "Precision: 0.8316583037376404\n",
      "Recall: 0.8092909455299377\n",
      "F1Val: 0.8203221827732577\n",
      "LossVal: 0.42045947909355164\n",
      "LossTrain: 0.22641737262407938\n",
      "----------\n",
      "\n",
      "Training 25/49\n",
      "Total iteration: 9\n",
      "Epoch 26/50 [16122020-021827] [SAVE]\n",
      "AccVal: 0.8313533659445609\n",
      "AUCVal: 0.9072815607897051\n",
      "Precision: 0.8317428231239319\n",
      "Recall: 0.809779942035675\n",
      "F1Val: 0.8206144555447556\n",
      "LossVal: 0.42356695731480914\n",
      "LossTrain: 0.2215997146235572\n",
      "----------\n",
      "\n",
      "Training 26/49\n",
      "Total iteration: 9\n",
      "Epoch 27/50 [16122020-021829] [SAVE]\n",
      "AccVal: 0.83298392732355\n",
      "AUCVal: 0.9071721454115149\n",
      "Precision: 0.8343403935432434\n",
      "Recall: 0.8102689385414124\n",
      "F1Val: 0.8221285041616304\n",
      "LossVal: 0.42688024044036865\n",
      "LossTrain: 0.2171396811803182\n",
      "----------\n",
      "\n",
      "Training 27/49\n",
      "Total iteration: 9\n",
      "Epoch 28/50 [16122020-021831]\n",
      "AccVal: 0.8325180526438388\n",
      "AUCVal: 0.9070200950151833\n",
      "Precision: 0.8348484635353088\n",
      "Recall: 0.8083129525184631\n",
      "F1Val: 0.8213664462574561\n",
      "LossVal: 0.4303695360819499\n",
      "LossTrain: 0.21299863192770216\n",
      "----------\n",
      "\n",
      "Training 28/49\n",
      "Total iteration: 9\n",
      "Epoch 29/50 [16122020-021833] [SAVE]\n",
      "AccVal: 0.8341486140228278\n",
      "AUCVal: 0.9068238869214906\n",
      "Precision: 0.8371269702911377\n",
      "Recall: 0.8092909455299377\n",
      "F1Val: 0.8229736755557497\n",
      "LossVal: 0.4340093930562337\n",
      "LossTrain: 0.20914370814959207\n",
      "----------\n",
      "\n",
      "Training 29/49\n",
      "Total iteration: 9\n",
      "Epoch 30/50 [16122020-021835]\n",
      "AccVal: 0.8341486140228278\n",
      "AUCVal: 0.9065693819662576\n",
      "Precision: 0.8374683260917664\n",
      "Recall: 0.8088019490242004\n",
      "F1Val: 0.8228855548537941\n",
      "LossVal: 0.4377777973810832\n",
      "LossTrain: 0.20554669201374054\n",
      "----------\n",
      "\n",
      "Training 30/49\n",
      "Total iteration: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [16122020-021837]\n",
      "AccVal: 0.8341486140228278\n",
      "AUCVal: 0.9063433728649862\n",
      "Precision: 0.8381532430648804\n",
      "Recall: 0.8078239560127258\n",
      "F1Val: 0.8227091413153903\n",
      "LossVal: 0.4416554967562358\n",
      "LossTrain: 0.20218316051695082\n",
      "----------\n",
      "\n",
      "Training 31/49\n",
      "Total iteration: 9\n",
      "Epoch 32/50 [16122020-021839] [SAVE]\n",
      "AccVal: 0.8346144887025391\n",
      "AUCVal: 0.9060986565618774\n",
      "Precision: 0.8390045762062073\n",
      "Recall: 0.8078239560127258\n",
      "F1Val: 0.8231190832605454\n",
      "LossVal: 0.44562562306722003\n",
      "LossTrain: 0.19903183645672268\n",
      "----------\n",
      "\n",
      "Training 32/49\n",
      "Total iteration: 9\n",
      "Epoch 33/50 [16122020-021841]\n",
      "AccVal: 0.8332168646634055\n",
      "AUCVal: 0.9058289248144507\n",
      "Precision: 0.836796760559082\n",
      "Recall: 0.8073349595069885\n",
      "F1Val: 0.8218019214008023\n",
      "LossVal: 0.44967320561408997\n",
      "LossTrain: 0.19607407020197976\n",
      "----------\n",
      "\n",
      "Training 33/49\n",
      "Total iteration: 9\n",
      "Epoch 34/50 [16122020-021843]\n",
      "AccVal: 0.831819240624272\n",
      "AUCVal: 0.9055115549600188\n",
      "Precision: 0.8352762460708618\n",
      "Recall: 0.8058679699897766\n",
      "F1Val: 0.8203085892968646\n",
      "LossVal: 0.45378510157267254\n",
      "LossTrain: 0.19329341252644858\n",
      "----------\n",
      "\n",
      "Training 34/49\n",
      "Total iteration: 9\n",
      "Epoch 35/50 [16122020-021844]\n",
      "AccVal: 0.8313533659445609\n",
      "AUCVal: 0.9052701015409513\n",
      "Precision: 0.8340920805931091\n",
      "Recall: 0.8063569664955139\n",
      "F1Val: 0.8199900644017457\n",
      "LossVal: 0.4579494297504425\n",
      "LossTrain: 0.19067527022626665\n",
      "----------\n",
      "\n",
      "Training 35/49\n",
      "Total iteration: 9\n",
      "Epoch 36/50 [16122020-021846]\n",
      "AccVal: 0.8315863032844165\n",
      "AUCVal: 0.9050319110059255\n",
      "Precision: 0.8348531126976013\n",
      "Recall: 0.8058679699897766\n",
      "F1Val: 0.8201045141289911\n",
      "LossVal: 0.46215585867563885\n",
      "LossTrain: 0.18820662962065804\n",
      "----------\n",
      "\n",
      "Training 36/49\n",
      "Total iteration: 9\n",
      "Epoch 37/50 [16122020-021848]\n",
      "AccVal: 0.8306545539249942\n",
      "AUCVal: 0.9047519555551689\n",
      "Precision: 0.8335019946098328\n",
      "Recall: 0.8053789734840393\n",
      "F1Val: 0.8191991900382071\n",
      "LossVal: 0.46639498074849445\n",
      "LossTrain: 0.18587584710783428\n",
      "----------\n",
      "\n",
      "Training 37/49\n",
      "Total iteration: 9\n",
      "Epoch 38/50 [16122020-021850]\n",
      "AccVal: 0.8343815513626834\n",
      "AUCVal: 0.9044931000878802\n",
      "Precision: 0.8315109610557556\n",
      "Recall: 0.8180928826332092\n",
      "F1Val: 0.824747349703043\n",
      "LossVal: 0.47065865993499756\n",
      "LossTrain: 0.18367247614595625\n",
      "----------\n",
      "\n",
      "Training 38/49\n",
      "Total iteration: 9\n",
      "Epoch 39/50 [16122020-021852] [SAVE]\n",
      "AccVal: 0.8348474260423946\n",
      "AUCVal: 0.904236854927825\n",
      "Precision: 0.8320079445838928\n",
      "Recall: 0.8185818791389465\n",
      "F1Val: 0.8252403073707275\n",
      "LossVal: 0.47493956486384076\n",
      "LossTrain: 0.18158704125218922\n",
      "----------\n",
      "\n",
      "Training 39/49\n",
      "Total iteration: 9\n",
      "Epoch 40/50 [16122020-021854]\n",
      "AccVal: 0.8341486140228278\n",
      "AUCVal: 0.9039297087767231\n",
      "Precision: 0.8304412364959717\n",
      "Recall: 0.8190708756446838\n",
      "F1Val: 0.824716896978672\n",
      "LossVal: 0.4792310794194539\n",
      "LossTrain: 0.17961104545328352\n",
      "----------\n",
      "\n",
      "Training 40/49\n",
      "Total iteration: 9\n",
      "Epoch 41/50 [16122020-021856]\n",
      "AccVal: 0.8343815513626834\n",
      "AUCVal: 0.9036449677627058\n",
      "Precision: 0.830525279045105\n",
      "Recall: 0.8195599317550659\n",
      "F1Val: 0.8250061712691678\n",
      "LossVal: 0.4835277895132701\n",
      "LossTrain: 0.177736710343096\n",
      "----------\n",
      "\n",
      "Training 41/49\n",
      "Total iteration: 9\n",
      "Epoch 42/50 [16122020-021858]\n",
      "AccVal: 0.8339156766829723\n",
      "AUCVal: 0.9033956834219389\n",
      "Precision: 0.8297029733657837\n",
      "Recall: 0.8195599317550659\n",
      "F1Val: 0.8246002624776316\n",
      "LossVal: 0.4878243605295817\n",
      "LossTrain: 0.1759569893280665\n",
      "----------\n",
      "\n",
      "Training 42/49\n",
      "Total iteration: 9\n",
      "Epoch 43/50 [16122020-021900]\n",
      "AccVal: 0.8339156766829723\n",
      "AUCVal: 0.9031561877332962\n",
      "Precision: 0.8297029733657837\n",
      "Recall: 0.8195599317550659\n",
      "F1Val: 0.8246002624776316\n",
      "LossVal: 0.4921162525812785\n",
      "LossTrain: 0.1742654244105021\n",
      "----------\n",
      "\n",
      "Training 43/49\n",
      "Total iteration: 9\n",
      "Epoch 44/50 [16122020-021902]\n",
      "AccVal: 0.8341486140228278\n",
      "AUCVal: 0.9029259368827709\n",
      "Precision: 0.83011394739151\n",
      "Recall: 0.8195599317550659\n",
      "F1Val: 0.8248031493885548\n",
      "LossVal: 0.4963999589284261\n",
      "LossTrain: 0.17265615529484218\n",
      "----------\n",
      "\n",
      "Training 44/49\n",
      "Total iteration: 9\n",
      "Epoch 45/50 [16122020-021904]\n",
      "AccVal: 0.8341486140228278\n",
      "AUCVal: 0.9026855710917175\n",
      "Precision: 0.8297872543334961\n",
      "Recall: 0.8200489282608032\n",
      "F1Val: 0.8248893505664945\n",
      "LossVal: 0.5006717145442963\n",
      "LossTrain: 0.17112378031015396\n",
      "----------\n",
      "\n",
      "Training 45/49\n",
      "Total iteration: 9\n",
      "Epoch 46/50 [16122020-021906]\n",
      "AccVal: 0.8339156766829723\n",
      "AUCVal: 0.9024605408556587\n",
      "Precision: 0.8297029733657837\n",
      "Recall: 0.8195599317550659\n",
      "F1Val: 0.8246002624776316\n",
      "LossVal: 0.5049284994602203\n",
      "LossTrain: 0.1696633208129141\n",
      "----------\n",
      "\n",
      "Training 46/49\n",
      "Total iteration: 9\n",
      "Epoch 47/50 [16122020-021908]\n",
      "AccVal: 0.8332168646634055\n",
      "AUCVal: 0.9022162596037554\n",
      "Precision: 0.8287976384162903\n",
      "Recall: 0.8190708756446838\n",
      "F1Val: 0.8239055502759105\n",
      "LossVal: 0.5091673930486044\n",
      "LossTrain: 0.16827025098933113\n",
      "----------\n",
      "\n",
      "Training 47/49\n",
      "Total iteration: 9\n",
      "Epoch 48/50 [16122020-021910]\n",
      "AccVal: 0.8332168646634055\n",
      "AUCVal: 0.9020271210921527\n",
      "Precision: 0.8287976384162903\n",
      "Recall: 0.8190708756446838\n",
      "F1Val: 0.8239055502759105\n",
      "LossVal: 0.5133873820304871\n",
      "LossTrain: 0.16694036540057924\n",
      "----------\n",
      "\n",
      "Training 48/49\n",
      "Total iteration: 9\n",
      "Epoch 49/50 [16122020-021912]\n",
      "AccVal: 0.8334498020032611\n",
      "AUCVal: 0.9017862114870919\n",
      "Precision: 0.8288822770118713\n",
      "Recall: 0.8195599317550659\n",
      "F1Val: 0.8241947145069262\n",
      "LossVal: 0.5175844530264536\n",
      "LossTrain: 0.16566978643337885\n",
      "----------\n",
      "\n",
      "Training 49/49\n",
      "Total iteration: 9\n",
      "Epoch 50/50 [16122020-021914]\n",
      "AccVal: 0.8325180526438388\n",
      "AUCVal: 0.9015785832992543\n",
      "Precision: 0.8278931975364685\n",
      "Recall: 0.8185818791389465\n",
      "F1Val: 0.8232112091659125\n",
      "LossVal: 0.5217586159706116\n",
      "LossTrain: 0.16445492125219768\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare model and train\n",
    "model_emb = ModelEmbedding(vocab_size=len(list_vocab), datasetTrain=datasetTrain, datasetVal=datasetVal,\n",
    "                           init_weight=embedding_weight, \n",
    "                           batch_size=2048, optimizer_choice='adam', init_lr=0.001, layers=[300,1], weight_decay=1e-4, \n",
    "                           dropout=0.8, batchnorm=True, checkpoint=None, model_name='EMB_Raw_Light')\n",
    "\n",
    "model_emb.train(numb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL AT Checkpoint/EMB_Raw_Light-16122020-021734.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9309300564905946,\n",
       " 'precision': 0.9268799,\n",
       " 'recall': 0.9282396,\n",
       " 'f1': 0.9275592350974992,\n",
       " 'tp': 7593,\n",
       " 'tn': 8392,\n",
       " 'fp': 599,\n",
       " 'fn': 587,\n",
       " 'auc': 0.9815640824198283}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrain and evaluate\n",
    "dataloader = make_EmbeddingDataLoader(datasetTrain, batch_size=2048)\n",
    "model_emb = ModelEmbedding(vocab_size=len(list_vocab), datasetTrain=datasetTrain, datasetVal=datasetVal,\n",
    "                           init_weight=embedding_weight, \n",
    "                           batch_size=2048, optimizer_choice='adam', init_lr=0.001, layers=[300,1], weight_decay=1e-4, \n",
    "                           dropout=0.8, batchnorm=True, \n",
    "                           checkpoint='Checkpoint/EMB_Raw_Light-16122020-021734.pth.tar', \n",
    "                           model_name='EMB_Raw_Light')\n",
    "\n",
    "model_emb.load_trained_model()\n",
    "model_emb.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
