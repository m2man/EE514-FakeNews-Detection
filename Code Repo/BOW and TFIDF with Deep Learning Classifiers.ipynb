{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW and TFIDF with Deep Learning\n",
    "In this notebooks I implemented the simple multi-layer perceptron network (Fully connected / Linear Layer) with PyTorch framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.ranking module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from myfunctions import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from deep_pytorch import *\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TRAINING SAMPLES =====\n",
      "Total Sample: 17171\n",
      "Sarcastic: 8180 (47.64%)\n",
      "Not Sarcastic: 8991 (52.36%)\n",
      "===== VALIDATING SAMPLES =====\n",
      "Total Sample: 4293\n",
      "Sarcastic: 2045 (47.64%)\n",
      "Not Sarcastic: 2248 (52.36%)\n",
      "===== TESTING SAMPLES =====\n",
      "Total Sample: 7155\n",
      "Sarcastic: 3409 (47.65%)\n",
      "Not Sarcastic: 3746 (52.35%)\n"
     ]
    }
   ],
   "source": [
    "# Read Dataset\n",
    "data_full = pd.read_json('fake_news.json', lines=True)\n",
    "data_full = data_full.drop(columns=['article_link']) # remove link column\n",
    "df_train_f, df_test = split_dataframe(data_full, test_size=0.25, seed=1509)\n",
    "df_train, df_validate = split_dataframe(df_train_f, test_size=0.2, seed=1309)\n",
    "\n",
    "# Proportion of each subsets\n",
    "list_label = df_train['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TRAINING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_validate['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== VALIDATING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_test['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TESTING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "data_train = df_train.copy()\n",
    "data_train_f = df_train_f.copy()\n",
    "data_val = df_validate.copy()\n",
    "data_test = df_test.copy()\n",
    "\n",
    "# Preprocessing headline\n",
    "# Lower case\n",
    "# Remove symbol\n",
    "# Lemmatise\n",
    "data_train = df_train\n",
    "data_train['headline'] = data_train.headline.apply(lambda row: row.lower())\n",
    "data_train['headline_s1'] = data_train.headline.apply(lambda row: remove_symbol(row))\n",
    "data_train['headline_s2'] = data_train.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_train['headline_s2'] = data_train.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "#data_train = data_train.drop(columns=['headline', 'headline_s1'])\n",
    "\n",
    "data_train_f = df_train_f\n",
    "data_train_f['headline'] = data_train_f.headline.apply(lambda row: row.lower())\n",
    "data_train_f['headline_s1'] = data_train_f.headline.apply(lambda row: remove_symbol(row))\n",
    "data_train_f['headline_s2'] = data_train_f.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_train_f['headline_s2'] = data_train_f.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "\n",
    "data_val = df_validate\n",
    "data_val['headline'] = data_val.headline.apply(lambda row: row.lower())\n",
    "data_val['headline_s1'] = data_val.headline.apply(lambda row: remove_symbol(row))\n",
    "data_val['headline_s2'] = data_val.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_val['headline_s2'] = data_val.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "#data_val = data_val.drop(columns=['headline', 'headline_s1'])\n",
    "\n",
    "data_test = df_test\n",
    "data_test['headline'] = data_test.headline.apply(lambda row: row.lower())\n",
    "data_test['headline_s1'] = data_test.headline.apply(lambda row: remove_symbol(row))\n",
    "data_test['headline_s2'] = data_test.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_test['headline_s2'] = data_test.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# BOW - Raw\n",
    "Use BOW on Original sentence (after discard symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "# Create BOW vectorizer and create X_train, X_val\n",
    "vectorizer = CountVectorizer(tokenizer=lambda text: text.split())\n",
    "all_string = data_train.headline_s1.tolist()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(all_string)\n",
    "\n",
    "vocab = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "vocab = list(vocab)\n",
    "\n",
    "# encode document\n",
    "# X_train_f = vectorizer.transform(data_train_f.headline.tolist())\n",
    "# y_train_f = data_train_f.is_sarcastic.to_numpy()\n",
    "\n",
    "X_train = vectorizer.transform(data_train.headline_s1.tolist()).toarray()\n",
    "y_train = data_train.is_sarcastic.to_numpy()\n",
    "\n",
    "X_val = vectorizer.transform(data_val.headline_s1.tolist()).toarray()\n",
    "y_val = data_val.is_sarcastic.to_numpy()\n",
    "\n",
    "# X_train, x_mean, x_std = normalize_data(X_train, [], [])\n",
    "# X_val, _, _ = normalize_data(X_val, x_mean, x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Dataset data structure of PyTorch\n",
    "datasetTrain = EncodingDataset(X_train, y_train)\n",
    "datasetVal = EncodingDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/49\n",
      "Total iteration: 17\n",
      "Epoch 1/50 [15122020-233200] [SAVE]\n",
      "AccVal: 0.7176799440950384\n",
      "AUCVal: 0.8919116367496454\n",
      "Precision: 0.6331096291542053\n",
      "Recall: 0.9687041640281677\n",
      "F1Val: 0.7657518453871642\n",
      "LossVal: 0.667226231098175\n",
      "LossTrain: 0.6180618685834548\n",
      "----------\n",
      "\n",
      "Training 1/49\n",
      "Total iteration: 17\n",
      "Epoch 2/50 [15122020-233202] [SAVE]\n",
      "AccVal: 0.8299557419054274\n",
      "AUCVal: 0.9112187741997233\n",
      "Precision: 0.7820677757263184\n",
      "Recall: 0.8914425373077393\n",
      "F1Val: 0.8331809812108414\n",
      "LossVal: 0.6050172448158264\n",
      "LossTrain: 0.44915131610982556\n",
      "----------\n",
      "\n",
      "Training 2/49\n",
      "Total iteration: 17\n",
      "Epoch 3/50 [15122020-233205] [SAVE]\n",
      "AccVal: 0.8441649196366178\n",
      "AUCVal: 0.9196655108806308\n",
      "Precision: 0.834956169128418\n",
      "Recall: 0.8386307954788208\n",
      "F1Val: 0.8367894481903344\n",
      "LossVal: 0.48506492376327515\n",
      "LossTrain: 0.37431760570582223\n",
      "----------\n",
      "\n",
      "Training 3/49\n",
      "Total iteration: 17\n",
      "Epoch 4/50 [15122020-233207] [SAVE]\n",
      "AccVal: 0.8483577917540182\n",
      "AUCVal: 0.9233352765620513\n",
      "Precision: 0.848848819732666\n",
      "Recall: 0.829339861869812\n",
      "F1Val: 0.8389809448997331\n",
      "LossVal: 0.38744757771492006\n",
      "LossTrain: 0.3230291114133947\n",
      "----------\n",
      "\n",
      "Training 4/49\n",
      "Total iteration: 17\n",
      "Epoch 5/50 [15122020-233209] [SAVE]\n",
      "AccVal: 0.8516189145119962\n",
      "AUCVal: 0.9253521739508741\n",
      "Precision: 0.8537688255310059\n",
      "Recall: 0.8308068513870239\n",
      "F1Val: 0.8421313443745362\n",
      "LossVal: 0.3621563255786896\n",
      "LossTrain: 0.28580404379788565\n",
      "----------\n",
      "\n",
      "Training 5/49\n",
      "Total iteration: 17\n",
      "Epoch 6/50 [15122020-233212] [SAVE]\n",
      "AccVal: 0.8546470999301188\n",
      "AUCVal: 0.9267841449938659\n",
      "Precision: 0.8526054620742798\n",
      "Recall: 0.8400977849960327\n",
      "F1Val: 0.8463054128404688\n",
      "LossVal: 0.3562115907669067\n",
      "LossTrain: 0.2608887386672637\n",
      "----------\n",
      "\n",
      "Training 6/49\n",
      "Total iteration: 17\n",
      "Epoch 7/50 [15122020-233215] [SAVE]\n",
      "AccVal: 0.853482413230841\n",
      "AUCVal: 0.9271998364207465\n",
      "Precision: 0.851190447807312\n",
      "Recall: 0.8391197919845581\n",
      "F1Val: 0.8451120210823087\n",
      "LossVal: 0.35430173873901366\n",
      "LossTrain: 0.23854940253145554\n",
      "----------\n",
      "\n",
      "Training 7/49\n",
      "Total iteration: 17\n",
      "Epoch 8/50 [15122020-233217]\n",
      "AccVal: 0.853482413230841\n",
      "AUCVal: 0.9271071705139695\n",
      "Precision: 0.8536463379859924\n",
      "Recall: 0.835696816444397\n",
      "F1Val: 0.8445761892521114\n",
      "LossVal: 0.3554339945316315\n",
      "LossTrain: 0.22485197466962478\n",
      "----------\n",
      "\n",
      "Training 8/49\n",
      "Total iteration: 17\n",
      "Epoch 9/50 [15122020-233219]\n",
      "AccVal: 0.8527836012112742\n",
      "AUCVal: 0.9269794829851475\n",
      "Precision: 0.8516675233840942\n",
      "Recall: 0.8366748094558716\n",
      "F1Val: 0.8441045977311095\n",
      "LossVal: 0.35690329074859617\n",
      "LossTrain: 0.20910600704305313\n",
      "----------\n",
      "\n",
      "Training 9/49\n",
      "Total iteration: 17\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 10/50 [15122020-233222]\n",
      "AccVal: 0.8544141625902633\n",
      "AUCVal: 0.926248814485465\n",
      "Precision: 0.849065899848938\n",
      "Recall: 0.8444987535476685\n",
      "F1Val: 0.846776168437591\n",
      "LossVal: 0.35992410182952883\n",
      "LossTrain: 0.20185591368114247\n",
      "----------\n",
      "\n",
      "Training 10/49\n",
      "Total iteration: 17\n",
      "Epoch 11/50 [15122020-233225] [SAVE]\n",
      "AccVal: 0.8562776613091079\n",
      "AUCVal: 0.9261826867022249\n",
      "Precision: 0.8486328125\n",
      "Recall: 0.8498777747154236\n",
      "F1Val: 0.8492548075436294\n",
      "LossVal: 0.3609682619571686\n",
      "LossTrain: 0.18657778115833507\n",
      "----------\n",
      "\n",
      "Training 11/49\n",
      "Total iteration: 17\n",
      "Epoch 12/50 [15122020-233228]\n",
      "AccVal: 0.8551129746098299\n",
      "AUCVal: 0.926285576312332\n",
      "Precision: 0.8486036062240601\n",
      "Recall: 0.846943736076355\n",
      "F1Val: 0.8477728586783766\n",
      "LossVal: 0.36235218644142153\n",
      "LossTrain: 0.17733152736635768\n",
      "----------\n",
      "\n",
      "Training 12/49\n",
      "Total iteration: 17\n",
      "Epoch 13/50 [15122020-233230]\n",
      "AccVal: 0.853482413230841\n",
      "AUCVal: 0.9260478208285114\n",
      "Precision: 0.8470588326454163\n",
      "Recall: 0.8449877500534058\n",
      "F1Val: 0.8460219940338322\n",
      "LossVal: 0.3653020620346069\n",
      "LossTrain: 0.1655236517681795\n",
      "----------\n",
      "\n",
      "Training 13/49\n",
      "Total iteration: 17\n",
      "Epoch    14: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 14/50 [15122020-233232] [SAVE]\n",
      "AccVal: 0.8569764733286745\n",
      "AUCVal: 0.9261204743798345\n",
      "Precision: 0.8491947054862976\n",
      "Recall: 0.8508557677268982\n",
      "F1Val: 0.8500244251225242\n",
      "LossVal: 0.3671539306640625\n",
      "LossTrain: 0.16181983053684235\n",
      "----------\n",
      "\n",
      "Training 14/49\n",
      "Total iteration: 17\n",
      "Epoch 15/50 [15122020-233234]\n",
      "AccVal: 0.856743535988819\n",
      "AUCVal: 0.9261661547564148\n",
      "Precision: 0.84912109375\n",
      "Recall: 0.8503667712211609\n",
      "F1Val: 0.8497434461597558\n",
      "LossVal: 0.3683574438095093\n",
      "LossTrain: 0.15214100918349097\n",
      "----------\n",
      "\n",
      "Training 15/49\n",
      "Total iteration: 17\n",
      "Epoch 16/50 [15122020-233236]\n",
      "AccVal: 0.8558117866293967\n",
      "AUCVal: 0.9260578270062386\n",
      "Precision: 0.8491674661636353\n",
      "Recall: 0.8479217886924744\n",
      "F1Val: 0.8485442000616076\n",
      "LossVal: 0.3697800517082214\n",
      "LossTrain: 0.14760794359094956\n",
      "----------\n",
      "\n",
      "Training 16/49\n",
      "Total iteration: 17\n",
      "Epoch 17/50 [15122020-233239]\n",
      "AccVal: 0.8562776613091079\n",
      "AUCVal: 0.9259734270723664\n",
      "Precision: 0.8496571779251099\n",
      "Recall: 0.8484107851982117\n",
      "F1Val: 0.8490335539338584\n",
      "LossVal: 0.37124162912368774\n",
      "LossTrain: 0.1413178198477801\n",
      "----------\n",
      "\n",
      "Training 17/49\n",
      "Total iteration: 17\n",
      "Epoch    18: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 18/50 [15122020-233241] [SAVE]\n",
      "AccVal: 0.8574423480083857\n",
      "AUCVal: 0.9259688590347084\n",
      "Precision: 0.8517427444458008\n",
      "Recall: 0.8484107851982117\n",
      "F1Val: 0.8500734700345395\n",
      "LossVal: 0.37241509556770325\n",
      "LossTrain: 0.13428620511994643\n",
      "----------\n",
      "\n",
      "Training 18/49\n",
      "Total iteration: 17\n",
      "Epoch 19/50 [15122020-233243]\n",
      "AccVal: 0.8569764733286745\n",
      "AUCVal: 0.9259112147499762\n",
      "Precision: 0.8522894978523254\n",
      "Recall: 0.8464547395706177\n",
      "F1Val: 0.8493620684474876\n",
      "LossVal: 0.37349587082862856\n",
      "LossTrain: 0.13179735138135798\n",
      "----------\n",
      "\n",
      "Training 19/49\n",
      "Total iteration: 17\n",
      "Epoch 20/50 [15122020-233246]\n",
      "AccVal: 0.8562776613091079\n",
      "AUCVal: 0.9258407364546808\n",
      "Precision: 0.8520709872245789\n",
      "Recall: 0.8449877500534058\n",
      "F1Val: 0.8485146163216746\n",
      "LossVal: 0.37461981177330017\n",
      "LossTrain: 0.1273101765443297\n",
      "----------\n",
      "\n",
      "Training 20/49\n",
      "Total iteration: 17\n",
      "Epoch 21/50 [15122020-233248]\n",
      "AccVal: 0.8553459119496856\n",
      "AUCVal: 0.9257483968363076\n",
      "Precision: 0.8507389426231384\n",
      "Recall: 0.8444987535476685\n",
      "F1Val: 0.8476073927841468\n",
      "LossVal: 0.3756869971752167\n",
      "LossTrain: 0.12670165694811764\n",
      "----------\n",
      "\n",
      "Training 21/49\n",
      "Total iteration: 17\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 22/50 [15122020-233250]\n",
      "AccVal: 0.8537153505706965\n",
      "AUCVal: 0.9257035865621384\n",
      "Precision: 0.8505690097808838\n",
      "Recall: 0.84058678150177\n",
      "F1Val: 0.8455484350552798\n",
      "LossVal: 0.3768748760223389\n",
      "LossTrain: 0.12646815575221004\n",
      "----------\n",
      "\n",
      "Training 22/49\n",
      "Total iteration: 17\n",
      "Epoch 23/50 [15122020-233253]\n",
      "AccVal: 0.8537153505706965\n",
      "AUCVal: 0.9256499665010572\n",
      "Precision: 0.851264238357544\n",
      "Recall: 0.8396087884902954\n",
      "F1Val: 0.8453963420126277\n",
      "LossVal: 0.3778524696826935\n",
      "LossTrain: 0.12019635473980624\n",
      "----------\n",
      "\n",
      "Training 23/49\n",
      "Total iteration: 17\n",
      "Epoch 24/50 [15122020-233255]\n",
      "AccVal: 0.8544141625902633\n",
      "AUCVal: 0.925585796448242\n",
      "Precision: 0.8521825671195984\n",
      "Recall: 0.8400977849960327\n",
      "F1Val: 0.8460970564009093\n",
      "LossVal: 0.37865769267082217\n",
      "LossTrain: 0.11815180278876249\n",
      "----------\n",
      "\n",
      "Training 24/49\n",
      "Total iteration: 17\n",
      "Epoch 25/50 [15122020-233258]\n",
      "AccVal: 0.8539482879105521\n",
      "AUCVal: 0.9255079222824526\n",
      "Precision: 0.8520357608795166\n",
      "Recall: 0.8391197919845581\n",
      "F1Val: 0.8455284544603793\n",
      "LossVal: 0.37965688705444334\n",
      "LossTrain: 0.11681072413921356\n",
      "----------\n",
      "\n",
      "Training 25/49\n",
      "Total iteration: 17\n",
      "Epoch 26/50 [15122020-233300]\n",
      "AccVal: 0.8539482879105521\n",
      "AUCVal: 0.9253998120578791\n",
      "Precision: 0.8523856997489929\n",
      "Recall: 0.8386307954788208\n",
      "F1Val: 0.845452335502392\n",
      "LossVal: 0.38063457012176516\n",
      "LossTrain: 0.11727063226349213\n",
      "----------\n",
      "\n",
      "Training 26/49\n",
      "Total iteration: 17\n",
      "Epoch 27/50 [15122020-233303]\n",
      "AccVal: 0.8553459119496856\n",
      "AUCVal: 0.9254191718365252\n",
      "Precision: 0.8538767099380493\n",
      "Recall: 0.8400977849960327\n",
      "F1Val: 0.8469312080245567\n",
      "LossVal: 0.38136271238327024\n",
      "LossTrain: 0.11200845635989133\n",
      "----------\n",
      "\n",
      "Training 27/49\n",
      "Total iteration: 17\n",
      "Epoch 28/50 [15122020-233305]\n",
      "AccVal: 0.8551129746098299\n",
      "AUCVal: 0.9253932862897962\n",
      "Precision: 0.8538040518760681\n",
      "Recall: 0.8396087884902954\n",
      "F1Val: 0.8466469531206886\n",
      "LossVal: 0.3823567509651184\n",
      "LossTrain: 0.1120880325050915\n",
      "----------\n",
      "\n",
      "Training 28/49\n",
      "Total iteration: 17\n",
      "Epoch 29/50 [15122020-233308]\n",
      "AccVal: 0.853482413230841\n",
      "AUCVal: 0.9253569595141349\n",
      "Precision: 0.8518886566162109\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.844959318714892\n",
      "LossVal: 0.38347831964492796\n",
      "LossTrain: 0.10987514520392698\n",
      "----------\n",
      "\n",
      "Training 29/49\n",
      "Total iteration: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [15122020-233310]\n",
      "AccVal: 0.8539482879105521\n",
      "AUCVal: 0.9252273142548878\n",
      "Precision: 0.8530876636505127\n",
      "Recall: 0.8376528024673462\n",
      "F1Val: 0.8452997802175508\n",
      "LossVal: 0.38487491607666013\n",
      "LossTrain: 0.11102377053569346\n",
      "----------\n",
      "\n",
      "Training 30/49\n",
      "Total iteration: 17\n",
      "Epoch 31/50 [15122020-233312]\n",
      "AccVal: 0.853482413230841\n",
      "AUCVal: 0.9250952762140104\n",
      "Precision: 0.8525896668434143\n",
      "Recall: 0.8371638059616089\n",
      "F1Val: 0.8448062947977052\n",
      "LossVal: 0.38619919419288634\n",
      "LossTrain: 0.10548001308651532\n",
      "----------\n",
      "\n",
      "Training 31/49\n",
      "Total iteration: 17\n",
      "Epoch 32/50 [15122020-233315]\n",
      "AccVal: 0.8539482879105521\n",
      "AUCVal: 0.9250382845060865\n",
      "Precision: 0.8530876636505127\n",
      "Recall: 0.8376528024673462\n",
      "F1Val: 0.8452997802175508\n",
      "LossVal: 0.38732707500457764\n",
      "LossTrain: 0.10483772132326574\n",
      "----------\n",
      "\n",
      "Training 32/49\n",
      "Total iteration: 17\n",
      "Epoch 33/50 [15122020-233317]\n",
      "AccVal: 0.8544141625902633\n",
      "AUCVal: 0.9249393103568291\n",
      "Precision: 0.853233814239502\n",
      "Recall: 0.8386307954788208\n",
      "F1Val: 0.8458692832214665\n",
      "LossVal: 0.3884891927242279\n",
      "LossTrain: 0.10483677509952993\n",
      "----------\n",
      "\n",
      "Training 33/49\n",
      "Total iteration: 17\n",
      "Epoch 34/50 [15122020-233320]\n",
      "AccVal: 0.8537153505706965\n",
      "AUCVal: 0.9248463181616475\n",
      "Precision: 0.8530144691467285\n",
      "Recall: 0.8371638059616089\n",
      "F1Val: 0.8450148129911601\n",
      "LossVal: 0.38976842164993286\n",
      "LossTrain: 0.10391104747267331\n",
      "----------\n",
      "\n",
      "Training 34/49\n",
      "Total iteration: 17\n",
      "Epoch 35/50 [15122020-233323]\n",
      "AccVal: 0.8537153505706965\n",
      "AUCVal: 0.9247496280312193\n",
      "Precision: 0.8537194132804871\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.844861683038164\n",
      "LossVal: 0.39122809171676637\n",
      "LossTrain: 0.10029847087228999\n",
      "----------\n",
      "\n",
      "Training 35/49\n",
      "Total iteration: 17\n",
      "Epoch 36/50 [15122020-233326]\n",
      "AccVal: 0.8539482879105521\n",
      "AUCVal: 0.9246695786094024\n",
      "Precision: 0.8537924289703369\n",
      "Recall: 0.8366748094558716\n",
      "F1Val: 0.8451469529674707\n",
      "LossVal: 0.3923880696296692\n",
      "LossTrain: 0.09765381497495315\n",
      "----------\n",
      "\n",
      "Training 36/49\n",
      "Total iteration: 17\n",
      "Epoch 37/50 [15122020-233329]\n",
      "AccVal: 0.8537153505706965\n",
      "AUCVal: 0.9246645755205387\n",
      "Precision: 0.8537194132804871\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.844861683038164\n",
      "LossVal: 0.3932677447795868\n",
      "LossTrain: 0.09663656178642721\n",
      "----------\n",
      "\n",
      "Training 37/49\n",
      "Total iteration: 17\n",
      "Epoch 38/50 [15122020-233331]\n",
      "AccVal: 0.8530165385511298\n",
      "AUCVal: 0.924700249719392\n",
      "Precision: 0.8524426817893982\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.8442360226020025\n",
      "LossVal: 0.39409453272819517\n",
      "LossTrain: 0.09791942817323349\n",
      "----------\n",
      "\n",
      "Training 38/49\n",
      "Total iteration: 17\n",
      "Epoch 39/50 [15122020-233333]\n",
      "AccVal: 0.8537153505706965\n",
      "AUCVal: 0.92465522191962\n",
      "Precision: 0.8537194132804871\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.844861683038164\n",
      "LossVal: 0.3951919436454773\n",
      "LossTrain: 0.09504076268743067\n",
      "----------\n",
      "\n",
      "Training 39/49\n",
      "Total iteration: 17\n",
      "Epoch 40/50 [15122020-233335]\n",
      "AccVal: 0.8527836012112742\n",
      "AUCVal: 0.9245518972583073\n",
      "Precision: 0.8530734777450562\n",
      "Recall: 0.8347188234329224\n",
      "F1Val: 0.8437963476290271\n",
      "LossVal: 0.3965551137924194\n",
      "LossTrain: 0.09347046824062571\n",
      "----------\n",
      "\n",
      "Training 40/49\n",
      "Total iteration: 17\n",
      "Epoch 41/50 [15122020-233337]\n",
      "AccVal: 0.8530165385511298\n",
      "AUCVal: 0.9244711952596821\n",
      "Precision: 0.8538538813591003\n",
      "Recall: 0.8342298269271851\n",
      "F1Val: 0.8439278186523607\n",
      "LossVal: 0.3978959321975708\n",
      "LossTrain: 0.09250037196804495\n",
      "----------\n",
      "\n",
      "Training 41/49\n",
      "Total iteration: 17\n",
      "Epoch 42/50 [15122020-233340]\n",
      "AccVal: 0.8527836012112742\n",
      "AUCVal: 0.9244122458213331\n",
      "Precision: 0.8534266948699951\n",
      "Recall: 0.8342298269271851\n",
      "F1Val: 0.843719079991796\n",
      "LossVal: 0.39918388724327086\n",
      "LossTrain: 0.0922208564246402\n",
      "----------\n",
      "\n",
      "Training 42/49\n",
      "Total iteration: 17\n",
      "Epoch 43/50 [15122020-233342]\n",
      "AccVal: 0.853482413230841\n",
      "AUCVal: 0.9243340453671398\n",
      "Precision: 0.8543543815612793\n",
      "Recall: 0.8347188234329224\n",
      "F1Val: 0.8444224703381535\n",
      "LossVal: 0.40048387050628664\n",
      "LossTrain: 0.08979219461188596\n",
      "----------\n",
      "\n",
      "Early stopping: 25 epoch not decrease the loss\n"
     ]
    }
   ],
   "source": [
    "# Declare and train model\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=1024, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[X_train.shape[1], 128, 1], weight_decay=1e-3,\n",
    "                     dropout=0.9, batchnorm=True, checkpoint=None, model_name='BOW_Raw')\n",
    "model_mlp.train(numb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL AT BOW_Raw-15122020-233156.pth.tar\n"
     ]
    }
   ],
   "source": [
    "# Load pretrain and run evaluate on train / validate set\n",
    "dataloader = make_dalaloader(datasetTrain, batch_size=1024)\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=1024, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[X_train.shape[1], 128, 1], weight_decay=1e-3,\n",
    "                     dropout=0.9, batchnorm=True, checkpoint='BOW_Raw-15122020-233156.pth.tar', model_name='BOW_Raw')\n",
    "model_mlp.load_trained_model()\n",
    "metrics = model_mlp.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9882942169937685,\n",
       " 'precision': 0.98944914,\n",
       " 'recall': 0.9859413,\n",
       " 'f1': 0.9876921025509319,\n",
       " 'tp': 8065,\n",
       " 'tn': 8905,\n",
       " 'fp': 86,\n",
       " 'fn': 115,\n",
       " 'auc': 0.9991705234166522}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# BOW - Lemmatised\n",
    "Use BOW on lemmatised sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "# Create BOW vectorizer and X_train, X_val\n",
    "vectorizer = CountVectorizer(tokenizer=lambda text: text.split())\n",
    "all_string = data_train.headline_s2.tolist()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(all_string)\n",
    "\n",
    "vocab = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "vocab = list(vocab)\n",
    "\n",
    "# encode document\n",
    "# X_train_f = vectorizer.transform(data_train_f.headline.tolist())\n",
    "# y_train_f = data_train_f.is_sarcastic.to_numpy()\n",
    "\n",
    "X_train = vectorizer.transform(data_train.headline_s2.tolist()).toarray()\n",
    "y_train = data_train.is_sarcastic.to_numpy()\n",
    "\n",
    "X_val = vectorizer.transform(data_val.headline_s2.tolist()).toarray()\n",
    "y_val = data_val.is_sarcastic.to_numpy()\n",
    "\n",
    "# X_train, x_mean, x_std = normalize_data(X_train, [], [])\n",
    "# X_val, _, _ = normalize_data(X_val, x_mean, x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17171, 18194)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Dataset data structure in PyTorch\n",
    "datasetTrain = EncodingDataset(X_train, y_train)\n",
    "datasetVal = EncodingDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/49\n",
      "Total iteration: 17\n",
      "Epoch 1/50 [15122020-041700] [SAVE]\n",
      "AccVal: 0.7484276729559748\n",
      "AUCVal: 0.8874455098365078\n",
      "Precision: 0.6690017580986023\n",
      "Recall: 0.9339853525161743\n",
      "F1Val: 0.7795918781476346\n",
      "LossVal: 0.6625605344772338\n",
      "LossTrain: 0.6022102762671078\n",
      "----------\n",
      "\n",
      "Training 1/49\n",
      "Total iteration: 17\n",
      "Epoch 2/50 [15122020-041701] [SAVE]\n",
      "AccVal: 0.8211041229909154\n",
      "AUCVal: 0.9052567237163813\n",
      "Precision: 0.7828976511955261\n",
      "Recall: 0.8640586733818054\n",
      "F1Val: 0.8214783789841473\n",
      "LossVal: 0.5933645009994507\n",
      "LossTrain: 0.41566961653092327\n",
      "----------\n",
      "\n",
      "Training 2/49\n",
      "Total iteration: 17\n",
      "Epoch 3/50 [15122020-041703] [SAVE]\n",
      "AccVal: 0.8364779874213837\n",
      "AUCVal: 0.9130209738186184\n",
      "Precision: 0.8312777280807495\n",
      "Recall: 0.8239609003067017\n",
      "F1Val: 0.8276031425167972\n",
      "LossVal: 0.4717401385307312\n",
      "LossTrain: 0.3379380667910856\n",
      "----------\n",
      "\n",
      "Training 3/49\n",
      "Total iteration: 17\n",
      "Epoch 4/50 [15122020-041705] [SAVE]\n",
      "AccVal: 0.8420684835779175\n",
      "AUCVal: 0.9162430718095519\n",
      "Precision: 0.8392059803009033\n",
      "Recall: 0.8268948793411255\n",
      "F1Val: 0.833004945417725\n",
      "LossVal: 0.3910719096660614\n",
      "LossTrain: 0.2848200052976608\n",
      "----------\n",
      "\n",
      "Training 4/49\n",
      "Total iteration: 17\n",
      "Epoch 5/50 [15122020-041706] [SAVE]\n",
      "AccVal: 0.8397391101793618\n",
      "AUCVal: 0.9171297061664159\n",
      "Precision: 0.8384039998054504\n",
      "Recall: 0.8220049142837524\n",
      "F1Val: 0.8301234441802127\n",
      "LossVal: 0.3834915220737457\n",
      "LossTrain: 0.25511935002663555\n",
      "----------\n",
      "\n",
      "Training 5/49\n",
      "Total iteration: 17\n",
      "Epoch 6/50 [15122020-041708] [SAVE]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.9171871329255454\n",
      "Precision: 0.8327661752700806\n",
      "Recall: 0.8376528024673462\n",
      "F1Val: 0.8352023412232175\n",
      "LossVal: 0.3868338167667389\n",
      "LossTrain: 0.2296687636305304\n",
      "----------\n",
      "\n",
      "Training 6/49\n",
      "Total iteration: 17\n",
      "Epoch 7/50 [15122020-041709] [SAVE]\n",
      "AccVal: 0.843466107617051\n",
      "AUCVal: 0.9178782117655249\n",
      "Precision: 0.832445502281189\n",
      "Recall: 0.84058678150177\n",
      "F1Val: 0.8364963334191655\n",
      "LossVal: 0.3887780368328094\n",
      "LossTrain: 0.20562636676956625\n",
      "----------\n",
      "\n",
      "Training 7/49\n",
      "Total iteration: 17\n",
      "Epoch 8/50 [15122020-041711]\n",
      "AccVal: 0.8430002329373398\n",
      "AUCVal: 0.9183229428603745\n",
      "Precision: 0.8361942172050476\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8349657514176553\n",
      "LossVal: 0.3924297749996185\n",
      "LossTrain: 0.19572304802782395\n",
      "----------\n",
      "\n",
      "Training 8/49\n",
      "Total iteration: 17\n",
      "Epoch 9/50 [15122020-041712]\n",
      "AccVal: 0.843466107617051\n",
      "AUCVal: 0.9175600805714832\n",
      "Precision: 0.8363547325134277\n",
      "Recall: 0.8347188234329224\n",
      "F1Val: 0.8355359772308887\n",
      "LossVal: 0.39837023615837097\n",
      "LossTrain: 0.18047159822548137\n",
      "----------\n",
      "\n",
      "Training 9/49\n",
      "Total iteration: 17\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 10/50 [15122020-041713]\n",
      "AccVal: 0.8404379221989284\n",
      "AUCVal: 0.9165286829259804\n",
      "Precision: 0.832355797290802\n",
      "Recall: 0.8327628374099731\n",
      "F1Val: 0.8325592377973611\n",
      "LossVal: 0.40562711358070375\n",
      "LossTrain: 0.17413632571697235\n",
      "----------\n",
      "\n",
      "Training 10/49\n",
      "Total iteration: 17\n",
      "Epoch 11/50 [15122020-041715]\n",
      "AccVal: 0.8395061728395061\n",
      "AUCVal: 0.9164460231969302\n",
      "Precision: 0.8317025303840637\n",
      "Recall: 0.8312958478927612\n",
      "F1Val: 0.8314991096094513\n",
      "LossVal: 0.40726839900016787\n",
      "LossTrain: 0.15940021153758555\n",
      "----------\n",
      "\n",
      "Training 11/49\n",
      "Total iteration: 17\n",
      "Epoch 12/50 [15122020-041716]\n",
      "AccVal: 0.8411367342184952\n",
      "AUCVal: 0.9164823499725918\n",
      "Precision: 0.8332518339157104\n",
      "Recall: 0.8332518339157104\n",
      "F1Val: 0.8332518339157104\n",
      "LossVal: 0.4105947971343994\n",
      "LossTrain: 0.14534512863439672\n",
      "----------\n",
      "\n",
      "Training 12/49\n",
      "Total iteration: 17\n",
      "Epoch 13/50 [15122020-041717]\n",
      "AccVal: 0.8430002329373398\n",
      "AUCVal: 0.916547933941825\n",
      "Precision: 0.835536003112793\n",
      "Recall: 0.8347188234329224\n",
      "F1Val: 0.8351272133684423\n",
      "LossVal: 0.4133805215358734\n",
      "LossTrain: 0.1384266733246691\n",
      "----------\n",
      "\n",
      "Training 13/49\n",
      "Total iteration: 17\n",
      "Epoch    14: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 14/50 [15122020-041719]\n",
      "AccVal: 0.8427672955974843\n",
      "AUCVal: 0.9167916713797214\n",
      "Precision: 0.8357843160629272\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8347613226370152\n",
      "LossVal: 0.41606331467628477\n",
      "LossTrain: 0.13293884913710988\n",
      "----------\n",
      "\n",
      "Training 14/49\n",
      "Total iteration: 17\n",
      "Epoch 15/50 [15122020-041720] [SAVE]\n",
      "AccVal: 0.8439319822967621\n",
      "AUCVal: 0.9167474049195589\n",
      "Precision: 0.837506115436554\n",
      "Recall: 0.8342298269271851\n",
      "F1Val: 0.8358647309245529\n",
      "LossVal: 0.4184408724308014\n",
      "LossTrain: 0.12599409020998897\n",
      "----------\n",
      "\n",
      "Training 15/49\n",
      "Total iteration: 17\n",
      "Epoch 16/50 [15122020-041722]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.9165638133108267\n",
      "Precision: 0.837358295917511\n",
      "Recall: 0.8308068513870239\n",
      "F1Val: 0.8340696789894221\n",
      "LossVal: 0.42123817205429076\n",
      "LossTrain: 0.12082114421269473\n",
      "----------\n",
      "\n",
      "Training 16/49\n",
      "Total iteration: 17\n",
      "Epoch 17/50 [15122020-041723]\n",
      "AccVal: 0.841835546238062\n",
      "AUCVal: 0.9163703242871687\n",
      "Precision: 0.8371174931526184\n",
      "Recall: 0.829339861869812\n",
      "F1Val: 0.83321049796566\n",
      "LossVal: 0.42432504892349243\n",
      "LossTrain: 0.11556889642687405\n",
      "----------\n",
      "\n",
      "Training 17/49\n",
      "Total iteration: 17\n",
      "Epoch    18: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 18/50 [15122020-041724]\n",
      "AccVal: 0.8409037968786397\n",
      "AUCVal: 0.9161001574885365\n",
      "Precision: 0.8354679942131042\n",
      "Recall: 0.829339861869812\n",
      "F1Val: 0.8323926790625024\n",
      "LossVal: 0.42720959186553953\n",
      "LossTrain: 0.10824298858642578\n",
      "----------\n",
      "\n",
      "Training 18/49\n",
      "Total iteration: 17\n",
      "Epoch 19/50 [15122020-041726]\n",
      "AccVal: 0.841835546238062\n",
      "AUCVal: 0.9160429482550095\n",
      "Precision: 0.8371174931526184\n",
      "Recall: 0.829339861869812\n",
      "F1Val: 0.83321049796566\n",
      "LossVal: 0.42853328585624695\n",
      "LossTrain: 0.10360921218114741\n",
      "----------\n",
      "\n",
      "Training 19/49\n",
      "Total iteration: 17\n",
      "Epoch 20/50 [15122020-041727]\n",
      "AccVal: 0.8409037968786397\n",
      "AUCVal: 0.916010863228602\n",
      "Precision: 0.8357987999916077\n",
      "Recall: 0.8288508653640747\n",
      "F1Val: 0.8323103031898309\n",
      "LossVal: 0.4300644874572754\n",
      "LossTrain: 0.10205088906428393\n",
      "----------\n",
      "\n",
      "Training 20/49\n",
      "Total iteration: 17\n",
      "Epoch 21/50 [15122020-041728]\n",
      "AccVal: 0.8402049848590729\n",
      "AUCVal: 0.9159520225530545\n",
      "Precision: 0.8355555534362793\n",
      "Recall: 0.8273838758468628\n",
      "F1Val: 0.8314496368463581\n",
      "LossVal: 0.431830495595932\n",
      "LossTrain: 0.10202679301009458\n",
      "----------\n",
      "\n",
      "Training 21/49\n",
      "Total iteration: 17\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 22/50 [15122020-041729]\n",
      "AccVal: 0.8409037968786397\n",
      "AUCVal: 0.9158969885755553\n",
      "Precision: 0.8364624381065369\n",
      "Recall: 0.8278728723526001\n",
      "F1Val: 0.8321455198341641\n",
      "LossVal: 0.43346540331840516\n",
      "LossTrain: 0.0996125471942565\n",
      "----------\n",
      "\n",
      "Training 22/49\n",
      "Total iteration: 17\n",
      "Epoch 23/50 [15122020-041731]\n",
      "AccVal: 0.8413696715583509\n",
      "AUCVal: 0.9158326009971374\n",
      "Precision: 0.8369565010070801\n",
      "Recall: 0.8283618688583374\n",
      "F1Val: 0.8326370066804571\n",
      "LossVal: 0.4351239144802094\n",
      "LossTrain: 0.09964388345970827\n",
      "----------\n",
      "\n",
      "Training 23/49\n",
      "Total iteration: 17\n",
      "Epoch 24/50 [15122020-041732]\n",
      "AccVal: 0.8413696715583509\n",
      "AUCVal: 0.9157081763523567\n",
      "Precision: 0.8359605669975281\n",
      "Recall: 0.8298288583755493\n",
      "F1Val: 0.8328834571933147\n",
      "LossVal: 0.4365574598312378\n",
      "LossTrain: 0.09796510461498709\n",
      "----------\n",
      "\n",
      "Training 24/49\n",
      "Total iteration: 17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2d584a965b3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                      \u001b[0minit_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      dropout=0.9, batchnorm=True, checkpoint=None, model_name='BOW_Lem')\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, numb_epoch)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mtimestampSTART\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampDate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestampTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mlossTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderVal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mmetricsVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mlossvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mlossvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mloss_report\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlossvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Declare and train model\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=1024, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[X_train.shape[1], 128, 1], weight_decay=1e-3,\n",
    "                     dropout=0.9, batchnorm=True, checkpoint=None, model_name='BOW_Lem')\n",
    "model_mlp.train(numb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL AT BOW_Lem-15122020-041600.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9543416225030574,\n",
       " 'precision': 0.95429975,\n",
       " 'recall': 0.94963324,\n",
       " 'f1': 0.9519607457548951,\n",
       " 'tp': 7768,\n",
       " 'tn': 8619,\n",
       " 'fp': 372,\n",
       " 'fn': 412,\n",
       " 'auc': 0.9901168691103491}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrain and evaluate on train / validate set\n",
    "dataloader = make_dalaloader(datasetTrain, batch_size=1024)\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=1024, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[X_train.shape[1], 128, 1], weight_decay=1e-3,\n",
    "                     dropout=0.9, batchnorm=True, checkpoint='BOW_Lem-15122020-041600.pth.tar', model_name='BOW_EMB')\n",
    "model_mlp.load_trained_model()\n",
    "metrics = model_mlp.evaluate(dataloader)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TFIDF - Raw\n",
    "Use TFIDF on original sentence (adter discard symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "# Create TFIDF vectorizer to build X_train, X_val\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda text: text.split())\n",
    "all_string = data_train.headline_s1.tolist()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(all_string)\n",
    "\n",
    "vocab = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "vocab = list(vocab)\n",
    "\n",
    "# encode document\n",
    "# X_train_f = vectorizer.transform(data_train_f.headline.tolist())\n",
    "# y_train_f = data_train_f.is_sarcastic.to_numpy()\n",
    "\n",
    "X_train = vectorizer.transform(data_train.headline_s1.tolist()).toarray()\n",
    "y_train = data_train.is_sarcastic.to_numpy()\n",
    "\n",
    "X_val = vectorizer.transform(data_val.headline_s1.tolist()).toarray()\n",
    "y_val = data_val.is_sarcastic.to_numpy()\n",
    "\n",
    "# X_train, x_mean, x_std = normalize_data(X_train, [], [])\n",
    "# X_val, _, _ = normalize_data(X_val, x_mean, x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dataset data structure in PyTorch\n",
    "datasetTrain = EncodingDataset(X_train, y_train)\n",
    "datasetVal = EncodingDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/49\n",
      "Total iteration: 17\n",
      "Epoch 1/50 [15122020-233925] [SAVE]\n",
      "AccVal: 0.4798509201024924\n",
      "AUCVal: 0.8912924501213793\n",
      "Precision: 0.4780271053314209\n",
      "Recall: 1.0\n",
      "F1Val: 0.6468448428410005\n",
      "LossVal: 0.6890757799148559\n",
      "LossTrain: 0.6222280439208535\n",
      "----------\n",
      "\n",
      "Training 1/49\n",
      "Total iteration: 17\n",
      "Epoch 2/50 [15122020-233927] [SAVE]\n",
      "AccVal: 0.7372466806429071\n",
      "AUCVal: 0.914713866822125\n",
      "Precision: 0.6499836444854736\n",
      "Recall: 0.9716381430625916\n",
      "F1Val: 0.7789102033347823\n",
      "LossVal: 0.6644232273101807\n",
      "LossTrain: 0.4446595293634078\n",
      "----------\n",
      "\n",
      "Training 2/49\n",
      "Total iteration: 17\n",
      "Epoch 3/50 [15122020-233929] [SAVE]\n",
      "AccVal: 0.8238993710691824\n",
      "AUCVal: 0.920556604512351\n",
      "Precision: 0.7684298157691956\n",
      "Recall: 0.90220046043396\n",
      "F1Val: 0.8299595286977396\n",
      "LossVal: 0.5944712162017822\n",
      "LossTrain: 0.35879873703507814\n",
      "----------\n",
      "\n",
      "Training 3/49\n",
      "Total iteration: 17\n",
      "Epoch 4/50 [15122020-233930] [SAVE]\n",
      "AccVal: 0.841835546238062\n",
      "AUCVal: 0.9236713536183208\n",
      "Precision: 0.8194574117660522\n",
      "Recall: 0.8567237257957458\n",
      "F1Val: 0.8376763300475544\n",
      "LossVal: 0.46645528078079224\n",
      "LossTrain: 0.3004858020473929\n",
      "----------\n",
      "\n",
      "Training 4/49\n",
      "Total iteration: 17\n",
      "Epoch 5/50 [15122020-233932] [SAVE]\n",
      "AccVal: 0.8462613556953179\n",
      "AUCVal: 0.9258305127513508\n",
      "Precision: 0.8330928087234497\n",
      "Recall: 0.846943736076355\n",
      "F1Val: 0.8399611759667536\n",
      "LossVal: 0.3689233064651489\n",
      "LossTrain: 0.266966560307671\n",
      "----------\n",
      "\n",
      "Training 5/49\n",
      "Total iteration: 17\n",
      "Epoch 6/50 [15122020-233933] [SAVE]\n",
      "AccVal: 0.8462613556953179\n",
      "AUCVal: 0.926604686371586\n",
      "Precision: 0.8406296372413635\n",
      "Recall: 0.835696816444397\n",
      "F1Val: 0.8381559392895116\n",
      "LossVal: 0.35419459342956544\n",
      "LossTrain: 0.24200602051089792\n",
      "----------\n",
      "\n",
      "Training 6/49\n",
      "Total iteration: 17\n",
      "Epoch 7/50 [15122020-233935] [SAVE]\n",
      "AccVal: 0.8509201024924296\n",
      "AUCVal: 0.9270691035334859\n",
      "Precision: 0.8517776727676392\n",
      "Recall: 0.8317848443984985\n",
      "F1Val: 0.8416625480563963\n",
      "LossVal: 0.35766411423683164\n",
      "LossTrain: 0.22593573086401997\n",
      "----------\n",
      "\n",
      "Training 7/49\n",
      "Total iteration: 17\n",
      "Epoch 8/50 [15122020-233937] [SAVE]\n",
      "AccVal: 0.8525506638714185\n",
      "AUCVal: 0.927279668316961\n",
      "Precision: 0.8544176816940308\n",
      "Recall: 0.8322738409042358\n",
      "F1Val: 0.8432004028627049\n",
      "LossVal: 0.36114753484725953\n",
      "LossTrain: 0.20560705135850346\n",
      "----------\n",
      "\n",
      "Training 8/49\n",
      "Total iteration: 17\n",
      "Epoch 9/50 [15122020-233938]\n",
      "AccVal: 0.8502212904728628\n",
      "AUCVal: 0.9272485621557657\n",
      "Precision: 0.8480635285377502\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.8415865527556022\n",
      "LossVal: 0.3626410782337189\n",
      "LossTrain: 0.19573251114172094\n",
      "----------\n",
      "\n",
      "Training 9/49\n",
      "Total iteration: 17\n",
      "Epoch 10/50 [15122020-233940]\n",
      "AccVal: 0.8511530398322851\n",
      "AUCVal: 0.9268847505851439\n",
      "Precision: 0.8463054299354553\n",
      "Recall: 0.8400977849960327\n",
      "F1Val: 0.8431901525030604\n",
      "LossVal: 0.3638827860355377\n",
      "LossTrain: 0.1810623363536947\n",
      "----------\n",
      "\n",
      "Training 10/49\n",
      "Total iteration: 17\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 11/50 [15122020-233941]\n",
      "AccVal: 0.8485907290938738\n",
      "AUCVal: 0.9268446171114341\n",
      "Precision: 0.8461538553237915\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8399014819062943\n",
      "LossVal: 0.36806800365448\n",
      "LossTrain: 0.17070465228136847\n",
      "----------\n",
      "\n",
      "Training 11/49\n",
      "Total iteration: 17\n",
      "Epoch 12/50 [15122020-233943]\n",
      "AccVal: 0.8502212904728628\n",
      "AUCVal: 0.9270225530544947\n",
      "Precision: 0.8473736643791199\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.8417425948399674\n",
      "LossVal: 0.3683270275592804\n",
      "LossTrain: 0.16456705419456258\n",
      "----------\n",
      "\n",
      "Training 12/49\n",
      "Total iteration: 17\n",
      "Epoch 13/50 [15122020-233944]\n",
      "AccVal: 0.8518518518518519\n",
      "AUCVal: 0.9269570778480627\n",
      "Precision: 0.8468734622001648\n",
      "Recall: 0.8410757780075073\n",
      "F1Val: 0.8439646931069904\n",
      "LossVal: 0.3700609922409058\n",
      "LossTrain: 0.14892627517966664\n",
      "----------\n",
      "\n",
      "Training 13/49\n",
      "Total iteration: 17\n",
      "Epoch 14/50 [15122020-233946]\n",
      "AccVal: 0.8506871651525739\n",
      "AUCVal: 0.926534316839092\n",
      "Precision: 0.8468379378318787\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.842467457924938\n",
      "LossVal: 0.3738092005252838\n",
      "LossTrain: 0.14530520228778615\n",
      "----------\n",
      "\n",
      "Training 14/49\n",
      "Total iteration: 17\n",
      "Epoch    15: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 15/50 [15122020-233947]\n",
      "AccVal: 0.8506871651525739\n",
      "AUCVal: 0.9262564278815616\n",
      "Precision: 0.8468379378318787\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.842467457924938\n",
      "LossVal: 0.37663230299949646\n",
      "LossTrain: 0.1395111048922819\n",
      "----------\n",
      "\n",
      "Training 15/49\n",
      "Total iteration: 17\n",
      "Epoch 16/50 [15122020-233949]\n",
      "AccVal: 0.8509201024924296\n",
      "AUCVal: 0.925987566236546\n",
      "Precision: 0.8476002216339111\n",
      "Recall: 0.8376528024673462\n",
      "F1Val: 0.8425971541006175\n",
      "LossVal: 0.3786568343639374\n",
      "LossTrain: 0.13319690131089268\n",
      "----------\n",
      "\n",
      "Training 16/49\n",
      "Total iteration: 17\n",
      "Epoch 17/50 [15122020-233950]\n",
      "AccVal: 0.8499883531330072\n",
      "AUCVal: 0.9257983189621419\n",
      "Precision: 0.8469539284706116\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.8415353956671418\n",
      "LossVal: 0.3806346237659454\n",
      "LossTrain: 0.12760379998122945\n",
      "----------\n",
      "\n",
      "Training 17/49\n",
      "Total iteration: 17\n",
      "Epoch 18/50 [15122020-233952]\n",
      "AccVal: 0.8490566037735849\n",
      "AUCVal: 0.9255988479844078\n",
      "Precision: 0.8459633588790894\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.840551184340742\n",
      "LossVal: 0.3829546868801117\n",
      "LossTrain: 0.12030973679879133\n",
      "----------\n",
      "\n",
      "Training 18/49\n",
      "Total iteration: 17\n",
      "Epoch    19: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 19/50 [15122020-233953]\n",
      "AccVal: 0.8490566037735849\n",
      "AUCVal: 0.9252661425749811\n",
      "Precision: 0.8459633588790894\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.840551184340742\n",
      "LossVal: 0.3859759271144867\n",
      "LossTrain: 0.1185304978314568\n",
      "----------\n",
      "\n",
      "Training 19/49\n",
      "Total iteration: 17\n",
      "Epoch 20/50 [15122020-233955]\n",
      "AccVal: 0.8481248544141626\n",
      "AUCVal: 0.9252140451931192\n",
      "Precision: 0.8453148007392883\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8394878952640944\n",
      "LossVal: 0.38728728890419006\n",
      "LossTrain: 0.11480084412238177\n",
      "----------\n",
      "\n",
      "Training 20/49\n",
      "Total iteration: 17\n",
      "Epoch 21/50 [15122020-233956]\n",
      "AccVal: 0.847891917074307\n",
      "AUCVal: 0.9252286194085044\n",
      "Precision: 0.8452380895614624\n",
      "Recall: 0.8332518339157104\n",
      "F1Val: 0.8392021642447213\n",
      "LossVal: 0.38837634325027465\n",
      "LossTrain: 0.11171663815484327\n",
      "----------\n",
      "\n",
      "Training 21/49\n",
      "Total iteration: 17\n",
      "Epoch 22/50 [15122020-233958]\n",
      "AccVal: 0.847891917074307\n",
      "AUCVal: 0.9252421059958756\n",
      "Precision: 0.8448959589004517\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8392813297961217\n",
      "LossVal: 0.38939347863197327\n",
      "LossTrain: 0.10962752428124933\n",
      "----------\n",
      "\n",
      "Training 22/49\n",
      "Total iteration: 17\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 23/50 [15122020-233959]\n",
      "AccVal: 0.8474260423945958\n",
      "AUCVal: 0.9252053441690087\n",
      "Precision: 0.8444004058837891\n",
      "Recall: 0.8332518339157104\n",
      "F1Val: 0.838789076866045\n",
      "LossVal: 0.39039064645767213\n",
      "LossTrain: 0.10454514315899681\n",
      "----------\n",
      "\n",
      "Training 23/49\n",
      "Total iteration: 17\n",
      "Epoch 24/50 [15122020-234001]\n",
      "AccVal: 0.8483577917540182\n",
      "AUCVal: 0.9252025163361728\n",
      "Precision: 0.8453914523124695\n",
      "Recall: 0.8342298269271851\n",
      "F1Val: 0.8397735831196603\n",
      "LossVal: 0.39146595597267153\n",
      "LossTrain: 0.10173494675580193\n",
      "----------\n",
      "\n",
      "Training 24/49\n",
      "Total iteration: 17\n",
      "Epoch 25/50 [15122020-234002]\n",
      "AccVal: 0.8476589797344515\n",
      "AUCVal: 0.9251495488518999\n",
      "Precision: 0.8455042243003845\n",
      "Recall: 0.8322738409042358\n",
      "F1Val: 0.838836897265913\n",
      "LossVal: 0.3924989283084869\n",
      "LossTrain: 0.09992789783898522\n",
      "----------\n",
      "\n",
      "Training 25/49\n",
      "Total iteration: 17\n",
      "Epoch 26/50 [15122020-234004]\n",
      "AccVal: 0.8483577917540182\n",
      "AUCVal: 0.9251063700197514\n",
      "Precision: 0.8457341194152832\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8396946523145202\n",
      "LossVal: 0.3933650732040405\n",
      "LossTrain: 0.10141202369157006\n",
      "----------\n",
      "\n",
      "Training 26/49\n",
      "Total iteration: 17\n",
      "Epoch 27/50 [15122020-234005]\n",
      "AccVal: 0.847891917074307\n",
      "AUCVal: 0.9250641700528153\n",
      "Precision: 0.8452380895614624\n",
      "Recall: 0.8332518339157104\n",
      "F1Val: 0.8392021642447213\n",
      "LossVal: 0.39437331557273864\n",
      "LossTrain: 0.10007453972802442\n",
      "----------\n",
      "\n",
      "Training 27/49\n",
      "Total iteration: 17\n",
      "Epoch 28/50 [15122020-234007]\n",
      "AccVal: 0.847891917074307\n",
      "AUCVal: 0.9249956494879448\n",
      "Precision: 0.8448959589004517\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8392813297961217\n",
      "LossVal: 0.3954776287078857\n",
      "LossTrain: 0.09860984761925305\n",
      "----------\n",
      "\n",
      "Training 28/49\n",
      "Total iteration: 17\n",
      "Epoch 29/50 [15122020-234008]\n",
      "AccVal: 0.8474260423945958\n",
      "AUCVal: 0.924945836124912\n",
      "Precision: 0.8444004058837891\n",
      "Recall: 0.8332518339157104\n",
      "F1Val: 0.838789076866045\n",
      "LossVal: 0.39647382497787476\n",
      "LossTrain: 0.09491752745474086\n",
      "----------\n",
      "\n",
      "Training 29/49\n",
      "Total iteration: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [15122020-234010]\n",
      "AccVal: 0.847891917074307\n",
      "AUCVal: 0.9248934124546458\n",
      "Precision: 0.8445544838905334\n",
      "Recall: 0.8342298269271851\n",
      "F1Val: 0.8393603768771332\n",
      "LossVal: 0.39748517870903016\n",
      "LossTrain: 0.09571446653674631\n",
      "----------\n",
      "\n",
      "Training 30/49\n",
      "Total iteration: 17\n",
      "Epoch 31/50 [15122020-234011]\n",
      "AccVal: 0.8481248544141626\n",
      "AUCVal: 0.9248605660886284\n",
      "Precision: 0.8453148007392883\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8394878952640944\n",
      "LossVal: 0.3984334051609039\n",
      "LossTrain: 0.09187938755049425\n",
      "----------\n",
      "\n",
      "Training 31/49\n",
      "Total iteration: 17\n",
      "Epoch 32/50 [15122020-234013]\n",
      "AccVal: 0.8485907290938738\n",
      "AUCVal: 0.9248355506443109\n",
      "Precision: 0.8461538553237915\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8399014819062943\n",
      "LossVal: 0.3995016574859619\n",
      "LossTrain: 0.09238653630018234\n",
      "----------\n",
      "\n",
      "Training 32/49\n",
      "Total iteration: 17\n",
      "Epoch 33/50 [15122020-234014]\n",
      "AccVal: 0.8483577917540182\n",
      "AUCVal: 0.9248127104560206\n",
      "Precision: 0.8460774421691895\n",
      "Recall: 0.8332518339157104\n",
      "F1Val: 0.8396156612785078\n",
      "LossVal: 0.400681871175766\n",
      "LossTrain: 0.09222875228699516\n",
      "----------\n",
      "\n",
      "Early stopping: 25 epoch not decrease the loss\n"
     ]
    }
   ],
   "source": [
    "# Declare and Train model\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=1024, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[X_train.shape[1], 128, 1], weight_decay=1e-3,\n",
    "                     dropout=0.9, batchnorm=True, checkpoint=None, model_name='TFIDF_Raw')\n",
    "model_mlp.train(numb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL AT TFIDF_Raw-15122020-233924.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.970065808630831,\n",
       " 'precision': 0.9719281,\n",
       " 'recall': 0.9650367,\n",
       " 'f1': 0.9684701754146052,\n",
       " 'tp': 7894,\n",
       " 'tn': 8763,\n",
       " 'fp': 228,\n",
       " 'fn': 286,\n",
       " 'auc': 0.9952982730081346}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrain and evaluate train / validate set\n",
    "dataloader = make_dalaloader(datasetTrain, batch_size=1024)\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=1024, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[X_train.shape[1], 128, 1], weight_decay=1e-3,\n",
    "                     dropout=0.9, batchnorm=True, checkpoint='TFIDF_Raw-15122020-233924.pth.tar', model_name='TFIDF_Raw')\n",
    "model_mlp.load_trained_model()\n",
    "metrics = model_mlp.evaluate(dataloader)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TFIDF - Lemmatised\n",
    "Use TFIDF on lemmatised sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "# Create TFIDF vectorizer to have X_train, X_val\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda text: text.split())\n",
    "all_string = data_train.headline_s2.tolist()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(all_string)\n",
    "\n",
    "vocab = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "vocab = list(vocab)\n",
    "\n",
    "# encode document\n",
    "# X_train_f = vectorizer.transform(data_train_f.headline.tolist())\n",
    "# y_train_f = data_train_f.is_sarcastic.to_numpy()\n",
    "\n",
    "X_train = vectorizer.transform(data_train.headline_s2.tolist()).toarray()\n",
    "y_train = data_train.is_sarcastic.to_numpy()\n",
    "\n",
    "X_val = vectorizer.transform(data_val.headline_s2.tolist()).toarray()\n",
    "y_val = data_val.is_sarcastic.to_numpy()\n",
    "\n",
    "# X_train, x_mean, x_std = normalize_data(X_train, [], [])\n",
    "# X_val, _, _ = normalize_data(X_val, x_mean, x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dataset data structure in PyTorch\n",
    "datasetTrain = EncodingDataset(X_train, y_train)\n",
    "datasetVal = EncodingDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/49\n",
      "Total iteration: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/EE514_FakeNews/Code Repo/myfunctions.py:41: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  precision = TP / (TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [15122020-042503] [SAVE]\n",
      "AccVal: 0.5236431399953413\n",
      "AUCVal: 0.8901080232143324\n",
      "Precision: nan\n",
      "Recall: 0.0\n",
      "F1Val: nan\n",
      "LossVal: 0.6851996302604675\n",
      "LossTrain: 0.6262577281278723\n",
      "----------\n",
      "\n",
      "Training 1/49\n",
      "Total iteration: 17\n",
      "Epoch 2/50 [15122020-042504] [SAVE]\n",
      "AccVal: 0.6261355695317959\n",
      "AUCVal: 0.9084861088150075\n",
      "Precision: 0.9888888597488403\n",
      "Recall: 0.2176039069890976\n",
      "F1Val: 0.35671341384570426\n",
      "LossVal: 0.66132572889328\n",
      "LossTrain: 0.45166406736654396\n",
      "----------\n",
      "\n",
      "Training 2/49\n",
      "Total iteration: 17\n",
      "Epoch 3/50 [15122020-042505] [SAVE]\n",
      "AccVal: 0.8052643838807361\n",
      "AUCVal: 0.9140851090673372\n",
      "Precision: 0.8995373249053955\n",
      "Recall: 0.6655256748199463\n",
      "F1Val: 0.7650365324443226\n",
      "LossVal: 0.595960795879364\n",
      "LossTrain: 0.37428174649967866\n",
      "----------\n",
      "\n",
      "Training 3/49\n",
      "Total iteration: 17\n",
      "Epoch 4/50 [15122020-042507] [SAVE]\n",
      "AccVal: 0.8322851153039832\n",
      "AUCVal: 0.9163172480400943\n",
      "Precision: 0.8548473715782166\n",
      "Recall: 0.780440092086792\n",
      "F1Val: 0.815950897809967\n",
      "LossVal: 0.4771660089492798\n",
      "LossTrain: 0.3218257988200468\n",
      "----------\n",
      "\n",
      "Training 4/49\n",
      "Total iteration: 17\n",
      "Epoch 5/50 [15122020-042508] [SAVE]\n",
      "AccVal: 0.8343815513626834\n",
      "AUCVal: 0.917737255174934\n",
      "Precision: 0.8365287780761719\n",
      "Recall: 0.8107579350471497\n",
      "F1Val: 0.823441801427626\n",
      "LossVal: 0.38821437358856203\n",
      "LossTrain: 0.29021324830896716\n",
      "----------\n",
      "\n",
      "Training 5/49\n",
      "Total iteration: 17\n",
      "Epoch 6/50 [15122020-042509] [SAVE]\n",
      "AccVal: 0.8388073608199395\n",
      "AUCVal: 0.9183852639455663\n",
      "Precision: 0.8353990912437439\n",
      "Recall: 0.8239609003067017\n",
      "F1Val: 0.8296406030841518\n",
      "LossVal: 0.37852192521095274\n",
      "LossTrain: 0.26173436115769777\n",
      "----------\n",
      "\n",
      "Training 6/49\n",
      "Total iteration: 17\n",
      "Epoch 7/50 [15122020-042510] [SAVE]\n",
      "AccVal: 0.8402049848590729\n",
      "AUCVal: 0.9181313028043401\n",
      "Precision: 0.8335787653923035\n",
      "Recall: 0.8303178548812866\n",
      "F1Val: 0.8319451445669985\n",
      "LossVal: 0.3841801047325134\n",
      "LossTrain: 0.24836034546880162\n",
      "----------\n",
      "\n",
      "Training 7/49\n",
      "Total iteration: 17\n",
      "Epoch 8/50 [15122020-042512]\n",
      "AccVal: 0.8395061728395061\n",
      "AUCVal: 0.9186584761026373\n",
      "Precision: 0.8339901566505432\n",
      "Recall: 0.8278728723526001\n",
      "F1Val: 0.8309202258995819\n",
      "LossVal: 0.3871634781360626\n",
      "LossTrain: 0.23133721772362204\n",
      "----------\n",
      "\n",
      "Training 8/49\n",
      "Total iteration: 17\n",
      "Epoch 9/50 [15122020-042513]\n",
      "AccVal: 0.8402049848590729\n",
      "AUCVal: 0.918729389449138\n",
      "Precision: 0.8325991034507751\n",
      "Recall: 0.8317848443984985\n",
      "F1Val: 0.8321918045488113\n",
      "LossVal: 0.39032760858535764\n",
      "LossTrain: 0.21660328700261958\n",
      "----------\n",
      "\n",
      "Training 9/49\n",
      "Total iteration: 17\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 10/50 [15122020-042514] [SAVE]\n",
      "AccVal: 0.8432331702771955\n",
      "AUCVal: 0.9190463242523645\n",
      "Precision: 0.8349609375\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.8355729263357436\n",
      "LossVal: 0.3919573962688446\n",
      "LossTrain: 0.20746255446882808\n",
      "----------\n",
      "\n",
      "Training 10/49\n",
      "Total iteration: 17\n",
      "Epoch 11/50 [15122020-042516]\n",
      "AccVal: 0.8409037968786397\n",
      "AUCVal: 0.919039363433076\n",
      "Precision: 0.8318713307380676\n",
      "Recall: 0.8347188234329224\n",
      "F1Val: 0.8332926147071931\n",
      "LossVal: 0.3928071320056915\n",
      "LossTrain: 0.19528480750672958\n",
      "----------\n",
      "\n",
      "Training 11/49\n",
      "Total iteration: 17\n",
      "Epoch 12/50 [15122020-042517]\n",
      "AccVal: 0.8411367342184952\n",
      "AUCVal: 0.9186336781839222\n",
      "Precision: 0.831953227519989\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.8335773767623109\n",
      "LossVal: 0.39611874222755433\n",
      "LossTrain: 0.1856322218390072\n",
      "----------\n",
      "\n",
      "Training 12/49\n",
      "Total iteration: 17\n",
      "Epoch 13/50 [15122020-042518]\n",
      "AccVal: 0.8395061728395061\n",
      "AUCVal: 0.918132716720758\n",
      "Precision: 0.8300876617431641\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8319102355603516\n",
      "LossVal: 0.40052802562713624\n",
      "LossTrain: 0.17990697920322418\n",
      "----------\n",
      "\n",
      "Training 13/49\n",
      "Total iteration: 17\n",
      "Epoch    14: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 14/50 [15122020-042519]\n",
      "AccVal: 0.8395061728395061\n",
      "AUCVal: 0.9177892437939944\n",
      "Precision: 0.8307316899299622\n",
      "Recall: 0.8327628374099731\n",
      "F1Val: 0.8317459938395398\n",
      "LossVal: 0.4045708179473877\n",
      "LossTrain: 0.16989484692321105\n",
      "----------\n",
      "\n",
      "Training 14/49\n",
      "Total iteration: 17\n",
      "Epoch 15/50 [15122020-042520]\n",
      "AccVal: 0.839040298159795\n",
      "AUCVal: 0.91769048717034\n",
      "Precision: 0.8302438855171204\n",
      "Recall: 0.8322738409042358\n",
      "F1Val: 0.8312575941076683\n",
      "LossVal: 0.40651663541793825\n",
      "LossTrain: 0.15657025312676148\n",
      "----------\n",
      "\n",
      "Training 15/49\n",
      "Total iteration: 17\n",
      "Epoch 16/50 [15122020-042522]\n",
      "AccVal: 0.8392732354996506\n",
      "AUCVal: 0.9175582316038597\n",
      "Precision: 0.8303266763687134\n",
      "Recall: 0.8327628374099731\n",
      "F1Val: 0.8315429725955426\n",
      "LossVal: 0.4089571893215179\n",
      "LossTrain: 0.15040229699190924\n",
      "----------\n",
      "\n",
      "Training 16/49\n",
      "Total iteration: 17\n",
      "Epoch 17/50 [15122020-042523]\n",
      "AccVal: 0.8402049848590729\n",
      "AUCVal: 0.9173757276231411\n",
      "Precision: 0.8322738409042358\n",
      "Recall: 0.8322738409042358\n",
      "F1Val: 0.8322738409042358\n",
      "LossVal: 0.41191841959953307\n",
      "LossTrain: 0.14677916554843679\n",
      "----------\n",
      "\n",
      "Training 17/49\n",
      "Total iteration: 17\n",
      "Epoch    18: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 18/50 [15122020-042524]\n",
      "AccVal: 0.839040298159795\n",
      "AUCVal: 0.9171629875836385\n",
      "Precision: 0.8315377235412598\n",
      "Recall: 0.8303178548812866\n",
      "F1Val: 0.8309273414950075\n",
      "LossVal: 0.4146101772785187\n",
      "LossTrain: 0.1430623693501248\n",
      "----------\n",
      "\n",
      "Training 18/49\n",
      "Total iteration: 17\n",
      "Epoch 19/50 [15122020-042525]\n",
      "AccVal: 0.839040298159795\n",
      "AUCVal: 0.917061403127148\n",
      "Precision: 0.83056640625\n",
      "Recall: 0.8317848443984985\n",
      "F1Val: 0.8311751787906057\n",
      "LossVal: 0.41630847454071046\n",
      "LossTrain: 0.1379788636284716\n",
      "----------\n",
      "\n",
      "Training 19/49\n",
      "Total iteration: 17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d17f87198550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                      \u001b[0minit_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      dropout=0.9, batchnorm=True, checkpoint=None, model_name='TFIDF_Lem')\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, numb_epoch)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mtimestampSTART\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampDate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestampTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mlossTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderVal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mmetricsVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/Code Repo/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mnumb_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total iteration: {numb_iter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatchID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mbatch_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mbatch_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Declare and train model\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=1024, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[X_train.shape[1], 128, 1], weight_decay=1e-3,\n",
    "                     dropout=0.9, batchnorm=True, checkpoint=None, model_name='TFIDF_Lem')\n",
    "model_mlp.train(numb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL AT TFIDF_Lem-15122020-042501.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9705899481684235,\n",
       " 'precision': 0.97219145,\n",
       " 'recall': 0.96589243,\n",
       " 'f1': 0.9690317072443284,\n",
       " 'tp': 7901,\n",
       " 'tn': 8765,\n",
       " 'fp': 226,\n",
       " 'fn': 279,\n",
       " 'auc': 0.9956610372937458}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrain model and evaluate on train / validate\n",
    "dataloader = make_dalaloader(datasetTrain, batch_size=1024)\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=1024, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[X_train.shape[1], 128, 1], weight_decay=1e-3,\n",
    "                     dropout=0.9, batchnorm=True, checkpoint='TFIDF_Lem-15122020-042501.pth.tar', model_name='TFIDF_Raw')\n",
    "model_mlp.load_trained_model()\n",
    "metrics = model_mlp.evaluate(dataloader)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
