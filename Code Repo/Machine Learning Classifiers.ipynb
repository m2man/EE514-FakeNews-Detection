{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Classifiers\n",
    "Run several machine learning classifiers (SVM, RF, Logistic Regression) with 24 basic features as well as BOW and TFIDF embedding features. Also calculate feature importance from RF, and feature selection on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.ranking module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from myfunctions import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Normalize data function\n",
    "def normalize_data(X, list_mean=[], list_std=[]):\n",
    "    nrow, ncol = X.shape\n",
    "    if len(list_mean) == 0 or len(list_std) == 0:\n",
    "        x_mean = np.asarray(np.mean(X, axis=0))\n",
    "        x_std = np.std(X, axis=0)\n",
    "        list_mean = list(x_mean)\n",
    "        list_std = list(x_std)\n",
    "    else:\n",
    "        x_mean = np.asarray(list_mean)\n",
    "        x_std = np.asarray(list_std)\n",
    "    x_mean = x_mean.reshape(1,-1)\n",
    "    x_std = x_std.reshape(1, -1)\n",
    "    x_mean = np.repeat(x_mean, nrow, axis=0)\n",
    "    x_std = np.repeat(x_std, nrow, axis=0)\n",
    "    X_norm = (X - x_mean) / x_std\n",
    "    return X_norm, list_mean, list_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extract Features\n",
    "This section to extract 24 features from the dataset. Warning: take a while to finish. Therefore I extracted and save into joblib files (Can skip this part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TRAINING SAMPLES =====\n",
      "Total Sample: 17171\n",
      "Sarcastic: 8180 (47.64%)\n",
      "Not Sarcastic: 8991 (52.36%)\n",
      "===== VALIDATING SAMPLES =====\n",
      "Total Sample: 4293\n",
      "Sarcastic: 2045 (47.64%)\n",
      "Not Sarcastic: 2248 (52.36%)\n",
      "===== TESTING SAMPLES =====\n",
      "Total Sample: 7155\n",
      "Sarcastic: 3409 (47.65%)\n",
      "Not Sarcastic: 3746 (52.35%)\n"
     ]
    }
   ],
   "source": [
    "data_full = pd.read_json('fake_news.json', lines=True)\n",
    "data_full = data_full.drop(columns=['article_link']) # remove link column\n",
    "df_train_f, df_test = split_dataframe(data_full, test_size=0.25, seed=1509)\n",
    "df_train, df_validate = split_dataframe(df_train_f, test_size=0.2, seed=1309)\n",
    "\n",
    "# Proportion of each subsets\n",
    "list_label = df_train['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TRAINING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_validate['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== VALIDATING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_test['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TESTING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "data_train = df_train.copy()\n",
    "data_train_f = df_train_f.copy()\n",
    "data_val = df_validate.copy()\n",
    "data_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_basic(data_input):\n",
    "    '''\n",
    "    Input: data is the dataframe with only is_sarcastic and headline column\n",
    "    Output: data with full features (except headline column)\n",
    "    '''\n",
    "    data = data_input.copy()\n",
    "    data['len_headline'] = data.headline.apply(lambda row: count_word(row)) # count words in title\n",
    "    data['headline_s1'] = data.headline.apply(lambda row: remove_symbol(row))\n",
    "    data['len_headline_s1'] = data.headline_s1.apply(lambda row: count_word(row))    \n",
    "    \n",
    "    data['len_char_s1'] = data.headline_s1.apply(lambda row: len(row))\n",
    "    data['len_char_headline'] = data.headline.apply(lambda row: len(row))\n",
    "    data['count_symbol'] = data.len_char_headline - data.len_char_s1\n",
    "    data['count_symbol_norm'] = data.count_symbol / data.len_char_headline\n",
    "    \n",
    "    data['headline_s2'] = data.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "    data['headline_s2'] = data.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "    data['len_headline_s2'] = data.headline_s2.apply(lambda row: count_word(row))\n",
    "    data['count_lemmatized'] = count_lemmatized_word(data, 'headline_s1', 'headline_s2')\n",
    "    data['ratio_lemmatized'] = data['count_lemmatized'] / data['len_headline_s1']\n",
    "    data['headline_s3'] = data.headline_s2.apply(lambda row: remove_stop_words(row))\n",
    "    data['len_headline_s3'] = data.headline_s3.apply(lambda row: count_word(row))\n",
    "    data['numb_stopwords'] = data['len_headline_s2'] - data['len_headline_s3']\n",
    "    data['ratio_stopwords'] = data['numb_stopwords'] / data['len_headline_s2']\n",
    "    data['min_len_word'] = data.headline_s1.apply(lambda row: min_len_word(row))\n",
    "    data['max_len_word'] = data.headline_s1.apply(lambda row: max_len_word(row))\n",
    "    data['avg_len_word'] = data.headline_s1.apply(lambda row: avg_len_word(row))\n",
    "    data['max_syl_word'] = data.headline_s1.apply(lambda row: max_syl_word(row))\n",
    "    data['avg_syl_word'] = data.headline_s1.apply(lambda row: avg_syl_word(row))\n",
    "    data['numb_syl'] = data.headline_s1.apply(lambda row: count_syllable(row))\n",
    "    data['norm_numb_syl'] = data.numb_syl / data.len_headline_s1\n",
    "    data['flesch_grade_score'] = data.headline.apply(lambda row: textstat.flesch_kincaid_grade(row))\n",
    "    data['ari_score'] = data.headline.apply(lambda row: textstat.automated_readability_index(row))\n",
    "    data['coleman_score'] = data.headline.apply(lambda row: textstat.coleman_liau_index(row))\n",
    "    data['linsear_score'] = data.headline.apply(lambda row: textstat.linsear_write_formula(row))\n",
    "    data['dale_score'] = data.headline.apply(lambda row: textstat.dale_chall_readability_score(row))\n",
    "    data['standard_score'] = data.headline.apply(lambda row: textstat.text_standard(row, float_output=True))\n",
    "    data['numb_NN'] = data.headline.apply(lambda row: count_noun(row))\n",
    "    data['numb_VED'] = data.headline.apply(lambda row: count_verb_past(row))\n",
    "    data['numb_VB'] = data.headline.apply(lambda row: count_verb_present(row))\n",
    "    data['numb_VING'] = data.headline.apply(lambda row: count_verb_ing(row))\n",
    "    data['numb_ADJ'] = data.headline.apply(lambda row: count_adj(row))\n",
    "    data['numb_ADV'] = data.headline.apply(lambda row: count_adv(row))\n",
    "    data['numb_DT'] = data.headline.apply(lambda row: count_DT(row))\n",
    "    data['numb_CD'] = data.headline.apply(lambda row: count_CD(row))\n",
    "    data['numb_PR'] = data.headline.apply(lambda row: count_pronoun(row))\n",
    "    data['norm_numb_NN'] = data['numb_NN'] / data['len_headline']\n",
    "    data['norm_numb_VED'] = data['numb_VED'] / data['len_headline']\n",
    "    data['norm_numb_VB'] = data['numb_VB'] / data['len_headline']\n",
    "    data['norm_numb_VING'] = data['numb_VING'] / data['len_headline']\n",
    "    data['norm_numb_ADJ'] = data['numb_ADJ'] / data['len_headline']\n",
    "    data['norm_numb_ADV'] = data['numb_ADV'] / data['len_headline']\n",
    "    data['norm_numb_DT'] = data['numb_DT'] / data['len_headline']\n",
    "    data['norm_numb_CD'] = data['numb_CD'] / data['len_headline']\n",
    "    data['norm_numb_PR'] = data['numb_PR'] / data['len_headline']\n",
    "        \n",
    "    data_ft = data.drop(columns=['numb_syl', 'count_symbol', 'len_char_s1', 'len_char_headline',\n",
    "                                 'count_lemmatized', 'numb_stopwords', 'norm_numb_syl',\n",
    "                                 'len_headline_s1', 'len_headline_s2', 'len_headline_s3', \n",
    "                                 'headline', 'headline_s1', 'headline_s2', 'headline_s3', \n",
    "                                 'numb_NN', 'numb_VED', 'numb_VB', 'numb_VING', \n",
    "                                 'numb_ADJ', 'numb_ADV', 'numb_DT', 'numb_CD', 'numb_PR'])\n",
    "    \n",
    "    return data_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_train_f_basic_ft.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_ft = extract_feature_basic(data_train)\n",
    "data_train_ft = extract_feature_basic(data_train_f)\n",
    "data_val_ft = extract_feature_basic(data_val)\n",
    "data_test_ft = extract_feature_basic(data_test)\n",
    "\n",
    "joblib.dump(data_train_ft, 'data_train_basic_ft.joblib')\n",
    "joblib.dump(data_train_ft, 'data_train_f_basic_ft.joblib')\n",
    "joblib.dump(data_val_ft, 'data_val_basic_ft.joblib')\n",
    "joblib.dump(data_test_ft, 'data_test_basic_ft.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare Features\n",
    "Load extracted features from joblib and create X and Y matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_train_f_ft = joblib.load('data_train_f_basic_ft.joblib')\n",
    "data_train_ft = joblib.load('data_train_basic_ft.joblib')\n",
    "data_val_ft = joblib.load('data_val_basic_ft.joblib')\n",
    "data_test_ft = joblib.load('data_test_basic_ft.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_f = data_train_f_ft.drop(columns=['is_sarcastic'])\n",
    "y_train_f = data_train_f_ft['is_sarcastic']\n",
    "X_train_f = np.asarray(X_train_f)\n",
    "y_train_f = np.asarray(y_train_f)\n",
    "\n",
    "X_train = data_train_ft.drop(columns=['is_sarcastic'])\n",
    "y_train = data_train_ft['is_sarcastic']\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "X_val = data_val_ft.drop(columns=['is_sarcastic'])\n",
    "y_val = data_val_ft['is_sarcastic']\n",
    "X_val = np.asarray(X_val)\n",
    "y_val = np.asarray(y_val)\n",
    "\n",
    "X_test = data_test_ft.drop(columns=['is_sarcastic'])\n",
    "y_test = data_test_ft['is_sarcastic']\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "feature_names = list(data_val_ft.drop(columns=['is_sarcastic']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Features\n",
    "Run classifiers with 24 basic features. All were run with cross validation GridSearch to find the best hyper-parameters. Note that I ran the cross validation on the combined set of training and validating data. Then chose the best parameters to train again on training set and evaluate on validating set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random Forest\n",
    "This include plotting feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB Score: 0.7258664541791846\n",
      "Best paras: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'max_depth': [5, 10, 15, 20, 25, 30],\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'min_samples_split': [5, 7, 10],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "}\n",
    "\n",
    "model_cv_rf = GridSearchCV(RandomForestClassifier(random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_rf.fit(X_train_f, y_train_f);\n",
    "print(f\"Best OOB Score: {model_cv_rf.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.9014035292062198, 'precision': 0.8864529965447396, 'recall': 0.9095354523227384, 'f1': 0.897845893923852, 'tp': 7440, 'tn': 8038, 'fp': 953, 'fn': 740, 'auc': 0.9711388514295333}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7239692522711391, 'precision': 0.7049571020019065, 'recall': 0.7232273838630807, 'f1': 0.713975380159305, 'tp': 1479, 'tn': 1629, 'fp': 619, 'fn': 566, 'auc': 0.803400577748001}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'random_state': 1509,\n",
    "    'max_depth': 15,\n",
    "    'n_estimators': 500,\n",
    "    'min_samples_split': 7,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "model_rf = RandomForestClassifier(**hypara)\n",
    "model_rf.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "train_pred = model_rf.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_rf.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = permutation_importance(model_rf, X_train, y_train, n_repeats=10,\n",
    "                                random_state=1509, n_jobs=-1)\n",
    "sorted_idx = result.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_syl_word</th>\n",
       "      <th>norm_numb_CD</th>\n",
       "      <th>max_len_word</th>\n",
       "      <th>standard_score</th>\n",
       "      <th>avg_syl_word</th>\n",
       "      <th>norm_numb_PR</th>\n",
       "      <th>linsear_score</th>\n",
       "      <th>avg_len_word</th>\n",
       "      <th>flesch_grade_score</th>\n",
       "      <th>coleman_score</th>\n",
       "      <th>...</th>\n",
       "      <th>norm_numb_VB</th>\n",
       "      <th>min_len_word</th>\n",
       "      <th>dale_score</th>\n",
       "      <th>norm_numb_NN</th>\n",
       "      <th>len_headline</th>\n",
       "      <th>norm_numb_ADJ</th>\n",
       "      <th>norm_numb_ADV</th>\n",
       "      <th>ratio_stopwords</th>\n",
       "      <th>count_symbol_norm</th>\n",
       "      <th>norm_numb_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006756</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.017355</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.025217</td>\n",
       "      <td>0.026848</td>\n",
       "      <td>0.026091</td>\n",
       "      <td>0.026440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030808</td>\n",
       "      <td>0.031448</td>\n",
       "      <td>0.033778</td>\n",
       "      <td>0.033137</td>\n",
       "      <td>0.035409</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>0.055093</td>\n",
       "      <td>0.055209</td>\n",
       "      <td>0.088288</td>\n",
       "      <td>0.106051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.017704</td>\n",
       "      <td>0.021606</td>\n",
       "      <td>0.025042</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.027139</td>\n",
       "      <td>0.027197</td>\n",
       "      <td>0.027022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030924</td>\n",
       "      <td>0.031332</td>\n",
       "      <td>0.033836</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>0.036224</td>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.051832</td>\n",
       "      <td>0.056199</td>\n",
       "      <td>0.087531</td>\n",
       "      <td>0.107682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.013977</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.024402</td>\n",
       "      <td>0.025275</td>\n",
       "      <td>0.026149</td>\n",
       "      <td>0.026382</td>\n",
       "      <td>0.025566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.032380</td>\n",
       "      <td>0.031681</td>\n",
       "      <td>0.035117</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.051599</td>\n",
       "      <td>0.057131</td>\n",
       "      <td>0.087240</td>\n",
       "      <td>0.106866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.013744</td>\n",
       "      <td>0.017355</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.025566</td>\n",
       "      <td>0.027838</td>\n",
       "      <td>0.026731</td>\n",
       "      <td>0.027255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031973</td>\n",
       "      <td>0.031973</td>\n",
       "      <td>0.033545</td>\n",
       "      <td>0.034418</td>\n",
       "      <td>0.036399</td>\n",
       "      <td>0.037622</td>\n",
       "      <td>0.052530</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.086425</td>\n",
       "      <td>0.105469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007746</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.012638</td>\n",
       "      <td>0.018636</td>\n",
       "      <td>0.021373</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>0.026323</td>\n",
       "      <td>0.026556</td>\n",
       "      <td>0.026556</td>\n",
       "      <td>0.026149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.033778</td>\n",
       "      <td>0.033778</td>\n",
       "      <td>0.033953</td>\n",
       "      <td>0.036632</td>\n",
       "      <td>0.038029</td>\n",
       "      <td>0.053055</td>\n",
       "      <td>0.055734</td>\n",
       "      <td>0.086308</td>\n",
       "      <td>0.108439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_syl_word  norm_numb_CD  max_len_word  standard_score  avg_syl_word  \\\n",
       "0      0.006756      0.009959      0.014152        0.017355      0.022247   \n",
       "1      0.007454      0.010774      0.014676        0.017704      0.021606   \n",
       "2      0.007338      0.009202      0.013977        0.017530      0.021082   \n",
       "3      0.007804      0.009551      0.013744        0.017355      0.023295   \n",
       "4      0.007746      0.010483      0.012638        0.018636      0.021373   \n",
       "\n",
       "   norm_numb_PR  linsear_score  avg_len_word  flesch_grade_score  \\\n",
       "0      0.025799       0.025217      0.026848            0.026091   \n",
       "1      0.025042       0.025974      0.027139            0.027197   \n",
       "2      0.024402       0.025275      0.026149            0.026382   \n",
       "3      0.025974       0.025566      0.027838            0.026731   \n",
       "4      0.025392       0.026323      0.026556            0.026556   \n",
       "\n",
       "   coleman_score  ...  norm_numb_VB  min_len_word  dale_score  norm_numb_NN  \\\n",
       "0       0.026440  ...      0.030808      0.031448    0.033778      0.033137   \n",
       "1       0.027022  ...      0.030924      0.031332    0.033836      0.033603   \n",
       "2       0.025566  ...      0.031623      0.032380    0.031681      0.035117   \n",
       "3       0.027255  ...      0.031973      0.031973    0.033545      0.034418   \n",
       "4       0.026149  ...      0.030051      0.033778    0.033778      0.033953   \n",
       "\n",
       "   len_headline  norm_numb_ADJ  norm_numb_ADV  ratio_stopwords  \\\n",
       "0      0.035409       0.035583       0.055093         0.055209   \n",
       "1      0.036224       0.036923       0.051832         0.056199   \n",
       "2      0.035700       0.038437       0.051599         0.057131   \n",
       "3      0.036399       0.037622       0.052530         0.055559   \n",
       "4      0.036632       0.038029       0.053055         0.055734   \n",
       "\n",
       "   count_symbol_norm  norm_numb_DT  \n",
       "0           0.088288      0.106051  \n",
       "1           0.087531      0.107682  \n",
       "2           0.087240      0.106866  \n",
       "3           0.086425      0.105469  \n",
       "4           0.086308      0.108439  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = result.importances[sorted_idx].T\n",
    "labels= np.asarray(feature_names)[sorted_idx]\n",
    "ft_imp_df = pd.DataFrame()\n",
    "for idx in range(values.shape[1]):\n",
    "    ft_imp_df[labels[idx]] = values[:,idx]\n",
    "ft_imp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(22,12))\n",
    "\n",
    "sns.boxplot(data=ft_imp_df, orient=\"h\", color=\"#35dbd0\")\n",
    "plt.xlabel('Feature importance', fontsize=20)\n",
    "plt.ylabel('Feature Names', fontsize=20)\n",
    "plt.tick_params(axis='both', which='major', labelsize=17)\n",
    "plt.savefig('../figures/RF_Ft_Imp.png', bbox_inches='tight', transparent=False, dpi=350)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.6978198432655167\n",
      "Best paras: {'C': 10, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_f_norm, _, _ = normalize_data(X_train_f, [], [])\n",
    "\n",
    "hypara = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [10, 20, 30, 40, 50],\n",
    "}\n",
    "\n",
    "model_cv_lr = GridSearchCV(LogisticRegression(max_iter=2000, tol=1e-5, solver='saga', random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_lr.fit(X_train_f_norm, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_lr.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.6980956263467474, 'precision': 0.6743482309124768, 'recall': 0.7083129584352078, 'f1': 0.6909134271404722, 'tp': 5794, 'tn': 6193, 'fp': 2798, 'fn': 2386, 'auc': 0.765356051514704}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7037037037037037, 'precision': 0.6778647031753336, 'recall': 0.7202933985330073, 'f1': 0.6984352773826459, 'tp': 1473, 'tn': 1548, 'fp': 700, 'fn': 572, 'auc': 0.7718948220205519}\n"
     ]
    }
   ],
   "source": [
    "X_train_norm, x_mean, x_std = normalize_data(X_train, [], [])\n",
    "X_val_norm, _, _ = normalize_data(X_val, x_mean, x_std)\n",
    "\n",
    "\n",
    "hypara = {\n",
    "    'penalty': 'l1',\n",
    "    'C': 10,\n",
    "    'max_iter': 5000,\n",
    "    'tol': 1e-5,\n",
    "    'solver': 'saga',\n",
    "    'random_state': 1509\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression(**hypara)\n",
    "model_lr.fit(X_train_norm, y_train);\n",
    "\n",
    "train_pred = model_lr.predict_proba(X_train_norm)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_lr.predict_proba(X_val_norm)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.04607715  0.01744879  0.21414481  0.26219142  2.17005218  9.47647223\n",
      "  5.2931261   3.03158777  1.56733191  6.87450149  9.04673873 11.50190645\n",
      "  5.30590757  8.63816949  7.6771804   0.41238513  0.03349773  0.10202515\n",
      "  0.03292514  0.22984578  0.04233041  0.04136632  0.01851094  0.02594399]\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.7273574702440457\n",
      "Best paras: {'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVM need normalization\n",
    "X_train_f_norm, _, _ = normalize_data(X_train_f, [], [])\n",
    "\n",
    "hypara = {\n",
    "    'C': [0.1, 1, 5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "model_cv_svm = GridSearchCV(SVC(max_iter=10000, tol=1e-5, random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_svm.fit(X_train_f_norm, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_svm.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_svm.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.7682138489313377, 'precision': 0.7556610664718773, 'recall': 0.75880195599022, 'f1': 0.7572282542393558, 'tp': 6207, 'tn': 6984, 'fp': 2007, 'fn': 1973, 'auc': 0.8500696431285945}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7370137433030515, 'precision': 0.726061204343534, 'recall': 0.7193154034229828, 'f1': 0.7226725620240727, 'tp': 1471, 'tn': 1693, 'fp': 555, 'fn': 574, 'auc': 0.8060060994179015}\n"
     ]
    }
   ],
   "source": [
    "# SVM need normalization\n",
    "X_train_norm, x_mean, x_std = normalize_data(X_train, [], [])\n",
    "X_val_norm, _, _ = normalize_data(X_val, x_mean, x_std)\n",
    "\n",
    "hypara = {\n",
    "    'C': 1,\n",
    "    'random_state': 1509,\n",
    "    'max_iter':50000,\n",
    "    'tol' : 1e-5\n",
    "}\n",
    "model_svm = SVC(**hypara, probability=True)\n",
    "model_svm.fit(X_train_norm, y_train);\n",
    "\n",
    "train_pred = model_svm.predict_proba(X_train_norm)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_svm.predict_proba(X_val_norm)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## MLP\n",
    "This part use the built-in class of scikit-learn (hence just basic structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   43.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB Score: 0.7319229227058331\n",
      "Best paras: {'hidden_layer_sizes': (16,), 'learning_rate_init': 0.005}\n"
     ]
    }
   ],
   "source": [
    "X_train_f_norm, _, _ = normalize_data(X_train_f, [], [])\n",
    "\n",
    "hypara = {\n",
    "    'hidden_layer_sizes': 1,\n",
    "    'learning_rate_init': [0.005, 0.001, 0.01, 0.05],\n",
    "    \n",
    "}\n",
    "\n",
    "model_cv_mlp = GridSearchCV(MLPClassifier(max_iter=2000, random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_mlp.fit(X_train_f_norm, y_train_f);\n",
    "print(f\"Best OOB Score: {model_cv_mlp.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_mlp.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.7498107273892027, 'precision': 0.7363680623174295, 'recall': 0.7396088019559902, 'f1': 0.7379848743595999, 'tp': 6050, 'tn': 6825, 'fp': 2166, 'fn': 2130, 'auc': 0.8311534843727183}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7246680642907058, 'precision': 0.7110024449877751, 'recall': 0.7110024449877751, 'f1': 0.7110024449877751, 'tp': 1454, 'tn': 1657, 'fp': 591, 'fn': 591, 'auc': 0.8029846687955171}\n"
     ]
    }
   ],
   "source": [
    "# SVM need normalization\n",
    "X_train_norm, x_mean, x_std = normalize_data(X_train, [], [])\n",
    "X_val_norm, _, _ = normalize_data(X_val, x_mean, x_std)\n",
    "\n",
    "hypara = {\n",
    "    'hidden_layer_sizes': (16,),\n",
    "    'learning_rate_init': 0.005,\n",
    "}\n",
    "model_mlp = MLPClassifier(**hypara, max_iter=2000, random_state=1509)\n",
    "model_mlp.fit(X_train_norm, y_train);\n",
    "\n",
    "train_pred = model_mlp.predict_proba(X_train_norm)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_mlp.predict_proba(X_val_norm)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Feature selection with Logistic Regression\n",
    "Run Logistic regression with L1 loss to check which features having coefficient as 0 making them became less useful and can be eliminated. However none of them have 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   58.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.6839826705907817\n",
      "Best paras: {'C': 20, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'penalty': ['l1'],\n",
    "    'C': [1, 5, 10, 20, 30, 40, 50],\n",
    "}\n",
    "\n",
    "model_cv_lr = GridSearchCV(LogisticRegression(max_iter=2000, tol=1e-5, solver='saga', random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_lr.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_lr.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.6980956263467474, 'precision': 0.6743482309124768, 'recall': 0.7083129584352078, 'f1': 0.6909134271404722, 'tp': 5794, 'tn': 6193, 'fp': 2798, 'fn': 2386, 'auc': 0.765356051514704}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7037037037037037, 'precision': 0.6778647031753336, 'recall': 0.7202933985330073, 'f1': 0.6984352773826459, 'tp': 1473, 'tn': 1548, 'fp': 700, 'fn': 572, 'auc': 0.7718948220205519}\n"
     ]
    }
   ],
   "source": [
    "X_train_norm, x_mean, x_std = normalize_data(X_train, [], [])\n",
    "X_val_norm, _, _ = normalize_data(X_val, x_mean, x_std)\n",
    "\n",
    "\n",
    "hypara = {\n",
    "    'penalty': 'l1',\n",
    "    'C': 10,\n",
    "    'max_iter': 5000,\n",
    "    'tol': 1e-5,\n",
    "    'solver': 'saga',\n",
    "    'random_state': 1509\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression(**hypara)\n",
    "model_lr.fit(X_train_norm, y_train);\n",
    "\n",
    "train_pred = model_lr.predict_proba(X_train_norm)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_lr.predict_proba(X_val_norm)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression coefficient\n",
    "imp_word_idx = list(np.argsort(np.abs(model_lr.coef_[0]))[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.09517654, -4.85841987, -1.31408215, -1.06862329,  0.86270645,\n",
       "       -0.61646543, -0.53866337, -0.44428294,  0.34963795, -0.29535175,\n",
       "        0.28947385,  0.28833098,  0.28712512, -0.2297851 , -0.18486482,\n",
       "        0.17865078, -0.15272407,  0.124895  ,  0.10939153, -0.08837382,\n",
       "       -0.06434122,  0.05604005,  0.04307724, -0.0377157 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = model_lr.coef_[0][imp_word_idx]\n",
    "labels = np.asarray(feature_names)[imp_word_idx]\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ari_score', 'avg_len_word', 'len_headline', 'count_symbol_norm',\n",
       "       'avg_syl_word', 'norm_numb_DT', 'coleman_score',\n",
       "       'flesch_grade_score', 'norm_numb_ADV', 'ratio_stopwords',\n",
       "       'norm_numb_VED', 'norm_numb_VING', 'norm_numb_ADJ', 'dale_score',\n",
       "       'max_syl_word', 'max_len_word', 'norm_numb_PR', 'norm_numb_VB',\n",
       "       'norm_numb_NN', 'standard_score', 'norm_numb_CD', 'linsear_score',\n",
       "       'min_len_word', 'ratio_lemmatized'], dtype='<U18')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Embedding Features - BOW\n",
    "BOW embedding features. Try on both original sentences and lemmatised headlines. This section has feature selection with Logistic Regression to find useless words that having coefficients of 0 (can be discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TRAINING SAMPLES =====\n",
      "Total Sample: 17171\n",
      "Sarcastic: 8180 (47.64%)\n",
      "Not Sarcastic: 8991 (52.36%)\n",
      "===== VALIDATING SAMPLES =====\n",
      "Total Sample: 4293\n",
      "Sarcastic: 2045 (47.64%)\n",
      "Not Sarcastic: 2248 (52.36%)\n",
      "===== TESTING SAMPLES =====\n",
      "Total Sample: 7155\n",
      "Sarcastic: 3409 (47.65%)\n",
      "Not Sarcastic: 3746 (52.35%)\n"
     ]
    }
   ],
   "source": [
    "data_full = pd.read_json('fake_news.json', lines=True)\n",
    "data_full = data_full.drop(columns=['article_link']) # remove link column\n",
    "df_train_f, df_test = split_dataframe(data_full, test_size=0.25, seed=1509)\n",
    "df_train, df_validate = split_dataframe(df_train_f, test_size=0.2, seed=1309)\n",
    "\n",
    "# Proportion of each subsets\n",
    "list_label = df_train['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TRAINING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_validate['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== VALIDATING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_test['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TESTING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "data_train = df_train.copy()\n",
    "data_train_f = df_train_f.copy()\n",
    "data_val = df_validate.copy()\n",
    "data_test = df_test.copy()\n",
    "\n",
    "data_train = df_train\n",
    "data_train['headline'] = data_train.headline.apply(lambda row: row.lower())\n",
    "data_train['headline_s1'] = data_train.headline.apply(lambda row: remove_symbol(row))\n",
    "data_train['headline_s2'] = data_train.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_train['headline_s2'] = data_train.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "#data_train = data_train.drop(columns=['headline', 'headline_s1'])\n",
    "\n",
    "data_train_f = df_train_f\n",
    "data_train_f['headline'] = data_train_f.headline.apply(lambda row: row.lower())\n",
    "data_train_f['headline_s1'] = data_train_f.headline.apply(lambda row: remove_symbol(row))\n",
    "data_train_f['headline_s2'] = data_train_f.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_train_f['headline_s2'] = data_train_f.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "\n",
    "data_val = df_validate\n",
    "data_val['headline'] = data_val.headline.apply(lambda row: row.lower())\n",
    "data_val['headline_s1'] = data_val.headline.apply(lambda row: remove_symbol(row))\n",
    "data_val['headline_s2'] = data_val.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_val['headline_s2'] = data_val.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "#data_val = data_val.drop(columns=['headline', 'headline_s1'])\n",
    "\n",
    "data_test = df_test\n",
    "data_test['headline'] = data_test.headline.apply(lambda row: row.lower())\n",
    "data_test['headline_s1'] = data_test.headline.apply(lambda row: remove_symbol(row))\n",
    "data_test['headline_s2'] = data_test.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_test['headline_s2'] = data_test.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Raw Sentence\n",
    "Also have feature selection with Logistic Regression in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda text: text.split())\n",
    "all_string = data_train.headline_s1.tolist()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(all_string)\n",
    "\n",
    "vocab = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "vocab = list(vocab)\n",
    "\n",
    "# encode document\n",
    "X_train_f = vectorizer.transform(data_train_f.headline_s1.tolist())\n",
    "y_train_f = data_train_f.is_sarcastic.to_numpy()\n",
    "\n",
    "X_train = vectorizer.transform(data_train.headline_s1.tolist())\n",
    "y_train = data_train.is_sarcastic.to_numpy()\n",
    "\n",
    "X_val = vectorizer.transform(data_val.headline_s1.tolist())\n",
    "y_val = data_val.is_sarcastic.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.8454159212346157\n",
      "Best paras: {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 5, 10, 20],\n",
    "}\n",
    "\n",
    "model_cv_lr = GridSearchCV(LogisticRegression(max_iter=5000, tol=1e-4, solver='liblinear', random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_lr.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_lr.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.9721041290548017, 'precision': 0.9735579879473619, 'recall': 0.9677261613691932, 'f1': 0.9706333149408375, 'tp': 7916, 'tn': 8776, 'fp': 215, 'fn': 264, 'auc': 0.9947238327705593}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8474260423945958, 'precision': 0.8420275590551181, 'recall': 0.8366748166259169, 'f1': 0.8393426539121902, 'tp': 1711, 'tn': 1927, 'fp': 321, 'fn': 334, 'auc': 0.9219143993248006}\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': 'l2',\n",
    "    'C': 1,\n",
    "    'max_iter': 5000,\n",
    "    'tol': 1e-5,\n",
    "    'solver': 'liblinear',\n",
    "    'random_state': 1509\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression(**hypara)\n",
    "model_lr.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_lr.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_lr.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB Score: 0.7631848829962037\n",
      "Best paras: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "## RF\n",
    "hypara = {\n",
    "    'max_depth': [15, 20],\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'min_samples_split': [5, 7, 10],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "}\n",
    "\n",
    "model_cv_rf = GridSearchCV(RandomForestClassifier(random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_rf.fit(X_train_f, y_train_f);\n",
    "print(f\"Best OOB Score: {model_cv_rf.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.7798031564847708, 'precision': 0.9073902574550843, 'recall': 0.5988997555012225, 'f1': 0.7215553428087489, 'tp': 4899, 'tn': 8491, 'fp': 500, 'fn': 3281, 'auc': 0.9077895472217666}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7579781038900536, 'precision': 0.8839694656488549, 'recall': 0.5662591687041565, 'f1': 0.6903129657228018, 'tp': 1158, 'tn': 2096, 'fp': 152, 'fn': 887, 'auc': 0.8865448450782658}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'random_state': 1509,\n",
    "    'max_depth': 20,\n",
    "    'n_estimators': 400,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "model_rf = RandomForestClassifier(**hypara)\n",
    "model_rf.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "train_pred = model_rf.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_rf.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.8527303707958664\n",
      "Best paras: {'C': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': [0.1, 1, 5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "model_cv_svm = GridSearchCV(SVC(max_iter=5000, tol=1e-4, random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_svm.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_svm.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_svm.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'tp': 8180, 'tn': 8991, 'fp': 0, 'fn': 0, 'auc': 1.0}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8457954810156068, 'precision': 0.8466165413533835, 'recall': 0.8259168704156479, 'f1': 0.8361386138613861, 'tp': 1689, 'tn': 1942, 'fp': 306, 'fn': 356, 'auc': 0.9241927624881449}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': 20,\n",
    "    'random_state': 1509,\n",
    "    'max_iter':5000,\n",
    "    'tol' : 1e-4\n",
    "}\n",
    "model_svm = SVC(**hypara, probability=True)\n",
    "model_svm.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_svm.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_svm.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Feature Selection with Logistic Regression\n",
    "Run LR model again with L1 to find useless words. Then I removed them and train LR again (with L1 again). The result show that the metrics remain exactly the same. \n",
    "\n",
    "I also train other classifiers again after remove useless words. The result slightly decrease but still acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.835305908814909\n",
      "Best paras: {'C': 1, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  25 | elapsed:    1.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': ['l1'],\n",
    "    'C': [0.1, 1, 5, 10, 20],\n",
    "}\n",
    "\n",
    "model_cv_lr = GridSearchCV(LogisticRegression(max_iter=5000, tol=1e-4, solver='liblinear', random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_lr.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_lr.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.9157300099004135, 'precision': 0.9053582179409994, 'recall': 0.9191931540342299, 'f1': 0.9122232332423414, 'tp': 7519, 'tn': 8205, 'fp': 786, 'fn': 661, 'auc': 0.9735526072119388}\n",
      "Validate Result:\n",
      "{'accuracy': 0.831819240624272, 'precision': 0.8145506419400856, 'recall': 0.8376528117359413, 'f1': 0.8259402121504339, 'tp': 1713, 'tn': 1858, 'fp': 390, 'fn': 332, 'auc': 0.9104491686171461}\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': 'l1',\n",
    "    'C': 1,\n",
    "    'max_iter': 5000,\n",
    "    'tol': 1e-5,\n",
    "    'solver': 'liblinear',\n",
    "    'random_state': 1509\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression(**hypara)\n",
    "model_lr.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_lr.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_lr.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression coefficient\n",
    "imp_word_idx = list(np.argsort(np.abs(model_lr.coef_[0]))[::-1])\n",
    "values = model_lr.coef_[0][imp_word_idx]\n",
    "labels = np.asarray(vocab)[imp_word_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocab with 0 coefficient: 20658 words\n",
      "Some example of useless vocab: ['farm', 'farenthold', 'farmer', 'fargo', 'farley', 'doorstops', 'fares', 'door', 'fark', 'farleys']\n",
      "Some example of good vocab: ['onion', 'area', 'fucking', 'wondering', 'prose', 'reddit', 'subconscious', 'fuck', 'bitch', 'nation']\n"
     ]
    }
   ],
   "source": [
    "useless_idx = np.where(values==0)[0]\n",
    "keep_idx = np.where(values!=0)[0]\n",
    "discard_vocab = labels[useless_idx].tolist()\n",
    "keep_vocab = labels[keep_idx].tolist()\n",
    "print(f'Total vocab with 0 coefficient: {len(discard_vocab)} words')\n",
    "print(f\"Some example of useless vocab: {discard_vocab[:10]}\")\n",
    "print(f\"Some example of good vocab: {keep_vocab[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_vocab_s1.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(keep_vocab, 'selected_vocab_s1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train Again\n",
    "vectorizer = CountVectorizer(tokenizer=lambda text: text.split())\n",
    "all_string = ' '.join(keep_vocab)\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit([all_string])\n",
    "\n",
    "keep_vocab = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "keep_vocab = list(keep_vocab)\n",
    "\n",
    "# encode document\n",
    "X_train_f = vectorizer.transform(data_train_f.headline_s1.tolist())\n",
    "y_train_f = data_train_f.is_sarcastic.to_numpy()\n",
    "\n",
    "X_train = vectorizer.transform(data_train.headline_s1.tolist())\n",
    "y_train = data_train.is_sarcastic.to_numpy()\n",
    "\n",
    "X_val = vectorizer.transform(data_val.headline_s1.tolist())\n",
    "y_val = data_val.is_sarcastic.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17171, 2457)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.8682446597540938\n",
      "Best paras: {'C': 5, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 5, 10, 20],\n",
    "}\n",
    "\n",
    "model_cv_lr = GridSearchCV(LogisticRegression(max_iter=5000, tol=1e-4, solver='liblinear', random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_lr.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_lr.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.9429270281288219, 'precision': 0.9382761139517897, 'recall': 0.9421760391198044, 'f1': 0.9402220324508967, 'tp': 7707, 'tn': 8484, 'fp': 507, 'fn': 473, 'auc': 0.9866183624537332}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8336827393431167, 'precision': 0.824159766195811, 'recall': 0.8273838630806846, 'f1': 0.8257686676427526, 'tp': 1692, 'tn': 1887, 'fp': 361, 'fn': 353, 'auc': 0.9097709237877298}\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': 'l2',\n",
    "    'C': 5,\n",
    "    'max_iter': 5000,\n",
    "    'tol': 1e-5,\n",
    "    'solver': 'liblinear',\n",
    "    'random_state': 1509\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression(**hypara)\n",
    "model_lr.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_lr.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_lr.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   41.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB Score: 0.7840574363129124\n",
      "Best paras: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "## RF\n",
    "hypara = {\n",
    "    'max_depth': [15, 20],\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'min_samples_split': [5, 7, 10],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "}\n",
    "\n",
    "model_cv_rf = GridSearchCV(RandomForestClassifier(random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_rf.fit(X_train_f, y_train_f);\n",
    "print(f\"Best OOB Score: {model_cv_rf.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.8020499679692504, 'precision': 0.7602046369870469, 'recall': 0.8537897310513447, 'f1': 0.804283986871653, 'tp': 6984, 'tn': 6788, 'fp': 2203, 'fn': 1196, 'auc': 0.8890408814138779}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7868623340321453, 'precision': 0.7456521739130435, 'recall': 0.8386308068459658, 'f1': 0.7894131185270425, 'tp': 1715, 'tn': 1663, 'fp': 585, 'fn': 330, 'auc': 0.8663697804731616}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'random_state': 1509,\n",
    "    'max_depth': 20,\n",
    "    'n_estimators': 500,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "model_rf = RandomForestClassifier(**hypara)\n",
    "model_rf.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "train_pred = model_rf.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_rf.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   48.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   48.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.8580416243612948\n",
      "Best paras: {'C': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': [0.1, 1, 5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "model_cv_svm = GridSearchCV(SVC(max_iter=5000, tol=1e-4, random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_svm.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_svm.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_svm.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.9910313901345291, 'precision': 0.9844278126508933, 'recall': 0.9969437652811736, 'f1': 0.9906462585034013, 'tp': 8155, 'tn': 8862, 'fp': 129, 'fn': 25, 'auc': 0.9992170790730965}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8346144887025391, 'precision': 0.8257686676427526, 'recall': 0.8273838630806846, 'f1': 0.8265754763067904, 'tp': 1692, 'tn': 1891, 'fp': 357, 'fn': 353, 'auc': 0.9091772964177883}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': 5,\n",
    "    'random_state': 1509,\n",
    "    'max_iter':5000,\n",
    "    'tol' : 1e-4\n",
    "}\n",
    "model_svm = SVC(**hypara, probability=True)\n",
    "model_svm.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_svm.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_svm.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from deep_pytorch import *\n",
    "datasetTrain = EncodingDataset(X_train.toarray(), y_train)\n",
    "datasetVal = EncodingDataset(X_val.toarray(), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/49\n",
      "Total iteration: 9\n",
      "Epoch 1/50 [16122020-003307] [SAVE]\n",
      "AccVal: 0.7693920335429769\n",
      "AUCVal: 0.888049034621375\n",
      "Precision: 0.865557849407196\n",
      "Recall: 0.6107579469680786\n",
      "F1Val: 0.7161697486777903\n",
      "LossVal: 0.6674820780754089\n",
      "LossTrain: 0.6730867293145921\n",
      "----------\n",
      "\n",
      "Training 1/49\n",
      "Total iteration: 9\n",
      "Epoch 2/50 [16122020-003308] [SAVE]\n",
      "AccVal: 0.8152806894945259\n",
      "AUCVal: 0.9062917105343298\n",
      "Precision: 0.8485523462295532\n",
      "Recall: 0.7452322840690613\n",
      "F1Val: 0.7935433869302214\n",
      "LossVal: 0.6333475311597189\n",
      "LossTrain: 0.44506992565260994\n",
      "----------\n",
      "\n",
      "Training 2/49\n",
      "Total iteration: 9\n",
      "Epoch 3/50 [16122020-003308] [SAVE]\n",
      "AccVal: 0.8383414861402283\n",
      "AUCVal: 0.9130179284601798\n",
      "Precision: 0.8312898278236389\n",
      "Recall: 0.8288508653640747\n",
      "F1Val: 0.8300685252151679\n",
      "LossVal: 0.5865205923716227\n",
      "LossTrain: 0.3682912124527825\n",
      "----------\n",
      "\n",
      "Training 3/49\n",
      "Total iteration: 9\n",
      "Epoch 4/50 [16122020-003309] [SAVE]\n",
      "AccVal: 0.8411367342184952\n",
      "AUCVal: 0.9167056400038285\n",
      "Precision: 0.8293861746788025\n",
      "Recall: 0.8391197919845581\n",
      "F1Val: 0.8342246214737004\n",
      "LossVal: 0.5252510706583658\n",
      "LossTrain: 0.3234518865744273\n",
      "----------\n",
      "\n",
      "Training 4/49\n",
      "Total iteration: 9\n",
      "Epoch 5/50 [16122020-003309] [SAVE]\n",
      "AccVal: 0.8450966689960401\n",
      "AUCVal: 0.9182633408452175\n",
      "Precision: 0.8346265554428101\n",
      "Recall: 0.8415647745132446\n",
      "F1Val: 0.8380813053750963\n",
      "LossVal: 0.4590103526910146\n",
      "LossTrain: 0.29339638021257186\n",
      "----------\n",
      "\n",
      "Training 5/49\n",
      "Total iteration: 9\n",
      "Epoch 6/50 [16122020-003310] [SAVE]\n",
      "AccVal: 0.8436990449569066\n",
      "AUCVal: 0.918913959923083\n",
      "Precision: 0.8334951400756836\n",
      "Recall: 0.8396087884902954\n",
      "F1Val: 0.8365407944159241\n",
      "LossVal: 0.4061262309551239\n",
      "LossTrain: 0.2569777336385515\n",
      "----------\n",
      "\n",
      "Training 6/49\n",
      "Total iteration: 9\n",
      "Epoch 7/50 [16122020-003310] [SAVE]\n",
      "AccVal: 0.8457954810156068\n",
      "AUCVal: 0.91925612769623\n",
      "Precision: 0.833253026008606\n",
      "Recall: 0.8454767465591431\n",
      "F1Val: 0.8393203825922919\n",
      "LossVal: 0.3825349609057109\n",
      "LossTrain: 0.24255349073145124\n",
      "----------\n",
      "\n",
      "Training 7/49\n",
      "Total iteration: 9\n",
      "Epoch 8/50 [16122020-003311] [SAVE]\n",
      "AccVal: 0.8471931050547403\n",
      "AUCVal: 0.9193519477242471\n",
      "Precision: 0.8346987962722778\n",
      "Recall: 0.846943736076355\n",
      "F1Val: 0.8407766851923535\n",
      "LossVal: 0.3842524588108063\n",
      "LossTrain: 0.22116479443179238\n",
      "----------\n",
      "\n",
      "Training 8/49\n",
      "Total iteration: 9\n",
      "Epoch 9/50 [16122020-003311]\n",
      "AccVal: 0.8446307943163289\n",
      "AUCVal: 0.9187057879212381\n",
      "Precision: 0.837084174156189\n",
      "Recall: 0.8366748094558716\n",
      "F1Val: 0.8368794417452212\n",
      "LossVal: 0.3957587281862895\n",
      "LossTrain: 0.20839484367105696\n",
      "----------\n",
      "\n",
      "Training 9/49\n",
      "Total iteration: 9\n",
      "Epoch 10/50 [16122020-003312]\n",
      "AccVal: 0.8453296063358956\n",
      "AUCVal: 0.9180666977003193\n",
      "Precision: 0.8393120169639587\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.8372549186226153\n",
      "LossVal: 0.4066128134727478\n",
      "LossTrain: 0.1960540513197581\n",
      "----------\n",
      "\n",
      "Training 10/49\n",
      "Total iteration: 9\n",
      "Epoch 11/50 [16122020-003313]\n",
      "AccVal: 0.8436990449569066\n",
      "AUCVal: 0.9175974949751585\n",
      "Precision: 0.83544921875\n",
      "Recall: 0.8366748094558716\n",
      "F1Val: 0.8360615649518701\n",
      "LossVal: 0.4158221284548442\n",
      "LossTrain: 0.1856090956264072\n",
      "----------\n",
      "\n",
      "Training 11/49\n",
      "Total iteration: 9\n",
      "Epoch    12: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 12/50 [16122020-003313]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.9173756188603399\n",
      "Precision: 0.8330900073051453\n",
      "Recall: 0.8371638059616089\n",
      "F1Val: 0.8351219683775666\n",
      "LossVal: 0.42574918270111084\n",
      "LossTrain: 0.17259563422865337\n",
      "----------\n",
      "\n",
      "Training 12/49\n",
      "Total iteration: 9\n",
      "Epoch 13/50 [16122020-003314]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.9172905663496593\n",
      "Precision: 0.8340653777122498\n",
      "Recall: 0.835696816444397\n",
      "F1Val: 0.8348803298831938\n",
      "LossVal: 0.4304898182551066\n",
      "LossTrain: 0.16613306601842245\n",
      "----------\n",
      "\n",
      "Training 13/49\n",
      "Total iteration: 9\n",
      "Epoch 14/50 [16122020-003314]\n",
      "AccVal: 0.8413696715583509\n",
      "AUCVal: 0.9170528108658389\n",
      "Precision: 0.8323586583137512\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.8337807753214679\n",
      "LossVal: 0.4352426429589589\n",
      "LossTrain: 0.16438356869750553\n",
      "----------\n",
      "\n",
      "Training 14/49\n",
      "Total iteration: 9\n",
      "Epoch 15/50 [16122020-003315]\n",
      "AccVal: 0.8420684835779175\n",
      "AUCVal: 0.91691750994092\n",
      "Precision: 0.8316351175308228\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8348757808388889\n",
      "LossVal: 0.44071192542711896\n",
      "LossTrain: 0.16045788758330876\n",
      "----------\n",
      "\n",
      "Training 15/49\n",
      "Total iteration: 9\n",
      "Epoch    16: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 16/50 [16122020-003315]\n",
      "AccVal: 0.8423014209177732\n",
      "AUCVal: 0.9166018802913103\n",
      "Precision: 0.8326848149299622\n",
      "Recall: 0.8371638059616089\n",
      "F1Val: 0.8349182737037648\n",
      "LossVal: 0.44592533508936566\n",
      "LossTrain: 0.1542210711373223\n",
      "----------\n",
      "\n",
      "Training 16/49\n",
      "Total iteration: 9\n",
      "Epoch 17/50 [16122020-003316]\n",
      "AccVal: 0.8427672955974843\n",
      "AUCVal: 0.9165316195216175\n",
      "Precision: 0.8341463208198547\n",
      "Recall: 0.8361858129501343\n",
      "F1Val: 0.8351647919626408\n",
      "LossVal: 0.4484313527743022\n",
      "LossTrain: 0.14787195126215616\n",
      "----------\n",
      "\n",
      "Training 17/49\n",
      "Total iteration: 9\n",
      "Epoch 18/50 [16122020-003316]\n",
      "AccVal: 0.8427672955974843\n",
      "AUCVal: 0.9165538071330995\n",
      "Precision: 0.834799587726593\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.835003624134259\n",
      "LossVal: 0.4507147471110026\n",
      "LossTrain: 0.1446773045592838\n",
      "----------\n",
      "\n",
      "Training 18/49\n",
      "Total iteration: 9\n",
      "Epoch 19/50 [16122020-003317]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.9165808890706436\n",
      "Precision: 0.8340653777122498\n",
      "Recall: 0.835696816444397\n",
      "F1Val: 0.8348803298831938\n",
      "LossVal: 0.45294613639513653\n",
      "LossTrain: 0.14297264400455686\n",
      "----------\n",
      "\n",
      "Training 19/49\n",
      "Total iteration: 9\n",
      "Epoch    20: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 20/50 [16122020-003317]\n",
      "AccVal: 0.8436990449569066\n",
      "AUCVal: 0.9166678993117491\n",
      "Precision: 0.8344693183898926\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8363015269273362\n",
      "LossVal: 0.45480648676554364\n",
      "LossTrain: 0.1410479090280003\n",
      "----------\n",
      "\n",
      "Training 20/49\n",
      "Total iteration: 9\n",
      "Epoch 21/50 [16122020-003318]\n",
      "AccVal: 0.843466107617051\n",
      "AUCVal: 0.9166956338261014\n",
      "Precision: 0.8337384462356567\n",
      "Recall: 0.8386307954788208\n",
      "F1Val: 0.8361774648176155\n",
      "LossVal: 0.45622390508651733\n",
      "LossTrain: 0.14114457865556082\n",
      "----------\n",
      "\n",
      "Training 21/49\n",
      "Total iteration: 9\n",
      "Epoch 22/50 [16122020-003318]\n",
      "AccVal: 0.8430002329373398\n",
      "AUCVal: 0.9167154286559529\n",
      "Precision: 0.8332523107528687\n",
      "Recall: 0.8381417989730835\n",
      "F1Val: 0.8356899030204165\n",
      "LossVal: 0.45721401770909625\n",
      "LossTrain: 0.13674431376987034\n",
      "----------\n",
      "\n",
      "Training 22/49\n",
      "Total iteration: 9\n",
      "Epoch 23/50 [16122020-003319]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.9166869328019909\n",
      "Precision: 0.8334144949913025\n",
      "Recall: 0.8366748094558716\n",
      "F1Val: 0.8350414996659137\n",
      "LossVal: 0.45813868443171185\n",
      "LossTrain: 0.13301550017462838\n",
      "----------\n",
      "\n",
      "Training 23/49\n",
      "Total iteration: 9\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 24/50 [16122020-003320]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.916637445727362\n",
      "Precision: 0.8330900073051453\n",
      "Recall: 0.8371638059616089\n",
      "F1Val: 0.8351219683775666\n",
      "LossVal: 0.45945702989896137\n",
      "LossTrain: 0.12975804342163932\n",
      "----------\n",
      "\n",
      "Training 24/49\n",
      "Total iteration: 9\n",
      "Epoch 25/50 [16122020-003320]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.9166136266738595\n",
      "Precision: 0.8334144949913025\n",
      "Recall: 0.8366748094558716\n",
      "F1Val: 0.8350414996659137\n",
      "LossVal: 0.46073100964228314\n",
      "LossTrain: 0.13554391182131237\n",
      "----------\n",
      "\n",
      "Training 25/49\n",
      "Total iteration: 9\n",
      "Epoch 26/50 [16122020-003321]\n",
      "AccVal: 0.8430002329373398\n",
      "AUCVal: 0.916576429795787\n",
      "Precision: 0.8342272043228149\n",
      "Recall: 0.8366748094558716\n",
      "F1Val: 0.8354492142136394\n",
      "LossVal: 0.46194274226824444\n",
      "LossTrain: 0.13159128692415026\n",
      "----------\n",
      "\n",
      "Training 26/49\n",
      "Total iteration: 9\n",
      "Epoch 27/50 [16122020-003321]\n",
      "AccVal: 0.841835546238062\n",
      "AUCVal: 0.9165459762114001\n",
      "Precision: 0.8331707119941711\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.8341879924988976\n",
      "LossVal: 0.4629048804442088\n",
      "LossTrain: 0.13156351778242323\n",
      "----------\n",
      "\n",
      "Training 27/49\n",
      "Total iteration: 9\n",
      "Epoch 28/50 [16122020-003322]\n",
      "AccVal: 0.8420684835779175\n",
      "AUCVal: 0.9165483689930305\n",
      "Precision: 0.8335773348808289\n",
      "Recall: 0.8352078199386597\n",
      "F1Val: 0.8343918106800483\n",
      "LossVal: 0.46367939313252765\n",
      "LossTrain: 0.12831349422534308\n",
      "----------\n",
      "\n",
      "Training 28/49\n",
      "Total iteration: 9\n",
      "Epoch 29/50 [16122020-003322]\n",
      "AccVal: 0.841835546238062\n",
      "AUCVal: 0.9165364050848785\n",
      "Precision: 0.83349609375\n",
      "Recall: 0.8347188234329224\n",
      "F1Val: 0.8341070104873644\n",
      "LossVal: 0.46445178985595703\n",
      "LossTrain: 0.12752137747075823\n",
      "----------\n",
      "\n",
      "Training 29/49\n",
      "Total iteration: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [16122020-003323]\n",
      "AccVal: 0.841835546238062\n",
      "AUCVal: 0.916500948411628\n",
      "Precision: 0.8341487050056458\n",
      "Recall: 0.8337408304214478\n",
      "F1Val: 0.8339446880393163\n",
      "LossVal: 0.46546528736750287\n",
      "LossTrain: 0.125530401037799\n",
      "----------\n",
      "\n",
      "Training 30/49\n",
      "Total iteration: 9\n",
      "Epoch 31/50 [16122020-003323]\n",
      "AccVal: 0.8423014209177732\n",
      "AUCVal: 0.9164205727014069\n",
      "Precision: 0.8343108296394348\n",
      "Recall: 0.8347188234329224\n",
      "F1Val: 0.8345147468668794\n",
      "LossVal: 0.4667538305123647\n",
      "LossTrain: 0.1259064334962103\n",
      "----------\n",
      "\n",
      "Training 31/49\n",
      "Total iteration: 9\n",
      "Epoch 32/50 [16122020-003324]\n",
      "AccVal: 0.8430002329373398\n",
      "AUCVal: 0.9163497681177074\n",
      "Precision: 0.8348802924156189\n",
      "Recall: 0.835696816444397\n",
      "F1Val: 0.8352883846870636\n",
      "LossVal: 0.46822287638982135\n",
      "LossTrain: 0.12323390195767085\n",
      "----------\n",
      "\n",
      "Training 32/49\n",
      "Total iteration: 9\n",
      "Epoch 33/50 [16122020-003324]\n",
      "AccVal: 0.8425343582576287\n",
      "AUCVal: 0.9162936465121944\n",
      "Precision: 0.8347188234329224\n",
      "Recall: 0.8347188234329224\n",
      "F1Val: 0.8347188234329224\n",
      "LossVal: 0.4694278339544932\n",
      "LossTrain: 0.1218420449230406\n",
      "----------\n",
      "\n",
      "Early stopping: 25 epoch not decrease the loss\n"
     ]
    }
   ],
   "source": [
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=2048, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[X_train.shape[1], 512, 1], weight_decay=1e-3,\n",
    "                     dropout=0.9, batchnorm=True, checkpoint=None, model_name='BOW_Raw_Light')\n",
    "model_mlp.train(numb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9767631471667346,\n",
       " 'precision': 0.97485656,\n",
       " 'recall': 0.97640586,\n",
       " 'f1': 0.9756305623514359,\n",
       " 'tp': 7987,\n",
       " 'tn': 8785,\n",
       " 'fp': 206,\n",
       " 'fn': 193,\n",
       " 'auc': 0.9974219397338115}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = make_dalaloader(datasetTrain, batch_size=1024)\n",
    "metrics = model_mlp.evaluate(dataloader)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Lemmatized Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda text: text.split())\n",
    "all_string = data_train.headline_s2.tolist()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(all_string)\n",
    "\n",
    "vocab = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "vocab = list(vocab)\n",
    "\n",
    "# encode document\n",
    "X_train_f = vectorizer.transform(data_train_f.headline_s2.tolist())\n",
    "y_train_f = data_train_f.is_sarcastic.to_numpy()\n",
    "\n",
    "X_train = vectorizer.transform(data_train.headline_s2.tolist())\n",
    "y_train = data_train.is_sarcastic.to_numpy()\n",
    "\n",
    "X_val = vectorizer.transform(data_val.headline_s2.tolist())\n",
    "y_val = data_val.is_sarcastic.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.8380546345521406\n",
      "Best paras: {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 5, 10, 20],\n",
    "}\n",
    "\n",
    "model_cv_lr = GridSearchCV(LogisticRegression(max_iter=5000, tol=1e-4, solver='liblinear', random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_lr.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_lr.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.9555063770310407, 'precision': 0.9539666993143977, 'recall': 0.9525672371638142, 'f1': 0.9532664546121851, 'tp': 7792, 'tn': 8615, 'fp': 376, 'fn': 388, 'auc': 0.9900906475614435}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8346144887025391, 'precision': 0.8257686676427526, 'recall': 0.8273838630806846, 'f1': 0.8265754763067904, 'tp': 1692, 'tn': 1891, 'fp': 357, 'fn': 353, 'auc': 0.9108975976472431}\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': 'l2',\n",
    "    'C': 1,\n",
    "    'max_iter': 5000,\n",
    "    'tol': 1e-5,\n",
    "    'solver': 'liblinear',\n",
    "    'random_state': 1509\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression(**hypara)\n",
    "model_lr.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_lr.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_lr.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB Score: 0.7650482188977092\n",
      "Best paras: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "## RF\n",
    "hypara = {\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'min_samples_split': [5, 7, 10],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "}\n",
    "\n",
    "model_cv_rf = GridSearchCV(RandomForestClassifier(random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_rf.fit(X_train_f, y_train_f);\n",
    "print(f\"Best OOB Score: {model_cv_rf.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.783472133247918, 'precision': 0.8877302745915885, 'recall': 0.6244498777506112, 'f1': 0.7331706616908282, 'tp': 5108, 'tn': 8345, 'fp': 646, 'fn': 3072, 'auc': 0.9014643684706167}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7654320987654321, 'precision': 0.8634453781512605, 'recall': 0.6029339853300734, 'f1': 0.7100489490354163, 'tp': 1233, 'tn': 2053, 'fp': 195, 'fn': 812, 'auc': 0.8795621644667577}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'random_state': 1509,\n",
    "    'max_depth': 20,\n",
    "    'n_estimators': 400,\n",
    "    'min_samples_split': 7,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "model_rf = RandomForestClassifier(**hypara)\n",
    "model_rf.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "train_pred = model_rf.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_rf.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.84499656889594\n",
      "Best paras: {'C': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': [0.1, 1, 5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "model_cv_svm = GridSearchCV(SVC(max_iter=5000, tol=1e-4, random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_svm.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_svm.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_svm.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.9998252868208025, 'precision': 0.9997555311086664, 'recall': 0.999877750611247, 'f1': 0.9998166371248701, 'tp': 8179, 'tn': 8989, 'fp': 2, 'fn': 1, 'auc': 0.9999999728062754}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8397391101793618, 'precision': 0.8394197098549274, 'recall': 0.8205378973105134, 'f1': 0.8298714144411472, 'tp': 1678, 'tn': 1927, 'fp': 321, 'fn': 367, 'auc': 0.9164516788626021}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': 5,\n",
    "    'random_state': 1509,\n",
    "    'max_iter':5000,\n",
    "    'tol' : 1e-4\n",
    "}\n",
    "model_svm = SVC(**hypara, probability=True)\n",
    "model_svm.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_svm.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_svm.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Embedding TFIDF\n",
    "TFIDF features. Try on both original sentences and lemmatised headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TRAINING SAMPLES =====\n",
      "Total Sample: 17171\n",
      "Sarcastic: 8180 (47.64%)\n",
      "Not Sarcastic: 8991 (52.36%)\n",
      "===== VALIDATING SAMPLES =====\n",
      "Total Sample: 4293\n",
      "Sarcastic: 2045 (47.64%)\n",
      "Not Sarcastic: 2248 (52.36%)\n",
      "===== TESTING SAMPLES =====\n",
      "Total Sample: 7155\n",
      "Sarcastic: 3409 (47.65%)\n",
      "Not Sarcastic: 3746 (52.35%)\n"
     ]
    }
   ],
   "source": [
    "data_full = pd.read_json('fake_news.json', lines=True)\n",
    "data_full = data_full.drop(columns=['article_link']) # remove link column\n",
    "df_train_f, df_test = split_dataframe(data_full, test_size=0.25, seed=1509)\n",
    "df_train, df_validate = split_dataframe(df_train_f, test_size=0.2, seed=1309)\n",
    "\n",
    "# Proportion of each subsets\n",
    "list_label = df_train['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TRAINING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_validate['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== VALIDATING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_test['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TESTING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "data_train = df_train.copy()\n",
    "data_train_f = df_train_f.copy()\n",
    "data_val = df_validate.copy()\n",
    "data_test = df_test.copy()\n",
    "\n",
    "data_train = df_train\n",
    "data_train['headline'] = data_train.headline.apply(lambda row: row.lower())\n",
    "data_train['headline_s1'] = data_train.headline.apply(lambda row: remove_symbol(row))\n",
    "data_train['headline_s2'] = data_train.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_train['headline_s2'] = data_train.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "#data_train = data_train.drop(columns=['headline', 'headline_s1'])\n",
    "\n",
    "data_train_f = df_train_f\n",
    "data_train_f['headline'] = data_train_f.headline.apply(lambda row: row.lower())\n",
    "data_train_f['headline_s1'] = data_train_f.headline.apply(lambda row: remove_symbol(row))\n",
    "data_train_f['headline_s2'] = data_train_f.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_train_f['headline_s2'] = data_train_f.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "\n",
    "data_val = df_validate\n",
    "data_val['headline'] = data_val.headline.apply(lambda row: row.lower())\n",
    "data_val['headline_s1'] = data_val.headline.apply(lambda row: remove_symbol(row))\n",
    "data_val['headline_s2'] = data_val.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_val['headline_s2'] = data_val.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "#data_val = data_val.drop(columns=['headline', 'headline_s1'])\n",
    "\n",
    "data_test = df_test\n",
    "data_test['headline'] = data_test.headline.apply(lambda row: row.lower())\n",
    "data_test['headline_s1'] = data_test.headline.apply(lambda row: remove_symbol(row))\n",
    "data_test['headline_s2'] = data_test.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_test['headline_s2'] = data_test.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Raw Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda text: text.split())\n",
    "all_string = data_train.headline_s1.tolist()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(all_string)\n",
    "\n",
    "vocab = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "vocab = list(vocab)\n",
    "\n",
    "# encode document\n",
    "X_train_f = vectorizer.transform(data_train_f.headline_s1.tolist())\n",
    "y_train_f = data_train_f.is_sarcastic.to_numpy()\n",
    "\n",
    "X_train = vectorizer.transform(data_train.headline_s1.tolist())\n",
    "y_train = data_train.is_sarcastic.to_numpy()\n",
    "\n",
    "X_val = vectorizer.transform(data_val.headline_s1.tolist())\n",
    "y_val = data_val.is_sarcastic.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.8493293662345929\n",
      "Best paras: {'C': 5, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 5, 10, 20],\n",
    "}\n",
    "\n",
    "model_cv_lr = GridSearchCV(LogisticRegression(max_iter=5000, tol=1e-4, solver='liblinear', random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_lr.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_lr.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.9712888008852134, 'precision': 0.9722324609902937, 'recall': 0.967359413202934, 'f1': 0.9697898155524235, 'tp': 7913, 'tn': 8765, 'fp': 226, 'fn': 267, 'auc': 0.9944726579336739}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8485907290938738, 'precision': 0.8348535765722516, 'recall': 0.8503667481662591, 'f1': 0.8425387596899224, 'tp': 1739, 'tn': 1904, 'fp': 344, 'fn': 306, 'auc': 0.9256408304257412}\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': 'l2',\n",
    "    'C': 5,\n",
    "    'max_iter': 5000,\n",
    "    'tol': 1e-5,\n",
    "    'solver': 'liblinear',\n",
    "    'random_state': 1509\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression(**hypara)\n",
    "model_lr.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_lr.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_lr.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB Score: 0.7796309972952783\n",
      "Best paras: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "## RF\n",
    "hypara = {\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'min_samples_split': [5, 7, 10],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "}\n",
    "\n",
    "model_cv_rf = GridSearchCV(RandomForestClassifier(random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_rf.fit(X_train_f, y_train_f);\n",
    "print(f\"Best OOB Score: {model_cv_rf.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.8097955855803389, 'precision': 0.8814032909034462, 'recall': 0.6941320293398533, 'f1': 0.7766379428258788, 'tp': 5678, 'tn': 8227, 'fp': 764, 'fn': 2502, 'auc': 0.9135647532890131}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7747495923596552, 'precision': 0.855072463768116, 'recall': 0.634718826405868, 'f1': 0.7285994948077463, 'tp': 1298, 'tn': 2028, 'fp': 220, 'fn': 747, 'auc': 0.8856271045602068}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'random_state': 1509,\n",
    "    'max_depth': 20,\n",
    "    'n_estimators': 300,\n",
    "    'min_samples_split': 7,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "model_rf = RandomForestClassifier(**hypara)\n",
    "model_rf.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "train_pred = model_rf.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_rf.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.8526372609868597\n",
      "Best paras: {'C': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': [0.1, 1, 5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "model_cv_svm = GridSearchCV(SVC(max_iter=5000, tol=1e-4, random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_svm.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_svm.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_svm.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'tp': 8180, 'tn': 8991, 'fp': 0, 'fn': 0, 'auc': 1.0}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8541812252504076, 'precision': 0.8462664714494875, 'recall': 0.847921760391198, 'f1': 0.8470933072789448, 'tp': 1734, 'tn': 1933, 'fp': 315, 'fn': 311, 'auc': 0.9263538793515997}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': 5,\n",
    "    'random_state': 1509,\n",
    "    'max_iter':5000,\n",
    "    'tol' : 1e-4\n",
    "}\n",
    "model_svm = SVC(**hypara, probability=True)\n",
    "model_svm.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_svm.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_svm.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Lemmatised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda text: text.split())\n",
    "all_string = data_train.headline_s2.tolist()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(all_string)\n",
    "\n",
    "vocab = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "vocab = list(vocab)\n",
    "\n",
    "# encode document\n",
    "X_train_f = vectorizer.transform(data_train_f.headline_s2.tolist())\n",
    "y_train_f = data_train_f.is_sarcastic.to_numpy()\n",
    "\n",
    "X_train = vectorizer.transform(data_train.headline_s2.tolist())\n",
    "y_train = data_train.is_sarcastic.to_numpy()\n",
    "\n",
    "X_val = vectorizer.transform(data_val.headline_s2.tolist())\n",
    "y_val = data_val.is_sarcastic.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.8417352507571548\n",
      "Best paras: {'C': 5, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 5, 10, 20],\n",
    "}\n",
    "\n",
    "model_cv_lr = GridSearchCV(LogisticRegression(max_iter=5000, tol=1e-4, solver='liblinear', random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_lr.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_lr.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.957777648360608, 'precision': 0.9580926631436647, 'recall': 0.9530562347188264, 'f1': 0.9555678127106698, 'tp': 7796, 'tn': 8650, 'fp': 341, 'fn': 384, 'auc': 0.9905264813849438}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8395061728395061, 'precision': 0.8256484149855908, 'recall': 0.8405867970660147, 'f1': 0.833050642112915, 'tp': 1719, 'tn': 1885, 'fp': 363, 'fn': 326, 'auc': 0.9145953153686189}\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "hypara = {\n",
    "    'penalty': 'l2',\n",
    "    'C': 5,\n",
    "    'max_iter': 5000,\n",
    "    'tol': 1e-5,\n",
    "    'solver': 'liblinear',\n",
    "    'random_state': 1509\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression(**hypara)\n",
    "model_lr.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_lr.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_lr.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB Score: 0.780329570516081\n",
      "Best paras: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "## RF\n",
    "hypara = {\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'min_samples_split': [5, 7, 10],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "}\n",
    "\n",
    "model_cv_rf = GridSearchCV(RandomForestClassifier(random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_rf.fit(X_train_f, y_train_f);\n",
    "print(f\"Best OOB Score: {model_cv_rf.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 0.8105526760235281, 'precision': 0.8675220050723557, 'recall': 0.710880195599022, 'f1': 0.7814284754417792, 'tp': 5815, 'tn': 8103, 'fp': 888, 'fn': 2365, 'auc': 0.909080868426155}\n",
      "Validate Result:\n",
      "{'accuracy': 0.7819706498951782, 'precision': 0.8446239900559354, 'recall': 0.6645476772616137, 'f1': 0.7438423645320197, 'tp': 1359, 'tn': 1998, 'fp': 250, 'fn': 686, 'auc': 0.8825521626395427}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'random_state': 1509,\n",
    "    'max_depth': 20,\n",
    "    'n_estimators': 400,\n",
    "    'min_samples_split': 7,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "model_rf = RandomForestClassifier(**hypara)\n",
    "model_rf.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "train_pred = model_rf.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_rf.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.84681338245641\n",
      "Best paras: {'C': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': [0.1, 1, 5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "model_cv_svm = GridSearchCV(SVC(max_iter=5000, tol=1e-4, random_state=1509), hypara, verbose=1, n_jobs=-1)\n",
    "model_cv_svm.fit(X_train_f, y_train_f);\n",
    "print(f\"Best CV Score: {model_cv_svm.best_score_}\")\n",
    "print(f\"Best paras: {model_cv_svm.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "{'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'tp': 8180, 'tn': 8991, 'fp': 0, 'fn': 0, 'auc': 1.0}\n",
      "Validate Result:\n",
      "{'accuracy': 0.8439319822967621, 'precision': 0.8316449589966233, 'recall': 0.8430317848410758, 'f1': 0.8372996600291405, 'tp': 1724, 'tn': 1899, 'fp': 349, 'fn': 321, 'auc': 0.919422861070748}\n"
     ]
    }
   ],
   "source": [
    "hypara = {\n",
    "    'C': 5,\n",
    "    'random_state': 1509,\n",
    "    'max_iter':5000,\n",
    "    'tol' : 1e-4\n",
    "}\n",
    "model_svm = SVC(**hypara, probability=True)\n",
    "model_svm.fit(X_train, y_train);\n",
    "\n",
    "train_pred = model_svm.predict_proba(X_train)\n",
    "train_pred = train_pred[:,1]\n",
    "metrics = calculate_metric(y_train, train_pred)\n",
    "print('Train Result:')\n",
    "print(metrics)\n",
    "\n",
    "val_pred = model_svm.predict_proba(X_val)\n",
    "val_pred = val_pred[:,1]\n",
    "metrics = calculate_metric(y_val, val_pred)\n",
    "print('Validate Result:')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
