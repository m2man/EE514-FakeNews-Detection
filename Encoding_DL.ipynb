{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization\n",
    "Encoded headline into vector with 4 cases:\n",
    "\n",
    "1. BOW without unknown token (ignore unknow token)\n",
    "2. BOW with unknown token\n",
    "3. BOW + Remove Stopwords w/o unknown token\n",
    "4. BOW + Remove Stopwords w unknown token\n",
    "3. TFIDF without unknown token\n",
    "4. TFIDF with unknown token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/graph/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.ranking module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from myfunctions import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from deep_pytorch import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TRAINING SAMPLES =====\n",
      "Total Sample: 18316\n",
      "Sarcastic: 8726 (47.64%)\n",
      "Not Sarcastic: 9590 (52.36%)\n",
      "===== VALIDATING SAMPLES =====\n",
      "Total Sample: 4579\n",
      "Sarcastic: 2181 (47.63%)\n",
      "Not Sarcastic: 2398 (52.37%)\n",
      "===== TESTING SAMPLES =====\n",
      "Total Sample: 5724\n",
      "Sarcastic: 2727 (47.64%)\n",
      "Not Sarcastic: 2997 (52.36%)\n"
     ]
    }
   ],
   "source": [
    "data_full = pd.read_json('fake_news.json', lines=True)\n",
    "data_full = data_full.drop(columns=['article_link']) # remove link column\n",
    "df_train_f, df_test = split_dataframe(data_full, test_size=0.25, seed=1509)\n",
    "df_train, df_validate = split_dataframe(df_train_f, test_size=0.2, seed=1309)\n",
    "\n",
    "# Proportion of each subsets\n",
    "list_label = df_train['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TRAINING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_validate['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== VALIDATING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')\n",
    "\n",
    "list_label = df_test['is_sarcastic'].tolist()\n",
    "numb_total = len(list_label)\n",
    "numb_sarcastic = np.sum(np.asarray(list_label))\n",
    "numb_not_sarcastic = numb_total - numb_sarcastic\n",
    "print(f'===== TESTING SAMPLES =====\\nTotal Sample: {numb_total}\\nSarcastic: {numb_sarcastic} ({np.round(numb_sarcastic/numb_total*100,2)}%)\\nNot Sarcastic: {numb_not_sarcastic} ({np.round(numb_not_sarcastic/numb_total*100,2)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_train\n",
    "data_train['headline_s1'] = data_train.headline.apply(lambda row: remove_symbol(row))\n",
    "data_train['headline_s2'] = data_train.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_train['headline_s2'] = data_train.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "data_train = data_train.drop(columns=['headline', 'headline_s1'])\n",
    "\n",
    "data_val = df_validate\n",
    "data_val['headline_s1'] = data_val.headline.apply(lambda row: remove_symbol(row))\n",
    "data_val['headline_s2'] = data_val.headline_s1.apply(lambda row: lemmatize_word(row, 'v'))\n",
    "data_val['headline_s2'] = data_val.headline_s2.apply(lambda row: lemmatize_word(row, 'n'))\n",
    "data_val = data_val.drop(columns=['headline', 'headline_s1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_rmsw = data_train.copy()\n",
    "data_train_rmsw['headline_s3'] = data_train_rmsw.headline_s2.apply(lambda row: remove_stop_words(row))\n",
    "data_train_rmsw = data_train_rmsw.drop(columns=['headline_s2'])\n",
    "\n",
    "data_val_rmsw = data_val.copy()\n",
    "data_val_rmsw['headline_s3'] = data_val_rmsw.headline_s2.apply(lambda row: remove_stop_words(row))\n",
    "data_val_rmsw = data_val_rmsw.drop(columns=['headline_s2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BOW entire dict without unknow token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FT_0\n",
      "Processing FT_1000\n",
      "Processing FT_2000\n",
      "Processing FT_3000\n",
      "Processing FT_4000\n",
      "Processing FT_5000\n",
      "Processing FT_6000\n",
      "Processing FT_7000\n",
      "Processing FT_8000\n",
      "Processing FT_9000\n",
      "Processing FT_10000\n",
      "Processing FT_11000\n",
      "Processing FT_12000\n",
      "Processing FT_13000\n",
      "Processing FT_14000\n",
      "Processing FT_15000\n",
      "Processing FT_16000\n",
      "Processing FT_17000\n",
      "Processing FT_18000\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "all_string = data_train.headline_s2.tolist()\n",
    "all_string_in_one = ' '.join(all_string)\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit([all_string_in_one])\n",
    "# encode document\n",
    "vector = vectorizer.transform(data_train.headline_s2.tolist())\n",
    "# summarize encoded vector\n",
    "vector = vector.toarray()\n",
    "data_train = data_train.drop(columns=['headline_s2'])\n",
    "\n",
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    data_train[f\"ft_{idx}\"] = vector[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# encode document\n",
    "vector = vectorizer.transform(data_val.headline_s2.tolist())\n",
    "# summarize encoded vector\n",
    "vector = vector.toarray()\n",
    "data_val = data_val.drop(columns=['headline_s2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FT_0\n",
      "Processing FT_1000\n",
      "Processing FT_2000\n",
      "Processing FT_3000\n",
      "Processing FT_4000\n",
      "Processing FT_5000\n",
      "Processing FT_6000\n",
      "Processing FT_7000\n",
      "Processing FT_8000\n",
      "Processing FT_9000\n",
      "Processing FT_10000\n",
      "Processing FT_11000\n",
      "Processing FT_12000\n",
      "Processing FT_13000\n",
      "Processing FT_14000\n",
      "Processing FT_15000\n",
      "Processing FT_16000\n",
      "Processing FT_17000\n",
      "Processing FT_18000\n"
     ]
    }
   ],
   "source": [
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    data_val[f\"ft_{idx}\"] = vector[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bow_entire_val_ft.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(data_train, 'bow_entire_train_ft.joblib')\n",
    "# joblib.dump(data_val, 'bow_entire_val_ft.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# X_train = data_train.drop(columns=['is_sarcastic'])\n",
    "# y_train = data_train['is_sarcastic']\n",
    "# X_train = np.asarray(X_train)\n",
    "# y_train = np.asarray(y_train)\n",
    "\n",
    "# X_val = data_val.drop(columns=['is_sarcastic'])\n",
    "# y_val = data_val['is_sarcastic']\n",
    "# X_val = np.asarray(X_val)\n",
    "# y_val = np.asarray(y_val)\n",
    "\n",
    "# # SVM need normalization\n",
    "# scaler = StandardScaler().fit(data_train.iloc[:,1:])\n",
    "# data_train.iloc[:,1:] = scaler.transform(data_train.iloc[:,1:])\n",
    "# data_val.iloc[:,1:] = scaler.transform(data_val.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasetTrain = EncodingDataset(data_train)\n",
    "datasetVal = EncodingDataset(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/99\n",
      "Total iteration: 18\n",
      "Epoch 1/100 [01122020-003536] [SAVE]\n",
      "AccVal: 0.5260974011792968\n",
      "AUCVal: 0.8825737977429607\n",
      "Precision: 1.0\n",
      "Recall: 0.005043557845056057\n",
      "F1Val: 0.010036496553280806\n",
      "LossVal: 0.6696352601051331\n",
      "LossTrain: 0.61982029179732\n",
      "----------\n",
      "\n",
      "Training 1/99\n",
      "Total iteration: 18\n",
      "Epoch 2/100 [01122020-003736] [SAVE]\n",
      "AccVal: 0.7043022493994322\n",
      "AUCVal: 0.9130960425144137\n",
      "Precision: 0.9569060802459717\n",
      "Recall: 0.39706557989120483\n",
      "F1Val: 0.5612443186431356\n",
      "LossVal: 0.582669472694397\n",
      "LossTrain: 0.3939804749356376\n",
      "----------\n",
      "\n",
      "Training 2/99\n",
      "Total iteration: 18\n",
      "Epoch 3/100 [01122020-003936] [SAVE]\n",
      "AccVal: 0.764359030355973\n",
      "AUCVal: 0.9157929636457709\n",
      "Precision: 0.9264705777168274\n",
      "Recall: 0.5488308072090149\n",
      "F1Val: 0.6893175865205168\n",
      "LossVal: 0.4749447166919708\n",
      "LossTrain: 0.2560974508523941\n",
      "----------\n",
      "\n",
      "Training 3/99\n",
      "Total iteration: 18\n",
      "Epoch 4/100 [01122020-004137] [SAVE]\n",
      "AccVal: 0.816335444420179\n",
      "AUCVal: 0.9086853671044073\n",
      "Precision: 0.8738839030265808\n",
      "Recall: 0.7180192470550537\n",
      "F1Val: 0.788321121845509\n",
      "LossVal: 0.4180478394031525\n",
      "LossTrain: 0.18001416077216467\n",
      "----------\n",
      "\n",
      "Training 4/99\n",
      "Total iteration: 18\n",
      "Epoch 5/100 [01122020-004337] [SAVE]\n",
      "AccVal: 0.8292203537890369\n",
      "AUCVal: 0.9090167222494367\n",
      "Precision: 0.8233934640884399\n",
      "Recall: 0.8165978789329529\n",
      "F1Val: 0.8199816219767233\n",
      "LossVal: 0.43719988465309145\n",
      "LossTrain: 0.18503179401159286\n",
      "----------\n",
      "\n",
      "Training 5/99\n",
      "Total iteration: 18\n",
      "Epoch 6/100 [01122020-004537]\n",
      "AccVal: 0.8290019654946494\n",
      "AUCVal: 0.9119784598123379\n",
      "Precision: 0.8481075763702393\n",
      "Recall: 0.7808344960212708\n",
      "F1Val: 0.813081922829042\n",
      "LossVal: 0.43558897376060485\n",
      "LossTrain: 0.18518158793449402\n",
      "----------\n",
      "\n",
      "Training 6/99\n",
      "Total iteration: 18\n",
      "Epoch 7/100 [01122020-004737] [SAVE]\n",
      "AccVal: 0.8322777899104608\n",
      "AUCVal: 0.9062943710925235\n",
      "Precision: 0.8189616203308105\n",
      "Recall: 0.8317285776138306\n",
      "F1Val: 0.8252957271403228\n",
      "LossVal: 0.43024643659591677\n",
      "LossTrain: 0.1674984875652525\n",
      "----------\n",
      "\n",
      "Training 7/99\n",
      "Total iteration: 18\n",
      "Epoch 8/100 [01122020-004938]\n",
      "AccVal: 0.8250709761956759\n",
      "AUCVal: 0.9077199821492693\n",
      "Precision: 0.8412463068962097\n",
      "Recall: 0.7799174785614014\n",
      "F1Val: 0.8094218243540795\n",
      "LossVal: 0.46422475576400757\n",
      "LossTrain: 0.15705662841598192\n",
      "----------\n",
      "\n",
      "Training 8/99\n",
      "Total iteration: 18\n",
      "Epoch 9/100 [01122020-005138]\n",
      "AccVal: 0.8263813059620004\n",
      "AUCVal: 0.9097943456624981\n",
      "Precision: 0.8451195359230042\n",
      "Recall: 0.7780834436416626\n",
      "F1Val: 0.8102172099632513\n",
      "LossVal: 0.44801944494247437\n",
      "LossTrain: 0.15505383577611712\n",
      "----------\n",
      "\n",
      "Training 9/99\n",
      "Total iteration: 18\n",
      "Epoch 10/100 [01122020-005339]\n",
      "AccVal: 0.8257261410788381\n",
      "AUCVal: 0.9068649214403413\n",
      "Precision: 0.8047598004341125\n",
      "Recall: 0.8372306227684021\n",
      "F1Val: 0.8206741517801505\n",
      "LossVal: 0.44152621626853944\n",
      "LossTrain: 0.157117227713267\n",
      "----------\n",
      "\n",
      "Training 10/99\n",
      "Total iteration: 18\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 11/100 [01122020-005539]\n",
      "AccVal: 0.8318410133216859\n",
      "AUCVal: 0.9110101112076052\n",
      "Precision: 0.851169764995575\n",
      "Recall: 0.7840440273284912\n",
      "F1Val: 0.8162291063034245\n",
      "LossVal: 0.4571924924850464\n",
      "LossTrain: 0.15653147217300203\n",
      "----------\n",
      "\n",
      "Training 11/99\n",
      "Total iteration: 18\n",
      "Epoch 12/100 [01122020-005740] [SAVE]\n",
      "AccVal: 0.834461672854335\n",
      "AUCVal: 0.9153575939601204\n",
      "Precision: 0.8432223796844482\n",
      "Recall: 0.80146723985672\n",
      "F1Val: 0.8218148028582279\n",
      "LossVal: 0.43034920692443845\n",
      "LossTrain: 0.11652721009320682\n",
      "----------\n",
      "\n",
      "Training 12/99\n",
      "Total iteration: 18\n",
      "Epoch 13/100 [01122020-005940] [SAVE]\n",
      "AccVal: 0.8399213802140205\n",
      "AUCVal: 0.9151784365620289\n",
      "Precision: 0.8480769395828247\n",
      "Recall: 0.8088033199310303\n",
      "F1Val: 0.8279746714983427\n",
      "LossVal: 0.44218350052833555\n",
      "LossTrain: 0.0919736839003033\n",
      "----------\n",
      "\n",
      "Training 13/99\n",
      "Total iteration: 18\n",
      "Epoch 14/100 [01122020-010142]\n",
      "AccVal: 0.8300939069665866\n",
      "AUCVal: 0.9124027397124075\n",
      "Precision: 0.8400387763977051\n",
      "Recall: 0.794589638710022\n",
      "F1Val: 0.8166823746255164\n",
      "LossVal: 0.4792659044265747\n",
      "LossTrain: 0.08010017996033032\n",
      "----------\n",
      "\n",
      "Training 14/99\n",
      "Total iteration: 18\n",
      "Epoch 15/100 [01122020-010343]\n",
      "AccVal: 0.834461672854335\n",
      "AUCVal: 0.913508850222503\n",
      "Precision: 0.8422318696975708\n",
      "Recall: 0.8028427362442017\n",
      "F1Val: 0.8220657426451102\n",
      "LossVal: 0.4811095118522644\n",
      "LossTrain: 0.08169952697224087\n",
      "----------\n",
      "\n",
      "Training 15/99\n",
      "Total iteration: 18\n",
      "Epoch    16: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 16/100 [01122020-010544]\n",
      "AccVal: 0.8333697313823979\n",
      "AUCVal: 0.9090150014206397\n",
      "Precision: 0.8363377451896667\n",
      "Recall: 0.8083447813987732\n",
      "F1Val: 0.8221030391965202\n",
      "LossVal: 0.5001080393791199\n",
      "LossTrain: 0.09030343923303816\n",
      "----------\n",
      "\n",
      "Training 16/99\n",
      "Total iteration: 18\n",
      "Epoch 17/100 [01122020-010744]\n",
      "AccVal: 0.8342432845599476\n",
      "AUCVal: 0.9117319032863623\n",
      "Precision: 0.8157193660736084\n",
      "Recall: 0.8422741889953613\n",
      "F1Val: 0.8287841233241444\n",
      "LossVal: 0.4944396555423737\n",
      "LossTrain: 0.07293284270498487\n",
      "----------\n",
      "\n",
      "Training 17/99\n",
      "Total iteration: 18\n",
      "Epoch 18/100 [01122020-010945]\n",
      "AccVal: 0.8377374972701463\n",
      "AUCVal: 0.9149205034456728\n",
      "Precision: 0.8178603053092957\n",
      "Recall: 0.8482347726821899\n",
      "F1Val: 0.8327706913517006\n",
      "LossVal: 0.48081799149513244\n",
      "LossTrain: 0.05572105675107903\n",
      "----------\n",
      "\n",
      "Training 18/99\n",
      "Total iteration: 18\n",
      "Epoch 19/100 [01122020-011147]\n",
      "AccVal: 0.8399213802140205\n",
      "AUCVal: 0.9153096019570031\n",
      "Precision: 0.8339483141899109\n",
      "Recall: 0.8289775252342224\n",
      "F1Val: 0.8314554904141821\n",
      "LossVal: 0.48702629208564757\n",
      "LossTrain: 0.05003203244672881\n",
      "----------\n",
      "\n",
      "Training 19/99\n",
      "Total iteration: 18\n",
      "Epoch    20: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 20/100 [01122020-011348]\n",
      "AccVal: 0.830312295260974\n",
      "AUCVal: 0.9138937422634406\n",
      "Precision: 0.8317580223083496\n",
      "Recall: 0.8069692850112915\n",
      "F1Val: 0.8191761662438124\n",
      "LossVal: 0.5062678992748261\n",
      "LossTrain: 0.0467313335587581\n",
      "----------\n",
      "\n",
      "Training 20/99\n",
      "Total iteration: 18\n",
      "Epoch 21/100 [01122020-011550]\n",
      "AccVal: 0.8322777899104608\n",
      "AUCVal: 0.9139344685449704\n",
      "Precision: 0.8349928855895996\n",
      "Recall: 0.8074277639389038\n",
      "F1Val: 0.8209790088915988\n",
      "LossVal: 0.5112727761268616\n",
      "LossTrain: 0.04482410930924945\n",
      "----------\n",
      "\n",
      "Training 21/99\n",
      "Total iteration: 18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-be2698ade89d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                      \u001b[0minit_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18337\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      dropout=0.75, batchnorm=True, checkpoint=None)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, numb_epoch)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mtimestampSTART\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampDate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestampTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mlossTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderVal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mmetricsVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mnumb_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total iteration: {numb_iter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatchID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0mbatch_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mbatch_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2827\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0;31m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=1024, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[18337, 2048, 512, 128, 1], weight_decay=1e-2,\n",
    "                     dropout=0.75, batchnorm=True, checkpoint=None)\n",
    "model_mlp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BOW entire with dict unknown token\n",
    "Firstly we want to convert least common words into ```unknown``` token and keep the remaining words as BoW model. All words which are not belong to BoW will be considered as ```unknown``` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_string = data_train.headline_s2.tolist()\n",
    "all_string_in_one = ' '.join(all_string)\n",
    "list_common_words, count_words = most_common_words(all_string_in_one, numb_words=-1)\n",
    "\n",
    "cwdf = pd.DataFrame(np.asarray(count_words),\n",
    "                    columns=['count_words'])\n",
    "cwdf['words'] = list_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words remaining: 9468\n",
      "Total discard (Unknown Token): 9266\n"
     ]
    }
   ],
   "source": [
    "s = cwdf.index[cwdf.iloc[:,0] == 1].tolist()[0]\n",
    "print(f\"Number of unique words remaining: {s}\")\n",
    "print(f\"Total discard (Unknown Token): {cwdf.iloc[s:,0].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_words</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5784</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4050</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3455</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2918</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2640</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_words words\n",
       "0         5784    to\n",
       "1         4050    of\n",
       "2         3455   the\n",
       "3         2918    in\n",
       "4         2640    be"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'of', 'the', 'in', 'be', 'a', 'for', 'on', 'and', 'with']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_vocab = cwdf.words[0:s].tolist()\n",
    "list_vocab[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "all_string_in_one = ' '.join(list_vocab)\n",
    "all_string_in_one += ' UNK'\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit([all_string_in_one])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab = list(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FT_0\n",
      "Processing FT_1000\n",
      "Processing FT_2000\n",
      "Processing FT_3000\n",
      "Processing FT_4000\n",
      "Processing FT_5000\n",
      "Processing FT_6000\n",
      "Processing FT_7000\n",
      "Processing FT_8000\n",
      "Processing FT_9000\n",
      "Processing FT_0\n",
      "Processing FT_1000\n",
      "Processing FT_2000\n",
      "Processing FT_3000\n",
      "Processing FT_4000\n",
      "Processing FT_5000\n",
      "Processing FT_6000\n",
      "Processing FT_7000\n",
      "Processing FT_8000\n",
      "Processing FT_9000\n"
     ]
    }
   ],
   "source": [
    "def add_unknown_token(sent, vocab):\n",
    "    sent_s = sent.split()\n",
    "    for idx, s in enumerate(sent_s):\n",
    "        if s not in vocab:\n",
    "            sent_s[idx] = 'UNK'\n",
    "    psent = ' '.join(sent_s)\n",
    "    return psent\n",
    "\n",
    "data_train['preprocess'] = data_train.headline_s2.apply(lambda row: add_unknown_token(row, vocab))\n",
    "# encode document\n",
    "vector = vectorizer.transform(data_train.preprocess.tolist())\n",
    "# summarize encoded vector\n",
    "vector = vector.toarray()\n",
    "data_train = data_train.drop(columns=['headline_s2', 'preprocess'])\n",
    "\n",
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    data_train[f\"ft_{idx}\"] = vector[:,idx]\n",
    "    \n",
    "# encode document\n",
    "data_val['preprocess'] = data_val.headline_s2.apply(lambda row: add_unknown_token(row, vocab))\n",
    "vector = vectorizer.transform(data_val.preprocess.tolist())\n",
    "# summarize encoded vector\n",
    "vector = vector.toarray()\n",
    "data_val = data_val.drop(columns=['headline_s2', 'preprocess'])\n",
    "\n",
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    data_val[f\"ft_{idx}\"] = vector[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18316, 9382)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasetTrain = EncodingDataset(data_train)\n",
    "datasetVal = EncodingDataset(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/99\n",
      "Total iteration: 9\n",
      "Epoch 1/100 [01122020-021905] [SAVE]\n",
      "AccVal: 0.7774623280192182\n",
      "AUCVal: 0.8811015331054957\n",
      "Precision: 0.8534063100814819\n",
      "Recall: 0.6432828903198242\n",
      "F1Val: 0.7335947605143323\n",
      "LossVal: 0.6762522260348002\n",
      "LossTrain: 0.6165444387329949\n",
      "----------\n",
      "\n",
      "Training 1/99\n",
      "Total iteration: 9\n",
      "Epoch 2/100 [01122020-022032] [SAVE]\n",
      "AccVal: 0.7080148504040183\n",
      "AUCVal: 0.9052672275038919\n",
      "Precision: 0.9460887908935547\n",
      "Recall: 0.41036221385002136\n",
      "F1Val: 0.5724336239822184\n",
      "LossVal: 0.6396872798601786\n",
      "LossTrain: 0.4128439625104268\n",
      "----------\n",
      "\n",
      "Training 2/99\n",
      "Total iteration: 9\n",
      "Epoch 3/100 [01122020-022336] [SAVE]\n",
      "AccVal: 0.6920725049137366\n",
      "AUCVal: 0.913232465997379\n",
      "Precision: 0.965018093585968\n",
      "Recall: 0.36680421233177185\n",
      "F1Val: 0.5315614673996237\n",
      "LossVal: 0.5992210507392883\n",
      "LossTrain: 0.31554121110174393\n",
      "----------\n",
      "\n",
      "Training 3/99\n",
      "Total iteration: 9\n",
      "Epoch 4/100 [01122020-022442] [SAVE]\n",
      "AccVal: 0.6999344835116837\n",
      "AUCVal: 0.9140359974439956\n",
      "Precision: 0.9580022692680359\n",
      "Recall: 0.3869784474372864\n",
      "F1Val: 0.5512736743332295\n",
      "LossVal: 0.5570330421129862\n",
      "LossTrain: 0.24106313784917197\n",
      "----------\n",
      "\n",
      "Training 4/99\n",
      "Total iteration: 9\n",
      "Epoch 5/100 [01122020-022548] [SAVE]\n",
      "AccVal: 0.7556234985804761\n",
      "AUCVal: 0.9133617193603565\n",
      "Precision: 0.9317073225975037\n",
      "Recall: 0.5254470705986023\n",
      "F1Val: 0.6719437358183076\n",
      "LossVal: 0.49456295371055603\n",
      "LossTrain: 0.1892323378059599\n",
      "----------\n",
      "\n",
      "Training 5/99\n",
      "Total iteration: 9\n",
      "Epoch 6/100 [01122020-022657] [SAVE]\n",
      "AccVal: 0.7754968333697314\n",
      "AUCVal: 0.9107892715119852\n",
      "Precision: 0.9180565476417542\n",
      "Recall: 0.580467700958252\n",
      "F1Val: 0.7112359980208882\n",
      "LossVal: 0.45824795961380005\n",
      "LossTrain: 0.1472511953777737\n",
      "----------\n",
      "\n",
      "Training 6/99\n",
      "Total iteration: 9\n",
      "Epoch 7/100 [01122020-022805] [SAVE]\n",
      "AccVal: 0.8034505350513212\n",
      "AUCVal: 0.910886402737418\n",
      "Precision: 0.8975791335105896\n",
      "Recall: 0.662998616695404\n",
      "F1Val: 0.7626582191289462\n",
      "LossVal: 0.42159433166186017\n",
      "LossTrain: 0.13420068555408055\n",
      "----------\n",
      "\n",
      "Training 7/99\n",
      "Total iteration: 9\n",
      "Epoch 8/100 [01122020-022914] [SAVE]\n",
      "AccVal: 0.8126228434155929\n",
      "AUCVal: 0.9098649952447765\n",
      "Precision: 0.8685236573219299\n",
      "Recall: 0.7148097157478333\n",
      "F1Val: 0.7842052206692203\n",
      "LossVal: 0.42266619205474854\n",
      "LossTrain: 0.13236943466795814\n",
      "----------\n",
      "\n",
      "Training 8/99\n",
      "Total iteration: 9\n",
      "Epoch 9/100 [01122020-023022] [SAVE]\n",
      "AccVal: 0.8296571303778117\n",
      "AUCVal: 0.9122653602134441\n",
      "Precision: 0.8302687406539917\n",
      "Recall: 0.8074277639389038\n",
      "F1Val: 0.8186889705809907\n",
      "LossVal: 0.4045235315958659\n",
      "LossTrain: 0.12945171114471224\n",
      "----------\n",
      "\n",
      "Training 9/99\n",
      "Total iteration: 9\n",
      "Epoch 10/100 [01122020-023130]\n",
      "AccVal: 0.8176457741865036\n",
      "AUCVal: 0.9085564005462291\n",
      "Precision: 0.7702811360359192\n",
      "Recall: 0.8794131278991699\n",
      "F1Val: 0.8212374650100753\n",
      "LossVal: 0.4536146322886149\n",
      "LossTrain: 0.13308318538798225\n",
      "----------\n",
      "\n",
      "Training 10/99\n",
      "Total iteration: 9\n",
      "Epoch 11/100 [01122020-023237] [SAVE]\n",
      "AccVal: 0.8390478270364709\n",
      "AUCVal: 0.9127920294269373\n",
      "Precision: 0.8141862750053406\n",
      "Recall: 0.8578633666038513\n",
      "F1Val: 0.8354543567815694\n",
      "LossVal: 0.4171905020872752\n",
      "LossTrain: 0.12941021968921027\n",
      "----------\n",
      "\n",
      "Training 11/99\n",
      "Total iteration: 9\n",
      "Epoch 12/100 [01122020-023345]\n",
      "AccVal: 0.8021402052849967\n",
      "AUCVal: 0.9013732787409957\n",
      "Precision: 0.8774423003196716\n",
      "Recall: 0.6795048117637634\n",
      "F1Val: 0.7658914814575036\n",
      "LossVal: 0.5502441426118215\n",
      "LossTrain: 0.12914804203642738\n",
      "----------\n",
      "\n",
      "Training 12/99\n",
      "Total iteration: 9\n",
      "Epoch 13/100 [01122020-023453]\n",
      "AccVal: 0.8185193273640533\n",
      "AUCVal: 0.9072158749133371\n",
      "Precision: 0.8104875683784485\n",
      "Recall: 0.8078863024711609\n",
      "F1Val: 0.8091848448743941\n",
      "LossVal: 0.43142056465148926\n",
      "LossTrain: 0.13013541532887352\n",
      "----------\n",
      "\n",
      "Training 13/99\n",
      "Total iteration: 9\n",
      "Epoch 14/100 [01122020-023602]\n",
      "AccVal: 0.8281284123170998\n",
      "AUCVal: 0.909890138465533\n",
      "Precision: 0.7828733921051025\n",
      "Recall: 0.8844566941261292\n",
      "F1Val: 0.8305705544108944\n",
      "LossVal: 0.44891170660654706\n",
      "LossTrain: 0.12478454907735188\n",
      "----------\n",
      "\n",
      "Training 14/99\n",
      "Total iteration: 9\n",
      "Epoch    15: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 15/100 [01122020-023709]\n",
      "AccVal: 0.8132780082987552\n",
      "AUCVal: 0.9096539069123399\n",
      "Precision: 0.8695651888847351\n",
      "Recall: 0.7152682542800903\n",
      "F1Val: 0.7849056955616602\n",
      "LossVal: 0.5079451501369476\n",
      "LossTrain: 0.11676688823435041\n",
      "----------\n",
      "\n",
      "Training 15/99\n",
      "Total iteration: 9\n",
      "Epoch 16/100 [01122020-023818]\n",
      "AccVal: 0.8285651889058746\n",
      "AUCVal: 0.9121992039063578\n",
      "Precision: 0.7905911803245544\n",
      "Recall: 0.8707014918327332\n",
      "F1Val: 0.8287148094676211\n",
      "LossVal: 0.43747331698735553\n",
      "LossTrain: 0.09963154875569874\n",
      "----------\n",
      "\n",
      "Training 16/99\n",
      "Total iteration: 9\n",
      "Epoch 17/100 [01122020-023925]\n",
      "AccVal: 0.8309674601441362\n",
      "AUCVal: 0.9151135230757405\n",
      "Precision: 0.8453608155250549\n",
      "Recall: 0.7895460724830627\n",
      "F1Val: 0.8165007030364557\n",
      "LossVal: 0.42790524164835614\n",
      "LossTrain: 0.07825230144792134\n",
      "----------\n",
      "\n",
      "Training 17/99\n",
      "Total iteration: 9\n",
      "Epoch 18/100 [01122020-024032]\n",
      "AccVal: 0.8368639440925967\n",
      "AUCVal: 0.9164389436558589\n",
      "Precision: 0.8183836340904236\n",
      "Recall: 0.8450252413749695\n",
      "F1Val: 0.8314910881320142\n",
      "LossVal: 0.41064031918843585\n",
      "LossTrain: 0.07101869169208738\n",
      "----------\n",
      "\n",
      "Training 18/99\n",
      "Total iteration: 9\n",
      "Epoch 19/100 [01122020-024140]\n",
      "AccVal: 0.8351168377374972\n",
      "AUCVal: 0.9147770054443198\n",
      "Precision: 0.8334892392158508\n",
      "Recall: 0.81705641746521\n",
      "F1Val: 0.8251910556070237\n",
      "LossVal: 0.42976275086402893\n",
      "LossTrain: 0.06546966938508882\n",
      "----------\n",
      "\n",
      "Training 19/99\n",
      "Total iteration: 9\n",
      "Epoch 20/100 [01122020-024248]\n",
      "AccVal: 0.8338065079711727\n",
      "AUCVal: 0.9149471762920269\n",
      "Precision: 0.8239051103591919\n",
      "Recall: 0.828060507774353\n",
      "F1Val: 0.8259775827692368\n",
      "LossVal: 0.4327968458334605\n",
      "LossTrain: 0.060993052191204496\n",
      "----------\n",
      "\n",
      "Training 20/99\n",
      "Total iteration: 9\n",
      "Epoch 21/100 [01122020-024356]\n",
      "AccVal: 0.834461672854335\n",
      "AUCVal: 0.9156972664443356\n",
      "Precision: 0.8409199714660645\n",
      "Recall: 0.8046767711639404\n",
      "F1Val: 0.8223992548321755\n",
      "LossVal: 0.4361202120780945\n",
      "LossTrain: 0.05705460657676061\n",
      "----------\n",
      "\n",
      "Training 21/99\n",
      "Total iteration: 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1af82b2c89aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                      \u001b[0minit_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9381\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      dropout=0.75, batchnorm=True, checkpoint=None)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, numb_epoch)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mlossTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderVal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mmetricsVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0mlossVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetricsVal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0maccVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetricsVal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36mval_epoch\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mloss_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatchID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mbatch_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mbatch_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2827\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0;31m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=2048, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[9381, 1024, 128, 1], weight_decay=1e-2,\n",
    "                     dropout=0.75, batchnorm=True, checkpoint=None)\n",
    "model_mlp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BOW entire dict without unknow token (Remove Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FT_0\n",
      "Processing FT_1000\n",
      "Processing FT_2000\n",
      "Processing FT_3000\n",
      "Processing FT_4000\n",
      "Processing FT_5000\n",
      "Processing FT_6000\n",
      "Processing FT_7000\n",
      "Processing FT_8000\n",
      "Processing FT_9000\n",
      "Processing FT_10000\n",
      "Processing FT_11000\n",
      "Processing FT_12000\n",
      "Processing FT_13000\n",
      "Processing FT_14000\n",
      "Processing FT_15000\n",
      "Processing FT_16000\n",
      "Processing FT_17000\n",
      "Processing FT_18000\n",
      "Processing FT_0\n",
      "Processing FT_1000\n",
      "Processing FT_2000\n",
      "Processing FT_3000\n",
      "Processing FT_4000\n",
      "Processing FT_5000\n",
      "Processing FT_6000\n",
      "Processing FT_7000\n",
      "Processing FT_8000\n",
      "Processing FT_9000\n",
      "Processing FT_10000\n",
      "Processing FT_11000\n",
      "Processing FT_12000\n",
      "Processing FT_13000\n",
      "Processing FT_14000\n",
      "Processing FT_15000\n",
      "Processing FT_16000\n",
      "Processing FT_17000\n",
      "Processing FT_18000\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "all_string = data_train_rmsw.headline_s3.tolist()\n",
    "all_string_in_one = ' '.join(all_string)\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit([all_string_in_one])\n",
    "# encode document\n",
    "vector = vectorizer.transform(data_train_rmsw.headline_s3.tolist())\n",
    "# summarize encoded vector\n",
    "vector = vector.toarray()\n",
    "dt_train = data_train_rmsw.drop(columns=['headline_s3']) \n",
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    dt_train[f\"ft_{idx}\"] = vector[:,idx]\n",
    "    \n",
    "# encode document\n",
    "vector = vectorizer.transform(data_val_rmsw.headline_s3.tolist())\n",
    "# summarize encoded vector\n",
    "vector = vector.toarray()\n",
    "dt_val = data_val_rmsw.drop(columns=['headline_s3'])\n",
    "\n",
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    dt_val[f\"ft_{idx}\"] = vector[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18316, 18265)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/99\n",
      "Total iteration: 36\n",
      "Epoch 1/100 [02122020-014804] [SAVE]\n",
      "AccVal: 0.525660624590522\n",
      "AUCVal: 0.8583078172663374\n",
      "Precision: 1.0\n",
      "Recall: 0.004126547370105982\n",
      "F1Val: 0.008219177901774902\n",
      "LossVal: 0.6823680202166239\n",
      "LossTrain: 0.575858806570371\n",
      "----------\n",
      "\n",
      "Training 1/99\n",
      "Total iteration: 36\n",
      "Epoch 2/100 [02122020-015010] [SAVE]\n",
      "AccVal: 0.7464511902162044\n",
      "AUCVal: 0.8664425573963325\n",
      "Precision: 0.8846153616905212\n",
      "Recall: 0.537826657295227\n",
      "F1Val: 0.6689478186892435\n",
      "LossVal: 0.5098949273427328\n",
      "LossTrain: 0.36468082583612865\n",
      "----------\n",
      "\n",
      "Training 2/99\n",
      "Total iteration: 36\n",
      "Epoch 3/100 [02122020-015218] [SAVE]\n",
      "AccVal: 0.7746232801921817\n",
      "AUCVal: 0.8597961429725751\n",
      "Precision: 0.7911809682846069\n",
      "Recall: 0.7157267332077026\n",
      "F1Val: 0.7515647696878383\n",
      "LossVal: 0.48627598418129814\n",
      "LossTrain: 0.30643068502346676\n",
      "----------\n",
      "\n",
      "Training 3/99\n",
      "Total iteration: 36\n",
      "Epoch 4/100 [02122020-015424] [SAVE]\n",
      "AccVal: 0.7759336099585062\n",
      "AUCVal: 0.8595932763777242\n",
      "Precision: 0.7753934264183044\n",
      "Recall: 0.7455295920372009\n",
      "F1Val: 0.7601683160177348\n",
      "LossVal: 0.5040773650010427\n",
      "LossTrain: 0.28475475394063526\n",
      "----------\n",
      "\n",
      "Training 4/99\n",
      "Total iteration: 36\n",
      "Epoch 5/100 [02122020-015633] [SAVE]\n",
      "AccVal: 0.7772439397248307\n",
      "AUCVal: 0.8548001945683759\n",
      "Precision: 0.7762969732284546\n",
      "Recall: 0.747822105884552\n",
      "F1Val: 0.7617935141211455\n",
      "LossVal: 0.5215663777457343\n",
      "LossTrain: 0.2746199174887604\n",
      "----------\n",
      "\n",
      "Training 5/99\n",
      "Total iteration: 36\n",
      "Epoch 6/100 [02122020-015840]\n",
      "AccVal: 0.7720026206595326\n",
      "AUCVal: 0.853324870679716\n",
      "Precision: 0.774505078792572\n",
      "Recall: 0.7354424595832825\n",
      "F1Val: 0.7544684906333057\n",
      "LossVal: 0.5372055570284525\n",
      "LossTrain: 0.2522748385866483\n",
      "----------\n",
      "\n",
      "Training 6/99\n",
      "Total iteration: 36\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 7/100 [02122020-020047] [SAVE]\n",
      "AccVal: 0.7792094343743176\n",
      "AUCVal: 0.8590296093450946\n",
      "Precision: 0.781520664691925\n",
      "Recall: 0.7446125745773315\n",
      "F1Val: 0.7626202962100815\n",
      "LossVal: 0.5304353005356259\n",
      "LossTrain: 0.25292148399684167\n",
      "----------\n",
      "\n",
      "Training 7/99\n",
      "Total iteration: 36\n",
      "Epoch 8/100 [02122020-020254] [SAVE]\n",
      "AccVal: 0.784669141734003\n",
      "AUCVal: 0.866830317485265\n",
      "Precision: 0.7956457138061523\n",
      "Recall: 0.7372764945030212\n",
      "F1Val: 0.7653498093411918\n",
      "LossVal: 0.5030472742186652\n",
      "LossTrain: 0.18721083117028078\n",
      "----------\n",
      "\n",
      "Training 8/99\n",
      "Total iteration: 36\n",
      "Epoch 9/100 [02122020-020501]\n",
      "AccVal: 0.7789910460799301\n",
      "AUCVal: 0.8647517475016434\n",
      "Precision: 0.7903626561164856\n",
      "Recall: 0.7294818758964539\n",
      "F1Val: 0.7587029079332822\n",
      "LossVal: 0.5373307201597426\n",
      "LossTrain: 0.13638587751322323\n",
      "----------\n",
      "\n",
      "Training 9/99\n",
      "Total iteration: 36\n",
      "Epoch 10/100 [02122020-020708]\n",
      "AccVal: 0.7763703865472811\n",
      "AUCVal: 0.8609680273833573\n",
      "Precision: 0.8020887970924377\n",
      "Recall: 0.7042641043663025\n",
      "F1Val: 0.7500000136216726\n",
      "LossVal: 0.5617485642433167\n",
      "LossTrain: 0.1320820270727078\n",
      "----------\n",
      "\n",
      "Training 10/99\n",
      "Total iteration: 36\n",
      "Epoch 11/100 [02122020-020913]\n",
      "AccVal: 0.7783358811967679\n",
      "AUCVal: 0.8589024592173133\n",
      "Precision: 0.7897614240646362\n",
      "Recall: 0.7285648584365845\n",
      "F1Val: 0.757929868900711\n",
      "LossVal: 0.5731687711344825\n",
      "LossTrain: 0.1361447369886769\n",
      "----------\n",
      "\n",
      "Training 11/99\n",
      "Total iteration: 36\n",
      "Epoch    12: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 12/100 [02122020-021120]\n",
      "AccVal: 0.7794278226687049\n",
      "AUCVal: 0.8610103788920846\n",
      "Precision: 0.7840853929519653\n",
      "Recall: 0.740944504737854\n",
      "F1Val: 0.7619047522059055\n",
      "LossVal: 0.5645294321907891\n",
      "LossTrain: 0.1469175430635611\n",
      "----------\n",
      "\n",
      "Training 12/99\n",
      "Total iteration: 36\n",
      "Epoch 13/100 [02122020-021328] [SAVE]\n",
      "AccVal: 0.7855426949115527\n",
      "AUCVal: 0.8692569728938873\n",
      "Precision: 0.7975186109542847\n",
      "Recall: 0.7368179559707642\n",
      "F1Val: 0.7659675790033937\n",
      "LossVal: 0.5344502164257897\n",
      "LossTrain: 0.11132394998437828\n",
      "----------\n",
      "\n",
      "Training 13/99\n",
      "Total iteration: 36\n",
      "Epoch 14/100 [02122020-021535]\n",
      "AccVal: 0.7837955885564534\n",
      "AUCVal: 0.867660330575036\n",
      "Precision: 0.7903461456298828\n",
      "Recall: 0.7432370185852051\n",
      "F1Val: 0.7660680250476152\n",
      "LossVal: 0.546549979183409\n",
      "LossTrain: 0.08141821146839195\n",
      "----------\n",
      "\n",
      "Training 14/99\n",
      "Total iteration: 36\n",
      "Epoch 15/100 [02122020-021743]\n",
      "AccVal: 0.7840139768508408\n",
      "AUCVal: 0.8666054625224521\n",
      "Precision: 0.7968127727508545\n",
      "Recall: 0.7336084246635437\n",
      "F1Val: 0.7639054414444416\n",
      "LossVal: 0.5579032500584921\n",
      "LossTrain: 0.07067602407187223\n",
      "----------\n",
      "\n",
      "Training 15/99\n",
      "Total iteration: 36\n",
      "Epoch    16: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 16/100 [02122020-021951] [SAVE]\n",
      "AccVal: 0.7879449661498144\n",
      "AUCVal: 0.8675893941879581\n",
      "Precision: 0.8043259382247925\n",
      "Recall: 0.7331499457359314\n",
      "F1Val: 0.7670904590782512\n",
      "LossVal: 0.5621493260065714\n",
      "LossTrain: 0.06884926888677809\n",
      "----------\n",
      "\n",
      "Training 16/99\n",
      "Total iteration: 36\n",
      "Epoch 17/100 [02122020-022158]\n",
      "AccVal: 0.784669141734003\n",
      "AUCVal: 0.8688700732193533\n",
      "Precision: 0.7959386110305786\n",
      "Recall: 0.7368179559707642\n",
      "F1Val: 0.7652380985783065\n",
      "LossVal: 0.5636071827676561\n",
      "LossTrain: 0.05754083332916101\n",
      "----------\n",
      "\n",
      "Training 17/99\n",
      "Total iteration: 36\n",
      "Epoch 18/100 [02122020-022404] [SAVE]\n",
      "AccVal: 0.7920943437431753\n",
      "AUCVal: 0.8706873640306246\n",
      "Precision: 0.8013732433319092\n",
      "Recall: 0.7491976022720337\n",
      "F1Val: 0.7744075856080995\n",
      "LossVal: 0.552348792552948\n",
      "LossTrain: 0.04821784577021996\n",
      "----------\n",
      "\n",
      "Training 18/99\n",
      "Total iteration: 36\n",
      "Epoch 19/100 [02122020-022611] [SAVE]\n",
      "AccVal: 0.794496614981437\n",
      "AUCVal: 0.8715187155427934\n",
      "Precision: 0.802734375\n",
      "Recall: 0.7537826895713806\n",
      "F1Val: 0.7774887494658521\n",
      "LossVal: 0.5558965603510538\n",
      "LossTrain: 0.042972391471266747\n",
      "----------\n",
      "\n",
      "Training 19/99\n",
      "Total iteration: 36\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 20/100 [02122020-022816]\n",
      "AccVal: 0.791875955448788\n",
      "AUCVal: 0.8705859307331992\n",
      "Precision: 0.7960463166236877\n",
      "Recall: 0.7569922208786011\n",
      "F1Val: 0.7760281943613584\n",
      "LossVal: 0.5606998039616479\n",
      "LossTrain: 0.041638538551827274\n",
      "----------\n",
      "\n",
      "Training 20/99\n",
      "Total iteration: 36\n",
      "Epoch 21/100 [02122020-023023]\n",
      "AccVal: 0.7894736842105263\n",
      "AUCVal: 0.8707988354960328\n",
      "Precision: 0.7996060848236084\n",
      "Recall: 0.7446125745773315\n",
      "F1Val: 0.7711301010948589\n",
      "LossVal: 0.5607802205615573\n",
      "LossTrain: 0.039199850521981716\n",
      "----------\n",
      "\n",
      "Training 21/99\n",
      "Total iteration: 36\n",
      "Epoch 22/100 [02122020-023230]\n",
      "AccVal: 0.7925311203319502\n",
      "AUCVal: 0.8701264694443903\n",
      "Precision: 0.7995133996009827\n",
      "Recall: 0.7533241510391235\n",
      "F1Val: 0.7757317945227811\n",
      "LossVal: 0.5620500412252214\n",
      "LossTrain: 0.036259676329791546\n",
      "----------\n",
      "\n",
      "Training 22/99\n",
      "Total iteration: 36\n",
      "Epoch 23/100 [02122020-023437]\n",
      "AccVal: 0.7925311203319502\n",
      "AUCVal: 0.8704553389478241\n",
      "Precision: 0.8036507368087769\n",
      "Recall: 0.7469050884246826\n",
      "F1Val: 0.7742395531593892\n",
      "LossVal: 0.5646159185303582\n",
      "LossTrain: 0.034798608575430184\n",
      "----------\n",
      "\n",
      "Training 23/99\n",
      "Total iteration: 36\n",
      "Epoch 24/100 [02122020-023642]\n",
      "AccVal: 0.7864162480891024\n",
      "AUCVal: 0.8690163436671013\n",
      "Precision: 0.7944199442863464\n",
      "Recall: 0.7441540360450745\n",
      "F1Val: 0.7684658851803085\n",
      "LossVal: 0.5680114097065396\n",
      "LossTrain: 0.034657671944134764\n",
      "----------\n",
      "\n",
      "Training 24/99\n",
      "Total iteration: 36\n",
      "Epoch 25/100 [02122020-023848]\n",
      "AccVal: 0.7910024022712383\n",
      "AUCVal: 0.8702480746793809\n",
      "Precision: 0.8026705980300903\n",
      "Recall: 0.7441540360450745\n",
      "F1Val: 0.7723054429882895\n",
      "LossVal: 0.5751287606027391\n",
      "LossTrain: 0.03344469124244319\n",
      "----------\n",
      "\n",
      "Training 25/99\n",
      "Total iteration: 36\n",
      "Epoch 26/100 [02122020-024055]\n",
      "AccVal: 0.7912207905656257\n",
      "AUCVal: 0.871068240804369\n",
      "Precision: 0.7998042106628418\n",
      "Recall: 0.7491976022720337\n",
      "F1Val: 0.773674235771692\n",
      "LossVal: 0.5718995531400045\n",
      "LossTrain: 0.03342748904186818\n",
      "----------\n",
      "\n",
      "Training 26/99\n",
      "Total iteration: 36\n",
      "Epoch 27/100 [02122020-024302]\n",
      "AccVal: 0.7890369076217515\n",
      "AUCVal: 0.8692970299642183\n",
      "Precision: 0.7964860796928406\n",
      "Recall: 0.7482805848121643\n",
      "F1Val: 0.7716311896182505\n",
      "LossVal: 0.5765886704126993\n",
      "LossTrain: 0.033595276789532766\n",
      "----------\n",
      "\n",
      "Training 27/99\n",
      "Total iteration: 36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-038d97d96187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0minit_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18264\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                      dropout=0.75, batchnorm=True, checkpoint=None)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, numb_epoch)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mtimestampSTART\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampDate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestampTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mlossTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderVal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mmetricsVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mnumb_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total iteration: {numb_iter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatchID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0mbatch_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mbatch_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2827\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0;31m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasetTrain = EncodingDataset(dt_train)\n",
    "datasetVal = EncodingDataset(dt_val)\n",
    "\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=512, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[18264, 512, 64, 1], weight_decay=1e-2,\n",
    "                     dropout=0.75, batchnorm=True, checkpoint=None)\n",
    "model_mlp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BOW entire dict with unknow token (Remove Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_string = data_train_rmsw.headline_s3.tolist()\n",
    "all_string_in_one = ' '.join(all_string)\n",
    "list_common_words, count_words = most_common_words(all_string_in_one, numb_words=-1)\n",
    "\n",
    "cwdf = pd.DataFrame(np.asarray(count_words),\n",
    "                    columns=['count_words'])\n",
    "cwdf['words'] = list_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words remaining: 9355\n",
      "Total discard (Unknown Token): 9262\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_words</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1128</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1040</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>653</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>609</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_words  words\n",
       "0         1128  trump\n",
       "1         1040    new\n",
       "2          958    man\n",
       "3          653    get\n",
       "4          609  woman"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = cwdf.index[cwdf.iloc[:,0] == 1].tolist()[0]\n",
    "print(f\"Number of unique words remaining: {s}\")\n",
    "print(f\"Total discard (Unknown Token): {cwdf.iloc[s:,0].sum()}\")\n",
    "cwdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump', 'new', 'man', 'get', 'woman', 'make', 'say', 'report', 'u', 'time']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_vocab = cwdf.words[0:s].tolist()\n",
    "list_vocab += ['UNK']\n",
    "list_vocab[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "all_string_in_one = ' '.join(list_vocab)\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit([all_string_in_one]);\n",
    "vocab = list(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FT_0\n",
      "Processing FT_1000\n",
      "Processing FT_2000\n",
      "Processing FT_3000\n",
      "Processing FT_4000\n",
      "Processing FT_5000\n",
      "Processing FT_6000\n",
      "Processing FT_7000\n",
      "Processing FT_8000\n",
      "Processing FT_9000\n",
      "Processing FT_0\n",
      "Processing FT_1000\n",
      "Processing FT_2000\n",
      "Processing FT_3000\n",
      "Processing FT_4000\n",
      "Processing FT_5000\n",
      "Processing FT_6000\n",
      "Processing FT_7000\n",
      "Processing FT_8000\n",
      "Processing FT_9000\n"
     ]
    }
   ],
   "source": [
    "def add_unknown_token(sent, vocab):\n",
    "    sent_s = sent.split()\n",
    "    for idx, s in enumerate(sent_s):\n",
    "        if s not in vocab:\n",
    "            sent_s[idx] = 'UNK'\n",
    "    psent = ' '.join(sent_s)\n",
    "    return psent\n",
    "\n",
    "data_train_rmsw['preprocess'] = data_train_rmsw.headline_s3.apply(lambda row: add_unknown_token(row, vocab))\n",
    "# encode document\n",
    "vector = vectorizer.transform(data_train_rmsw.preprocess.tolist())\n",
    "# summarize encoded vector\n",
    "vector = vector.toarray()\n",
    "data_train_rmsw = data_train_rmsw.drop(columns=['headline_s3', 'preprocess'])\n",
    "\n",
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    data_train_rmsw[f\"ft_{idx}\"] = vector[:,idx]\n",
    "    \n",
    "# encode document\n",
    "data_val_rmsw['preprocess'] = data_val_rmsw.headline_s3.apply(lambda row: add_unknown_token(row, vocab))\n",
    "vector = vectorizer.transform(data_val_rmsw.preprocess.tolist())\n",
    "# summarize encoded vector\n",
    "vector = vector.toarray()\n",
    "data_val_rmsw = data_val_rmsw.drop(columns=['headline_s3', 'preprocess'])\n",
    "\n",
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    data_val_rmsw[f\"ft_{idx}\"] = vector[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18316, 9286)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_rmsw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FROM SCRATCH\n",
      "Training 0/99\n",
      "Total iteration: 36\n",
      "Epoch 1/100 [02122020-033218] [SAVE]\n",
      "AccVal: 0.5306835553614326\n",
      "AUCVal: 0.8509029953510854\n",
      "Precision: 1.0\n",
      "Recall: 0.014672168530523777\n",
      "F1Val: 0.028920017926528548\n",
      "LossVal: 0.6690416137377421\n",
      "LossTrain: 0.6094964543978373\n",
      "----------\n",
      "\n",
      "Training 1/99\n",
      "Total iteration: 36\n",
      "Epoch 2/100 [02122020-033328] [SAVE]\n",
      "AccVal: 0.771129067481983\n",
      "AUCVal: 0.8693792473400768\n",
      "Precision: 0.8605983257293701\n",
      "Recall: 0.6198991537094116\n",
      "F1Val: 0.7206823128204218\n",
      "LossVal: 0.4781721962822808\n",
      "LossTrain: 0.40572494599554276\n",
      "----------\n",
      "\n",
      "Training 2/99\n",
      "Total iteration: 36\n",
      "Epoch 3/100 [02122020-033437] [SAVE]\n",
      "AccVal: 0.7772439397248307\n",
      "AUCVal: 0.8640366475348744\n",
      "Precision: 0.8021863698959351\n",
      "Recall: 0.7065566182136536\n",
      "F1Val: 0.7513407793983922\n",
      "LossVal: 0.4655287232663896\n",
      "LossTrain: 0.32748667316304314\n",
      "----------\n",
      "\n",
      "Training 3/99\n",
      "Total iteration: 36\n",
      "Epoch 4/100 [02122020-033544]\n",
      "AccVal: 0.7687267962437213\n",
      "AUCVal: 0.8606485268367075\n",
      "Precision: 0.793410062789917\n",
      "Recall: 0.6955525279045105\n",
      "F1Val: 0.7412655713392907\n",
      "LossVal: 0.4809208810329437\n",
      "LossTrain: 0.3047218322753906\n",
      "----------\n",
      "\n",
      "Training 4/99\n",
      "Total iteration: 36\n",
      "Epoch 5/100 [02122020-033653]\n",
      "AccVal: 0.7724393972483075\n",
      "AUCVal: 0.8612619067012515\n",
      "Precision: 0.7877715826034546\n",
      "Recall: 0.7148097157478333\n",
      "F1Val: 0.7495191898307989\n",
      "LossVal: 0.4945545428329044\n",
      "LossTrain: 0.2842418361041281\n",
      "----------\n",
      "\n",
      "Training 5/99\n",
      "Total iteration: 36\n",
      "Epoch 6/100 [02122020-033800] [SAVE]\n",
      "AccVal: 0.7792094343743176\n",
      "AUCVal: 0.8596236776864719\n",
      "Precision: 0.7993858456611633\n",
      "Recall: 0.7161852121353149\n",
      "F1Val: 0.7555017575612505\n",
      "LossVal: 0.5036265353361765\n",
      "LossTrain: 0.2775904859105746\n",
      "----------\n",
      "\n",
      "Training 6/99\n",
      "Total iteration: 36\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 7/100 [02122020-033909]\n",
      "AccVal: 0.7744048918977943\n",
      "AUCVal: 0.8614233778033735\n",
      "Precision: 0.7728136777877808\n",
      "Recall: 0.7455295920372009\n",
      "F1Val: 0.7589265220717565\n",
      "LossVal: 0.49513325426313615\n",
      "LossTrain: 0.2624242314034038\n",
      "----------\n",
      "\n",
      "Training 7/99\n",
      "Total iteration: 36\n",
      "Epoch 8/100 [02122020-034017] [SAVE]\n",
      "AccVal: 0.7803013758462546\n",
      "AUCVal: 0.8644245988270066\n",
      "Precision: 0.7971674203872681\n",
      "Recall: 0.7226043343544006\n",
      "F1Val: 0.7580567394924642\n",
      "LossVal: 0.4995354678895738\n",
      "LossTrain: 0.20766454810897508\n",
      "----------\n",
      "\n",
      "Training 8/99\n",
      "Total iteration: 36\n",
      "Epoch 9/100 [02122020-034127]\n",
      "AccVal: 0.7796462109630924\n",
      "AUCVal: 0.8592514050567128\n",
      "Precision: 0.7761545777320862\n",
      "Recall: 0.7551581859588623\n",
      "F1Val: 0.7655124670222754\n",
      "LossVal: 0.5307929582066007\n",
      "LossTrain: 0.16370183353622755\n",
      "----------\n",
      "\n",
      "Training 9/99\n",
      "Total iteration: 36\n",
      "Epoch 10/100 [02122020-034233]\n",
      "AccVal: 0.7728761738370823\n",
      "AUCVal: 0.8592049426791928\n",
      "Precision: 0.7795198559761047\n",
      "Recall: 0.7294818758964539\n",
      "F1Val: 0.7536712448041204\n",
      "LossVal: 0.5469742814699808\n",
      "LossTrain: 0.153061227252086\n",
      "----------\n",
      "\n",
      "Training 10/99\n",
      "Total iteration: 36\n",
      "Epoch    11: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 11/100 [02122020-034341]\n",
      "AccVal: 0.7783358811967679\n",
      "AUCVal: 0.865377555574166\n",
      "Precision: 0.7704081535339355\n",
      "Recall: 0.7615772485733032\n",
      "F1Val: 0.7659672488259688\n",
      "LossVal: 0.5291283561123742\n",
      "LossTrain: 0.1495889321797424\n",
      "----------\n",
      "\n",
      "Training 11/99\n",
      "Total iteration: 36\n",
      "Epoch 12/100 [02122020-034449] [SAVE]\n",
      "AccVal: 0.7811749290238044\n",
      "AUCVal: 0.8666443723735852\n",
      "Precision: 0.784096360206604\n",
      "Recall: 0.7459880709648132\n",
      "F1Val: 0.7645676827639303\n",
      "LossVal: 0.5288020173708597\n",
      "LossTrain: 0.12758490981327164\n",
      "----------\n",
      "\n",
      "Training 12/99\n",
      "Total iteration: 36\n",
      "Epoch 13/100 [02122020-034557] [SAVE]\n",
      "AccVal: 0.7833588119676785\n",
      "AUCVal: 0.8667794574341525\n",
      "Precision: 0.7848586440086365\n",
      "Recall: 0.7510316371917725\n",
      "F1Val: 0.7675726016545584\n",
      "LossVal: 0.5376560489336649\n",
      "LossTrain: 0.10415252836214171\n",
      "----------\n",
      "\n",
      "Training 13/99\n",
      "Total iteration: 36\n",
      "Epoch 14/100 [02122020-034707] [SAVE]\n",
      "AccVal: 0.7859794715003275\n",
      "AUCVal: 0.8654442854908512\n",
      "Precision: 0.7817925810813904\n",
      "Recall: 0.7638697624206543\n",
      "F1Val: 0.7727272294034713\n",
      "LossVal: 0.5464444624053107\n",
      "LossTrain: 0.09662593135403262\n",
      "----------\n",
      "\n",
      "Training 14/99\n",
      "Total iteration: 36\n",
      "Epoch    15: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 15/100 [02122020-034815]\n",
      "AccVal: 0.7833588119676785\n",
      "AUCVal: 0.8675572720504133\n",
      "Precision: 0.7720823884010315\n",
      "Recall: 0.7734984159469604\n",
      "F1Val: 0.7727897237048668\n",
      "LossVal: 0.5467130806710985\n",
      "LossTrain: 0.09110948319236438\n",
      "----------\n",
      "\n",
      "Training 15/99\n",
      "Total iteration: 36\n",
      "Epoch 16/100 [02122020-034924] [SAVE]\n",
      "AccVal: 0.7892552959161389\n",
      "AUCVal: 0.867649240789455\n",
      "Precision: 0.7867924571037292\n",
      "Recall: 0.7647867798805237\n",
      "F1Val: 0.7756335678636735\n",
      "LossVal: 0.5507462686962552\n",
      "LossTrain: 0.07778178931524356\n",
      "----------\n",
      "\n",
      "Training 16/99\n",
      "Total iteration: 36\n",
      "Epoch 17/100 [02122020-035032]\n",
      "AccVal: 0.7864162480891024\n",
      "AUCVal: 0.865967130640351\n",
      "Precision: 0.7854769825935364\n",
      "Recall: 0.7588262557983398\n",
      "F1Val: 0.7719216872755674\n",
      "LossVal: 0.5592378709051344\n",
      "LossTrain: 0.06919944586439265\n",
      "----------\n",
      "\n",
      "Training 17/99\n",
      "Total iteration: 36\n",
      "Epoch 18/100 [02122020-035140]\n",
      "AccVal: 0.7844507534396157\n",
      "AUCVal: 0.8665036468186273\n",
      "Precision: 0.7898058295249939\n",
      "Recall: 0.7459880709648132\n",
      "F1Val: 0.7672718676851193\n",
      "LossVal: 0.5612100495232476\n",
      "LossTrain: 0.0634030725599991\n",
      "----------\n",
      "\n",
      "Training 18/99\n",
      "Total iteration: 36\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 19/100 [02122020-035248]\n",
      "AccVal: 0.7844507534396157\n",
      "AUCVal: 0.8658037475062323\n",
      "Precision: 0.7909356951713562\n",
      "Recall: 0.7441540360450745\n",
      "F1Val: 0.7668320331313564\n",
      "LossVal: 0.5687166717317369\n",
      "LossTrain: 0.06160789386679729\n",
      "----------\n",
      "\n",
      "Training 19/99\n",
      "Total iteration: 36\n",
      "Epoch 20/100 [02122020-035355]\n",
      "AccVal: 0.7842323651452282\n",
      "AUCVal: 0.8664247754987632\n",
      "Precision: 0.7891420125961304\n",
      "Recall: 0.7464466094970703\n",
      "F1Val: 0.7672007609839193\n",
      "LossVal: 0.5703795618481107\n",
      "LossTrain: 0.05687496159225702\n",
      "----------\n",
      "\n",
      "Training 20/99\n",
      "Total iteration: 36\n",
      "Epoch 21/100 [02122020-035503]\n",
      "AccVal: 0.7853243066171653\n",
      "AUCVal: 0.8661503989072356\n",
      "Precision: 0.7791239619255066\n",
      "Recall: 0.7666208148002625\n",
      "F1Val: 0.7728218209307995\n",
      "LossVal: 0.5708331598175896\n",
      "LossTrain: 0.05274629613591565\n",
      "----------\n",
      "\n",
      "Training 21/99\n",
      "Total iteration: 36\n",
      "Epoch 22/100 [02122020-035610]\n",
      "AccVal: 0.7837955885564534\n",
      "AUCVal: 0.8661809914191827\n",
      "Precision: 0.785885751247406\n",
      "Recall: 0.7505731582641602\n",
      "F1Val: 0.7678236284928126\n",
      "LossVal: 0.5759370194541084\n",
      "LossTrain: 0.05178834777325392\n",
      "----------\n",
      "\n",
      "Training 22/99\n",
      "Total iteration: 36\n",
      "Epoch 23/100 [02122020-035719]\n",
      "AccVal: 0.7822668704957414\n",
      "AUCVal: 0.866335483604517\n",
      "Precision: 0.7779342532157898\n",
      "Recall: 0.7597432136535645\n",
      "F1Val: 0.768731101773495\n",
      "LossVal: 0.5724411606788635\n",
      "LossTrain: 0.05117137792209784\n",
      "----------\n",
      "\n",
      "Training 23/99\n",
      "Total iteration: 36\n",
      "Epoch 24/100 [02122020-035826]\n",
      "AccVal: 0.7848875300283905\n",
      "AUCVal: 0.8655112066107359\n",
      "Precision: 0.7937131524085999\n",
      "Recall: 0.740944504737854\n",
      "F1Val: 0.7664215833877601\n",
      "LossVal: 0.5782958269119263\n",
      "LossTrain: 0.050024121378858886\n",
      "----------\n",
      "\n",
      "Training 24/99\n",
      "Total iteration: 36\n",
      "Epoch 25/100 [02122020-035933]\n",
      "AccVal: 0.7811749290238044\n",
      "AUCVal: 0.8648188598247277\n",
      "Precision: 0.7771509289741516\n",
      "Recall: 0.7579092383384705\n",
      "F1Val: 0.7674094881687845\n",
      "LossVal: 0.583878841665056\n",
      "LossTrain: 0.047017672616574496\n",
      "----------\n",
      "\n",
      "Training 25/99\n",
      "Total iteration: 36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1f6e62c90f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                      \u001b[0minit_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9285\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                      dropout=0.75, batchnorm=True, checkpoint=None)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, numb_epoch)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mtimestampSTART\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampDate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestampTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mlossTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderVal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mmetricsVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mnumb_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total iteration: {numb_iter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatchID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaderTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0mbatch_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mbatch_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EE514_FakeNews/deep_pytorch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2827\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0;31m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dt_train = data_train_rmsw.copy()\n",
    "dt_val = data_val_rmsw.copy()\n",
    "datasetTrain = EncodingDataset(dt_train)\n",
    "datasetVal = EncodingDataset(dt_val)\n",
    "\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=512, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[9285, 1024, 128, 1], weight_decay=1e-5,\n",
    "                     dropout=0.75, batchnorm=True, checkpoint=None)\n",
    "model_mlp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Entire w/o UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FT_0\n",
      "Processing FT_1000\n",
      "Processing FT_2000\n",
      "Processing FT_3000\n",
      "Processing FT_4000\n",
      "Processing FT_5000\n",
      "Processing FT_6000\n",
      "Processing FT_7000\n",
      "Processing FT_8000\n",
      "Processing FT_9000\n",
      "Processing FT_10000\n",
      "Processing FT_11000\n",
      "Processing FT_12000\n",
      "Processing FT_13000\n",
      "Processing FT_14000\n",
      "Processing FT_15000\n",
      "Processing FT_16000\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "all_string = data_train.headline_s2.tolist()\n",
    "vectorizer.fit(all_string)\n",
    "vector = vectorizer.transform(data_train.headline_s2.tolist())\n",
    "vector = vector.toarray()\n",
    "\n",
    "dt_train = data_train.drop(columns=['headline_s2'])\n",
    "\n",
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    dt_train[f\"ft_{idx}\"] = vector[:,idx]\n",
    "    \n",
    "# encode document\n",
    "vector = vectorizer.transform(data_val.headline_s2.tolist())\n",
    "# summarize encoded vector\n",
    "vector = vector.toarray()\n",
    "dt_val = data_val.drop(columns=['headline_s2'])\n",
    "\n",
    "for idx in range(vector.shape[1]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing FT_{idx}')\n",
    "    dt_val[f\"ft_{idx}\"] = vector[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = EncodingDataset(dt_train)\n",
    "datasetVal = EncodingDataset(dt_val)\n",
    "\n",
    "model_mlp = ModelMLP(datasetTrain=datasetTrain, datasetVal=datasetVal, batch_size=256, optimizer_choice='adam', \n",
    "                     init_lr=0.001, layers=[18337, 2048, 128, 1], weight_decay=1e-3,\n",
    "                     dropout=0.75, batchnorm=True, checkpoint=None)\n",
    "model_mlp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
